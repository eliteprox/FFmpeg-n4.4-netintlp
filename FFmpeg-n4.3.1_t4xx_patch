diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/build_ffmpeg.sh FFmpeg-n4.3.1/build_ffmpeg.sh
*** base_ffmpeg_n4.3.1/build_ffmpeg.sh	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/build_ffmpeg.sh	2021-12-21 15:39:35.010154336 -0800
***************
*** 0 ****
--- 1,329 ----
+ #!/usr/bin/env bash
+ 
+ target_windows=false;
+ target_android=false;
+ debug=false;
+ enable_ffplay=false;
+ enable_ffprobe=false;
+ enable_x264=false;
+ enable_x265=false;
+ enable_ffnvcodec=false;
+ enable_vmaf=false;
+ enable_shared=false;
+ enable_multi_threaded_nienc=false;
+ dry_run_mode=false;
+ android_arch=x86_64
+ custom_flags="";
+ extra_config_flags=""
+ 
+ # parse a flag with an arg in or after it
+ # $1 flag pattern, $2 entire flag arg, $3 arg after flag arg
+ # return 1 if path is in second arg (separated by space), else return 0. Store path in $extract_arg_ret
+ extract_arg () {
+     unset extract_arg_ret
+     # check valid arg flag
+     if [ -n "$(printf "%s" ${2} | grep -Eoh "${1}")" ]; then
+         # check if path string is connected by '=' or is in following arg
+         if [ -n "$(echo "${2}" | grep -Eoh "${1}=")" ]; then
+             arg_str=`printf "%s" "${2}" | grep -Poh "${1}=\K.+"`;
+             # trim out leading and trailing quotation marks
+             extract_arg_ret=`echo "${arg_str}" | sed -e 's/^\(["'\'']\)//' -e 's/\(["'\'']\)$//'`;
+             return 0;
+         elif [ -n "$(printf "%s" ${2} | grep -Eoh "^${1}$")" ]; then
+             arg_str="${3}";
+             # trim out leading and trailing quotation marks
+             extract_arg_ret=`printf "%s" "${arg_str}" | sed -e 's/^\(["'\'']\)//' -e 's/\(["'\'']\)$//'`;
+             return 1;
+         else
+             echo "Unknown option '$2', exiting";
+             exit 1;
+         fi
+     else
+         echo "Target flag '$1' not found in '$2', exiting"; exit 1;
+     fi
+ }
+ 
+ if [ `whoami` = root ]; then
+     read -p "Do you wish to execute with sudo [Y/N]? " -n 1 -r
+     echo   
+     if [[ ! $REPLY =~ ^[Yy]$ ]]; then
+         exit
+     fi
+ fi
+ 
+ while [ "$1" != "" ]; do
+     case $1 in
+         -h | --help) echo "Usage: ./build_ffmpeg.sh [OPTION]";
+                      echo "Compile FFmpeg for T408.";
+                      echo "Example: ./build_ffmpeg.sh";
+                      echo;
+                      echo "Options:";
+                      echo "-h, --help                    display this help and exit.";
+                      echo "-w, windows                   compile for Windows.";
+                      echo "-a, --android                 compile for Android NDK.";
+                      echo "-g, --gdb                     compile for GDB.";
+                      echo "--ffplay                      compile with ffplay (requires libsdl2 package).";
+                      echo "--ffprobe                     compile with ffprobe.";
+                      echo "--libx264                     compile with libx264 (requires libx264 package).";
+                      echo "--libx265                     compile with libx265 (requires libx265 package).";
+                      echo "--ffnvcodec                   compile with ffnvcodec (requires ffnvcodec package).";
+                      echo "--vmaf                        compile with vmaf (requires libvmaf).";
+                      echo "--shared                      compile with shared libFF components.";
+                      echo "--nienc_multi_thread          compile nienc in libavcodec with multithreaded frame send/receive.";
+                      echo "--dry                         dry run printing configs without building";
+                      echo "--android_arch \"<arch>\"       cross compile CPU arch when compiling for --android. [arm,arm64,x86,x86_64(default)]";
+                      echo "--custom_flags \"<flags>\"      compile with custom configuration flags";
+                      echo "";
+                      echo "T408 required configuration flags:";
+                      echo "--enable-libxcoder --enable-gpl";
+                      echo "--extra-ldflags='-lm -ldl'";
+                      echo "--enable-pthreads --extra-libs='-lpthread'";
+                      echo "--enable-x86asm";
+                      exit 0
+         ;;
+         -w | windows)          target_windows=true
+         ;;
+         -a | --android)        target_android=true
+         ;;
+         -g | --gdb)            debug=true
+         ;;
+         --ffplay)              enable_ffplay=true
+         ;;
+         --ffprobe)             enable_ffprobe=true
+         ;;
+         --libx264)             enable_x264=true
+         ;;
+         --libx265)             enable_x265=true
+         ;;
+         --ffnvcodec)           enable_ffnvcodec=true
+         ;;
+         --vmaf)                enable_vmaf=true
+         ;;
+         --shared)              enable_shared=true
+         ;;
+         --nienc_multi_thread)  enable_multi_threaded_nienc=true
+         ;;
+         --dry)                 dry_run_mode=true
+         ;;
+         --android_arch | --android_arch=*) extract_arg "\-\-android_arch" "$1" "$2"; prev_rc=$?;
+                                            if [ "$prev_rc" -eq 1 ]; then shift; fi
+                                            android_arch=$extract_arg_ret
+         ;;
+         --custom_flags | --custom_flags=*) extract_arg "\-\-custom_flags" "$1" "$2"; prev_rc=$?;
+                                            if [ "$prev_rc" -eq 1 ]; then shift; fi
+                                            custom_flags=$extract_arg_ret
+         ;;
+         *)                     echo "Usage: ./build_ffmpeg.sh [OPTION]...";
+                                echo "Try './build_ffmpeg.sh --help' for more information"; exit 1
+         ;;
+     esac
+     shift
+ done
+ 
+ if $debug; then
+     extra_config_flags="${extra_config_flags} --disable-optimizations --disable-asm --disable-stripping --enable-debug=3"
+ else
+     extra_config_flags="${extra_config_flags} --enable-x86asm --disable-debug"
+ fi
+ 
+ if $enable_ffplay; then
+     extra_config_flags="${extra_config_flags} --enable-ffplay"
+ else
+     extra_config_flags="${extra_config_flags} --disable-ffplay"
+ fi
+ 
+ if $enable_ffprobe; then
+     extra_config_flags="${extra_config_flags} --enable-ffprobe"
+ else
+     extra_config_flags="${extra_config_flags} --disable-ffprobe"
+ fi
+ 
+ if $enable_x264; then
+     extra_config_flags="${extra_config_flags} --enable-libx264"
+ else
+     extra_config_flags="${extra_config_flags} --disable-libx264"
+ fi
+ 
+ if $enable_x265; then
+     extra_config_flags="${extra_config_flags} --enable-libx265"
+ else
+     extra_config_flags="${extra_config_flags} --disable-libx265"
+ fi
+ 
+ if $enable_ffnvcodec; then
+     extra_config_flags="${extra_config_flags} --extra-cflags=-I/usr/local/cuda/targets/x86_64-linux/include --extra-ldflags=-L/usr/local/cuda/targets/x86_64-linux/lib --enable-cuda-nvcc --enable-cuda --enable-cuvid --enable-nvdec --enable-nvenc"
+ else
+     extra_config_flags="${extra_config_flags} --disable-cuda-nvcc --disable-cuda --disable-cuvid --disable-nvdec --disable-nvenc"
+ fi
+ 
+ if $enable_vmaf; then
+     extra_config_flags="${extra_config_flags} --enable-libvmaf --enable-version3"
+ else
+     extra_config_flags="${extra_config_flags} --disable-libvmaf"
+ fi
+ 
+ if $enable_shared; then
+     extra_config_flags="${extra_config_flags} --disable-static --enable-shared"
+ else
+     extra_config_flags="${extra_config_flags} --enable-static --disable-shared"
+ fi
+ 
+ if $enable_multi_threaded_nienc; then
+     extra_config_flags="${extra_config_flags} --extra-cflags=-DNIENC_MULTI_THREAD"
+ else
+     extra_config_flags="${extra_config_flags} --extra-cflags=-UNIENC_MULTI_THREAD"
+ fi
+ 
+ extra_config_flags="${extra_config_flags} ${custom_flags}"
+ 
+ if $target_windows; then
+     if $dry_run_mode; then # Dry-run mode args is a separate duplicate of wet-run mode args due to bash quotation passing limitations
+         echo ./configure \
+         --enable-cross-compile --arch='x86_64' \
+         --target-os='mingw32' \
+         --pkg-config-flags='--static' \
+         --enable-gpl --enable-nonfree \
+         --extra-ldflags='-lm' \
+         --enable-libxcoder \
+         --enable-ni \
+         --enable-w32threads --extra-libs='-lwinpthread -lws2_32' \
+         --enable-encoders --enable-decoders --enable-avfilter --enable-muxers --enable-demuxers --enable-parsers \
+         ${extra_config_flags}
+     else # Dry-run mode args is a separate duplicate of wet-run mode args due to bash quotation passing limitations
+         ./configure \
+         --enable-cross-compile --arch='x86_64' \
+         --target-os='mingw32' \
+         --pkg-config-flags='--static' \
+         --enable-gpl --enable-nonfree \
+         --extra-ldflags='-lm' \
+         --enable-libxcoder \
+         --enable-ni \
+         --enable-w32threads --extra-libs='-lwinpthread -lws2_32' \
+         --enable-encoders --enable-decoders --enable-avfilter --enable-muxers --enable-demuxers --enable-parsers \
+         ${extra_config_flags}
+         if [ $? != 0 ]; then
+             echo -e "\e[31mConfiguration failed. Exiting...\e[0m"
+             exit 1
+         else
+             make -j $(nproc)
+             . ./mingw_package_ffmpeg.sh
+             RC=$?
+         fi
+     fi
+ elif $target_android; then
+ 
+ 	echo "android_arch: ${android_arch}"
+ 
+ 	if [ -z ${ANDROID_NDK_ROOT} ]; then
+ 		echo "You must set ANDROID_NDK_ROOT environment variable"
+ 		echo "Please download NDK r20b from https://developer.android.com/ndk/downloads/older_releases"
+ 		exit -1
+ 	fi
+ 
+ 	if [ "${android_arch}" = "arm" ]; then
+ 		ARCH=arm
+ 		ARCH2=armv7a
+ 	elif [ "${android_arch}" = "arm64" ]; then
+ 		ARCH=arm64
+ 		ARCH2=aarch64
+ 	elif [ "${android_arch}" = "x86" ]; then
+ 		ARCH=x86
+ 		ARCH2=i686
+ 	elif [ "${android_arch}" = "x86_64" ]; then
+ 		ARCH=x86_64
+ 		ARCH2=x86_64
+ 	elif [ "${android_arch}" = "" ]; then
+ 		ARCH=x86_64
+ 		ARCH2=x86_64
+ 	else
+ 		echo "Error - unknown option for --android_arch. Select from: [arm,arm64,x86,x86_64]"
+ 		exit -1
+ 	fi
+ 
+ 	echo "Building android ARCH=${ARCH}"
+ 
+ 	API=28
+ 	TOOLCHAIN=${ANDROID_NDK_ROOT}/toolchains/llvm/prebuilt/linux-x86_64
+     PREFIX=android/$ARCH
+ 
+     if $dry_run_mode; then # Dry-run mode args is a separate duplicate of wet-run mode args due to bash quotation passing limitations
+         echo ./configure \
+ 		--prefix=$PREFIX \
+         --enable-cross-compile --arch='x86_64' \
+         --target-os='android' \
+ 		--cc=$TOOLCHAIN/bin/$ARCH2-linux-android$API-clang \
+ 		--cross-prefix=$TOOLCHAIN/bin/$ARCH2-linux-android- \
+ 		--pkg-config=$(which pkg-config) \
+         --pkg-config-flags='--static' \
+         --enable-gpl --enable-nonfree \
+         --extra-ldflags='-lm' \
+         --enable-libxcoder \
+         --enable-ni \
+ 		--extra-libs=-lgcc \
+ 		--enable-pic \
+ 		--extra-cflags="-DANDROID -D_ANDROID -D__ANDROID__" \
+ 		--enable-pthreads \
+         --enable-encoders --enable-decoders --enable-avfilter --enable-muxers --enable-demuxers --enable-parsers \
+         ${extra_config_flags}
+     else # Dry-run mode args is a separate duplicate of wet-run mode args due to bash quotation passing limitations
+         ./configure \
+ 		--prefix=$PREFIX \
+         --enable-cross-compile --arch='x86_64' \
+         --target-os='android' \
+ 		--cc=$TOOLCHAIN/bin/$ARCH2-linux-android$API-clang \
+ 		--cross-prefix=$TOOLCHAIN/bin/$ARCH2-linux-android- \
+ 		--pkg-config=$(which pkg-config) \
+         --pkg-config-flags='--static' \
+         --enable-gpl --enable-nonfree \
+         --extra-ldflags='-lm' \
+         --enable-libxcoder \
+         --enable-ni \
+ 		--extra-libs=-lgcc \
+ 		--enable-pic \
+ 		--extra-cflags="-DANDROID -D_ANDROID -D__ANDROID__" \
+         --enable-pthreads \
+         --enable-encoders --enable-decoders --enable-avfilter --enable-muxers --enable-demuxers --enable-parsers \
+         ${extra_config_flags}
+         if [ $? != 0 ]; then
+             echo -e "\e[31mConfiguration failed. Exiting...\e[0m"
+             exit 1
+         else
+             make -j $(nproc)
+             RC=$?
+         fi
+     fi
+ else
+     if $dry_run_mode; then # Dry-run mode args is a separate duplicate of wet-run mode args due to bash quotation passing limitations
+         echo ./configure \
+         --pkg-config-flags='--static' \
+         --enable-gpl --enable-nonfree \
+         --extra-ldflags='-lm' --extra-ldflags='-ldl' \
+         --enable-libxcoder \
+         --enable-ni \
+         --enable-pthreads --extra-libs='-lpthread' \
+         --enable-encoders --enable-decoders --enable-avfilter --enable-muxers --enable-demuxers --enable-parsers \
+         ${extra_config_flags}
+     else # Dry-run mode args is a separate duplicate of wet-run mode args due to bash quotation passing limitations
+         ./configure \
+         --pkg-config-flags='--static' \
+         --enable-gpl --enable-nonfree \
+         --extra-ldflags='-lm' --extra-ldflags='-ldl' \
+         --enable-libxcoder \
+         --enable-ni \
+         --enable-pthreads --extra-libs='-lpthread' \
+         --enable-encoders --enable-decoders --enable-avfilter --enable-muxers --enable-demuxers --enable-parsers \
+         ${extra_config_flags}
+         if [ $? != 0 ]; then
+             echo -e "\e[31mConfiguration failed. Exiting...\e[0m"
+             exit 1
+         else
+             make -j $(nproc)
+             RC=$?
+         fi
+     fi
+ fi
+ 
+ if $enable_shared && [ ! -z $RC ] && [ $RC -eq 0 ]; then
+     echo "Reminder: after installing FFmpeg, run 'sudo ldconfig' to cache the shared libraries"
+ fi
+ exit $RC
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/configure FFmpeg-n4.3.1/configure
*** base_ffmpeg_n4.3.1/configure	2022-01-30 21:54:34.156204389 -0800
--- FFmpeg-n4.3.1/configure	2021-11-04 21:55:58.351592756 -0700
***************
*** 285,290 ****
--- 285,292 ----
    --enable-libwebp         enable WebP encoding via libwebp [no]
    --enable-libx264         enable H.264 encoding via x264 [no]
    --enable-libx265         enable HEVC encoding via x265 [no]
+   --enable-libxcoder       enable NetInt Xcoder [no]
+   --enable-ni              enable NetInt HWaccel [no]
    --enable-libxavs         enable AVS encoding via xavs [no]
    --enable-libxavs2        enable AVS2 encoding via xavs2 [no]
    --enable-libxcb          enable X11 grabbing using XCB [autodetect]
***************
*** 1723,1728 ****
--- 1725,1731 ----
      libvidstab
      libx264
      libx265
+     libxcoder
      libxavs
      libxavs2
      libxvid
***************
*** 1860,1865 ****
--- 1863,1869 ----
      libmfx
      mmal
      omx
+     ni
      opencl
      vulkan
  "
***************
*** 2396,2401 ****
--- 2400,2406 ----
      mpegvideo
      mpegvideoenc
      mss34dsp
+     ni
      pixblockdsp
      qpeldsp
      qsv
***************
*** 3259,3264 ****
--- 3264,3273 ----
  libx264rgb_encoder_deps="libx264 x264_csp_bgr"
  libx264rgb_encoder_select="libx264_encoder"
  libx265_encoder_deps="libx265"
+ h264_ni_decoder_deps="libxcoder"
+ h265_ni_encoder_deps="libxcoder"
+ h265_ni_decoder_deps="libxcoder"
+ h264_ni_encoder_deps="libxcoder"
  libxavs_encoder_deps="libxavs"
  libxavs2_encoder_deps="libxavs2"
  libxvid_encoder_deps="libxvid"
***************
*** 3580,3585 ****
--- 3589,3595 ----
  scale_filter_deps="swscale"
  scale_qsv_filter_deps="libmfx"
  scdet_filter_select="scene_sad"
+ sdl_filter_deps="swscale sdl2"
  select_filter_select="scene_sad"
  sharpness_vaapi_filter_deps="vaapi"
  showcqt_filter_deps="avcodec avformat swscale"
***************
*** 6416,6421 ****
--- 6426,6432 ----
                               check_cpp_condition libx262 x264.h "X264_MPEG2"
  enabled libx265           && require_pkg_config libx265 x265 x265.h x265_api_get &&
                               require_cpp_condition libx265 x265.h "X265_BUILD >= 70"
+ enabled libxcoder         && require_pkg_config libxcoder xcoder ni_device_api.h ni_device_open
  enabled libxavs           && require libxavs "stdint.h xavs.h" xavs_encoder_encode "-lxavs $pthreads_extralibs $libm_extralibs"
  enabled libxavs2          && require_pkg_config libxavs2 "xavs2 >= 1.3.0" "stdint.h xavs2.h" xavs2_api_get
  enabled libxvid           && require libxvid xvid.h xvid_global -lxvidcore
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/fftools/ffmpeg.c FFmpeg-n4.3.1/fftools/ffmpeg.c
*** base_ffmpeg_n4.3.1/fftools/ffmpeg.c	2022-01-30 21:54:34.172204617 -0800
--- FFmpeg-n4.3.1/fftools/ffmpeg.c	2021-09-10 14:46:57.110959896 -0700
***************
*** 1690,1698 ****
              float fps;
  
              frame_number = ost->frame_number;
!             fps = t > 1 ? frame_number / t : 0;
              av_bprintf(&buf, "frame=%5d fps=%3.*f q=%3.1f ",
!                      frame_number, fps < 9.95, fps, q);
              av_bprintf(&buf_script, "frame=%d\n", frame_number);
              av_bprintf(&buf_script, "fps=%.2f\n", fps);
              av_bprintf(&buf_script, "stream_%d_%d_q=%.1f\n",
--- 1690,1716 ----
              float fps;
  
              frame_number = ost->frame_number;
! 
!             // NETINT: add option to display windowed average FPS
!             if (ni_interval_fps > 0) { // if ni_interval_fps arg selected, calculate windowed average FPS
!                 float interval = (cur_time - ost->ni_prev_fps_measurement_time)/ 1000000.0 ;
!                 if (interval >= (float)ni_interval_fps) { // update fps at every ni_interval_fps
!                     fps = (frame_number - ost->ni_prev_frame_count) / interval;
!                     // store variables for tracking windowed average FPS in OutputStream object
!                     ost->ni_prev_fps = fps;
!                     ost->ni_prev_fps_measurement_time = cur_time;
!                     ost->ni_prev_frame_count = frame_number;
!                 } else { // display FPS from previous interval if windowing interval not yet reached
!                     fps = ost->ni_prev_fps;
!                 }
!             } else { // else, use default FFmpeg default fps calculation
!                 fps = t > 1 ? frame_number / t : 0;
!             }
! 
!             // NETINT: add option to display windowed average FPS
!             // in addition to default behavior, display 1 decimal place in FPS if ni_interval_fps selected
              av_bprintf(&buf, "frame=%5d fps=%3.*f q=%3.1f ",
!                        frame_number, (fps < 9.95) || ni_interval_fps, fps, q);
              av_bprintf(&buf_script, "frame=%d\n", frame_number);
              av_bprintf(&buf_script, "fps=%.2f\n", fps);
              av_bprintf(&buf_script, "stream_%d_%d_q=%.1f\n",
***************
*** 2600,2605 ****
--- 2618,2626 ----
              ret = decode_video    (ist, repeating ? NULL : &avpkt, &got_output, &duration_pts, !pkt,
                                     &decode_failed);
              if (!repeating || !pkt || got_output) {
+                 if (got_output && repeating) { // NETINT: if a frame is already decoded no need to update DTS or PTS
+                     break;
+                 }
                  if (pkt && pkt->duration) {
                      duration_dts = av_rescale_q(pkt->duration, ist->st->time_base, AV_TIME_BASE_Q);
                  } else if(ist->dec_ctx->framerate.num != 0 && ist->dec_ctx->framerate.den != 0) {
***************
*** 3429,3434 ****
--- 3450,3467 ----
          if (ret < 0)
              return ret;
  
+         // NETINT: automatically enabling GenHdrs for MKV and HLS container format support
+         if (!strcmp(output_files[ost->file_index]->ctx->oformat->name, "matroska") ||
+             !strcmp(output_files[ost->file_index]->ctx->oformat->name, "hls") ||
+             !strcmp(output_files[ost->file_index]->ctx->oformat->name, "asf")) {
+             AVDictionaryEntry *t;
+             if ((t = av_dict_get(ost->encoder_opts, "xcoder-params", NULL, 0))) {
+                 av_dict_set(&ost->encoder_opts, "xcoder-params", ":GenHdrs=1", AV_DICT_APPEND);
+             }else{
+                 av_opt_set(ost->enc_ctx->priv_data, "xcoder-params", "GenHdrs=1", 0);
+             }
+         }
+ 
          if ((ist = get_input_stream(ost)))
              dec = ist->dec_ctx;
          if (dec && dec->subtitle_header) {
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/fftools/ffmpeg_filter.c FFmpeg-n4.3.1/fftools/ffmpeg_filter.c
*** base_ffmpeg_n4.3.1/fftools/ffmpeg_filter.c	2022-01-30 21:54:34.172204617 -0800
--- FFmpeg-n4.3.1/fftools/ffmpeg_filter.c	2021-08-09 14:16:17.718193592 -0700
***************
*** 470,476 ****
      if (ret < 0)
          return ret;
  
!     if (ofilter->width || ofilter->height) {
          char args[255];
          AVFilterContext *filter;
          AVDictionaryEntry *e = NULL;
--- 470,477 ----
      if (ret < 0)
          return ret;
  
!     // NETINT/FFmpeg-patch: add option for autoscale
!     if ((ofilter->width || ofilter->height) && ofilter->ost->autoscale) {
          char args[255];
          AVFilterContext *filter;
          AVDictionaryEntry *e = NULL;
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/fftools/ffmpeg.h FFmpeg-n4.3.1/fftools/ffmpeg.h
*** base_ffmpeg_n4.3.1/fftools/ffmpeg.h	2022-01-30 21:54:34.172204617 -0800
--- FFmpeg-n4.3.1/fftools/ffmpeg.h	2021-11-04 21:55:58.351592756 -0700
***************
*** 61,66 ****
--- 61,67 ----
      HWACCEL_GENERIC,
      HWACCEL_VIDEOTOOLBOX,
      HWACCEL_QSV,
+     HWACCEL_NI,
  };
  
  typedef struct HWAccel {
***************
*** 132,137 ****
--- 133,141 ----
      int        nb_hwaccel_output_formats;
      SpecifierOpt *autorotate;
      int        nb_autorotate;
+     // NETINT/FFmpeg-patch: add option for autoscale
+     SpecifierOpt *autoscale;
+     int        nb_autoscale;
  
      /* output options */
      StreamMap *stream_maps;
***************
*** 460,465 ****
--- 464,475 ----
      AVRational mux_timebase;
      AVRational enc_timebase;
  
+     // NETINT: add option to display windowed average FPS
+     int64_t ni_prev_fps_measurement_time;
+     int ni_prev_frame_count;
+     float ni_prev_fps;
+ 
+     int                    nb_bitstream_filters;
      AVBSFContext            *bsf_ctx;
  
      AVCodecContext *enc_ctx;
***************
*** 480,485 ****
--- 490,497 ----
      int top_field_first;
      int rotate_overridden;
      double rotate_override_value;
+     // NETINT/FFmpeg-patch: add option for autoscale
+     int autoscale;
  
      AVRational frame_aspect_ratio;
  
***************
*** 584,589 ****
--- 596,606 ----
  extern float dts_delta_threshold;
  extern float dts_error_threshold;
  
+ // NETINT: add option to display windowed average FPS
+ // if ni_interval_fps>0 the windowed average FPS calulation mode is used
+ // when ni_interval_fps>0, ni_interval_fps is the window size and update interval
+ extern float ni_interval_fps;
+ 
  extern int audio_volume;
  extern int audio_sync_method;
  extern int video_sync_method;
***************
*** 653,658 ****
--- 670,676 ----
  
  int videotoolbox_init(AVCodecContext *s);
  int qsv_init(AVCodecContext *s);
+ int ni_init(AVCodecContext *s);
  
  HWDevice *hw_device_get_by_name(const char *name);
  int hw_device_init_from_string(const char *arg, HWDevice **dev);
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/fftools/ffmpeg_ni.c FFmpeg-n4.3.1/fftools/ffmpeg_ni.c
*** base_ffmpeg_n4.3.1/fftools/ffmpeg_ni.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/fftools/ffmpeg_ni.c	2021-11-04 21:55:58.355591545 -0700
***************
*** 0 ****
--- 1,102 ----
+ /*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+ 
+ #include <stdlib.h>
+ 
+ #include "libavutil/dict.h"
+ #include "libavutil/hwcontext.h"
+ #include "libavutil/hwcontext_ni.h"
+ #include "libavutil/mem.h"
+ #include "libavutil/opt.h"
+ 
+ #include "ffmpeg.h"
+ static AVBufferRef *hw_device_ctx = NULL;
+ 
+ static int ni_get_buffer(AVCodecContext *s, AVFrame *frame, int flags)
+ {
+     InputStream *ist = s->opaque;
+ 
+     return av_hwframe_get_buffer(ist->hw_frames_ctx, frame, 0);
+ }
+ 
+ static void ni_uninit(AVCodecContext *s)
+ {
+     InputStream *ist = s->opaque;
+     av_buffer_unref(&ist->hw_frames_ctx);
+ }
+ 
+ static int ni_device_init(InputStream *ist)
+ {
+     int err;
+     AVDictionary *dict = NULL;
+     av_log(NULL, AV_LOG_ERROR, "NI DEVICE INIT DEBUG\n");
+ 
+     err = av_hwdevice_ctx_create(&hw_device_ctx, AV_HWDEVICE_TYPE_NI,
+         ist->hwaccel_device, dict, 0);
+     if (err < 0) {
+         av_log(NULL, AV_LOG_ERROR, "Error creating a NI device\n");
+         goto err_out;
+     }
+ 
+ err_out:
+     if (dict)
+         av_dict_free(&dict);
+ 
+     return err;
+ }
+ 
+ int ni_init(AVCodecContext *s)
+ {
+   InputStream *ist = s->opaque; //why set to opaque? who uses it?
+   AVHWFramesContext *frames_ctx;
+   AVNIFramesContext *frames_hwctx;
+   int ret;
+   av_log(NULL, AV_LOG_ERROR, "NI INIT ffmpeg_ni.c\n");
+   if (!hw_device_ctx) {
+     ret = ni_device_init(ist);
+     if (ret < 0)
+       return ret;
+   }
+ 
+   av_buffer_unref(&ist->hw_frames_ctx);
+   av_log(NULL, AV_LOG_ERROR, "NI INIT ffmpeg_ni.c, time to alloc hwframectx\n");
+   ist->hw_frames_ctx = av_hwframe_ctx_alloc(hw_device_ctx);
+   if (!ist->hw_frames_ctx)
+     return AVERROR(ENOMEM);
+   s->hw_frames_ctx = ist->hw_frames_ctx;
+   frames_ctx = (AVHWFramesContext*)ist->hw_frames_ctx->data;
+   frames_hwctx = frames_ctx->hwctx;
+ 
+   frames_ctx->width = FFALIGN(s->coded_width, 32);
+   frames_ctx->height = FFALIGN(s->coded_height, 32);
+   frames_ctx->format = AV_PIX_FMT_NI;
+   frames_ctx->sw_format = s->sw_pix_fmt;
+   frames_ctx->initial_pool_size = 64;
+   frames_hwctx->frame_type = NI_MEMTYPE_VIDEO_MEMORY_DECODER_TARGET;
+ 
+   ret = av_hwframe_ctx_init(ist->hw_frames_ctx); //might need to set the hw_frames_ctx format
+   if (ret < 0) {
+     av_log(NULL, AV_LOG_ERROR, "Error initializing a NI frame pool\n");
+     return ret;
+   }
+   //there's a retrieve data command option too //int  (*hwaccel_retrieve_data)(AVCodecContext *s, AVFrame *frame);
+   ist->hwaccel_get_buffer = ni_get_buffer;
+   ist->hwaccel_uninit = ni_uninit;
+ 
+   return 0;
+ }
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/fftools/ffmpeg_opt.c FFmpeg-n4.3.1/fftools/ffmpeg_opt.c
*** base_ffmpeg_n4.3.1/fftools/ffmpeg_opt.c	2022-01-30 21:54:34.172204617 -0800
--- FFmpeg-n4.3.1/fftools/ffmpeg_opt.c	2021-12-21 15:39:35.010154336 -0800
***************
*** 62,67 ****
--- 62,68 ----
  static const char *opt_name_hwaccel_devices[]           = {"hwaccel_device", NULL};
  static const char *opt_name_hwaccel_output_formats[]    = {"hwaccel_output_format", NULL};
  static const char *opt_name_autorotate[]                = {"autorotate", NULL};
+ static const char *const opt_name_autoscale[]           = {"autoscale", NULL};
  static const char *opt_name_max_frames[]                = {"frames", "aframes", "vframes", "dframes", NULL};
  static const char *opt_name_bitstream_filters[]         = {"bsf", "absf", "vbsf", NULL};
  static const char *opt_name_codec_tags[]                = {"tag", "atag", "vtag", "stag", NULL};
***************
*** 137,142 ****
--- 138,146 ----
  #if CONFIG_LIBMFX
      { "qsv",   qsv_init,   HWACCEL_QSV,   AV_PIX_FMT_QSV },
  #endif
+ #if CONFIG_NI
+     { "ni", ni_init, HWACCEL_NI, AV_PIX_FMT_NI },
+ #endif
      { 0 },
  };
  HWDevice *filter_hw_device;
***************
*** 148,153 ****
--- 152,162 ----
  float dts_delta_threshold   = 10;
  float dts_error_threshold   = 3600*30;
  
+ // NETINT: add option to display windowed average FPS
+ // if ni_interval_fps>0 the windowed average FPS calulation mode is used
+ // when ni_interval_fps>0, ni_interval_fps is the window size and update interval
+ float ni_interval_fps = 0;
+ 
  int audio_volume      = 256;
  int audio_sync_method = 0;
  int video_sync_method = VSYNC_AUTO;
***************
*** 858,864 ****
  #endif
  
              // avformat_find_stream_info() doesn't set this for us anymore.
!             ist->dec_ctx->framerate = st->avg_frame_rate;
  
              MATCH_PER_STREAM_OPT(frame_rates, str, framerate, ic, st);
              if (framerate && av_parse_video_rate(&ist->framerate,
--- 867,883 ----
  #endif
  
              // avformat_find_stream_info() doesn't set this for us anymore.
! 
!             // NETINT: use bitstream framerate info when find_stream_info cannot estimate it
!             if ((st->avg_frame_rate.num != 0) && (st->avg_frame_rate.den != 0)){
!                 ist->dec_ctx->framerate = st->avg_frame_rate;
!             }else if ((st->r_frame_rate.num != 0) && (st->r_frame_rate.den != 0)){
!                 ist->dec_ctx->framerate = st->r_frame_rate;
!             }else{
!                 av_log(NULL, AV_LOG_WARNING, "No framerate info found or probed -> using a default 30 fps\n");
!                 ist->dec_ctx->framerate.num = 30;
!                 ist->dec_ctx->framerate.den = 1;
!             }
  
              MATCH_PER_STREAM_OPT(frame_rates, str, framerate, ic, st);
              if (framerate && av_parse_video_rate(&ist->framerate,
***************
*** 1429,1434 ****
--- 1448,1462 ----
          exit_program(1);
      output_streams[nb_output_streams - 1] = ost;
  
+     // NETINT/FFmpeg-patch: add option for autoscale
+     ost->autoscale = 1;
+     MATCH_PER_STREAM_OPT(autoscale, i, ost->autoscale, oc, st);
+ 
+     // NETINT: add option to display windowed average FPS
+     ost->ni_prev_fps_measurement_time = 0;
+     ost->ni_prev_frame_count = 0;
+     ost->ni_prev_fps = 0;
+ 
      ost->file_index = nb_output_files - 1;
      ost->index      = idx;
      ost->st         = st;
***************
*** 1555,1561 ****
      MATCH_PER_STREAM_OPT(disposition, str, ost->disposition, oc, st);
      ost->disposition = av_strdup(ost->disposition);
  
!     ost->max_muxing_queue_size = 128;
      MATCH_PER_STREAM_OPT(max_muxing_queue_size, i, ost->max_muxing_queue_size, oc, st);
      ost->max_muxing_queue_size *= sizeof(AVPacket);
  
--- 1583,1590 ----
      MATCH_PER_STREAM_OPT(disposition, str, ost->disposition, oc, st);
      ost->disposition = av_strdup(ost->disposition);
  
!     // NETINT: change max_muxing_queue_size from 128 to 512 to alleviate muxing issues due to encoding latency
!     ost->max_muxing_queue_size = 512;
      MATCH_PER_STREAM_OPT(max_muxing_queue_size, i, ost->max_muxing_queue_size, oc, st);
      ost->max_muxing_queue_size *= sizeof(AVPacket);
  
***************
*** 3503,3508 ****
--- 3532,3539 ----
          "timestamp discontinuity delta threshold", "threshold" },
      { "dts_error_threshold", HAS_ARG | OPT_FLOAT | OPT_EXPERT,       { &dts_error_threshold },
          "timestamp error delta threshold", "threshold" },
+     { "ni_interval_fps", HAS_ARG | OPT_FLOAT | OPT_EXPERT,           { &ni_interval_fps }, // NETINT: add option to display windowed average FPS
+         "window size and reporting interval for moving average processing FPS calculation", "number" },
      { "xerror",         OPT_BOOL | OPT_EXPERT,                       { &exit_on_error },
          "exit on error", "error" },
      { "abort_on",       HAS_ARG | OPT_EXPERT,                        { .func_arg = opt_abort_on },
***************
*** 3664,3669 ****
--- 3695,3704 ----
      { "autorotate",       HAS_ARG | OPT_BOOL | OPT_SPEC |
                            OPT_EXPERT | OPT_INPUT,                                { .off = OFFSET(autorotate) },
          "automatically insert correct rotate filters" },
+     // NETINT/FFmpeg-patch: add option for autoscale
+     { "autoscale",        HAS_ARG | OPT_BOOL | OPT_SPEC |
+                           OPT_EXPERT | OPT_OUTPUT,                               { .off = OFFSET(autoscale) },
+         "automatically insert a scale filter at the end of the filter graph" },
  
      /* audio options */
      { "aframes",        OPT_AUDIO | HAS_ARG  | OPT_PERFILE | OPT_OUTPUT,           { .func_arg = opt_audio_frames },
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/fftools/Makefile FFmpeg-n4.3.1/fftools/Makefile
*** base_ffmpeg_n4.3.1/fftools/Makefile	2022-01-30 21:54:34.168204560 -0800
--- FFmpeg-n4.3.1/fftools/Makefile	2021-11-04 21:55:58.351592756 -0700
***************
*** 13,18 ****
--- 13,19 ----
  OBJS-ffmpeg-$(CONFIG_LIBMFX)       += fftools/ffmpeg_qsv.o
  ifndef CONFIG_VIDEOTOOLBOX
  OBJS-ffmpeg-$(CONFIG_VDA)          += fftools/ffmpeg_videotoolbox.o
+ OBJS-ffmpeg-$(CONFIG_NI)           += fftools/ffmpeg_ni.o
  endif
  OBJS-ffmpeg-$(CONFIG_VIDEOTOOLBOX) += fftools/ffmpeg_videotoolbox.o
  
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/allcodecs.c FFmpeg-n4.3.1/libavcodec/allcodecs.c
*** base_ffmpeg_n4.3.1/libavcodec/allcodecs.c	2022-01-30 21:54:34.184204788 -0800
--- FFmpeg-n4.3.1/libavcodec/allcodecs.c	2021-08-09 14:16:17.730193661 -0700
***************
*** 757,762 ****
--- 757,766 ----
  
  /* external libraries, that shouldn't be used by default if one of the
   * above is available */
+ extern AVCodec ff_h264_ni_decoder;
+ extern AVCodec ff_h265_ni_decoder;
+ extern AVCodec ff_h264_ni_encoder;
+ extern AVCodec ff_h265_ni_encoder;
  extern AVCodec ff_h263_v4l2m2m_encoder;
  extern AVCodec ff_libaom_av1_decoder;
  extern AVCodec ff_libopenh264_encoder;
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/bitstream_filters.c FFmpeg-n4.3.1/libavcodec/bitstream_filters.c
*** base_ffmpeg_n4.3.1/libavcodec/bitstream_filters.c	2022-01-30 21:54:34.196204959 -0800
--- FFmpeg-n4.3.1/libavcodec/bitstream_filters.c	2021-09-13 14:19:52.152858778 -0700
***************
*** 38,45 ****
--- 38,48 ----
  extern const AVBitStreamFilter ff_h264_mp4toannexb_bsf;
  extern const AVBitStreamFilter ff_h264_redundant_pps_bsf;
  extern const AVBitStreamFilter ff_hapqa_extract_bsf;
+ extern const AVBitStreamFilter ff_hevc_frame_split_bsf;
  extern const AVBitStreamFilter ff_hevc_metadata_bsf;
  extern const AVBitStreamFilter ff_hevc_mp4toannexb_bsf;
+ extern const AVBitStreamFilter ff_hevc_rawtotile_bsf;
+ extern const AVBitStreamFilter ff_hevc_tile_repack_bsf;
  extern const AVBitStreamFilter ff_imx_dump_header_bsf;
  extern const AVBitStreamFilter ff_mjpeg2jpeg_bsf;
  extern const AVBitStreamFilter ff_mjpega_dump_header_bsf;
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/h264_mp4toannexb_bsf.c FFmpeg-n4.3.1/libavcodec/h264_mp4toannexb_bsf.c
*** base_ffmpeg_n4.3.1/libavcodec/h264_mp4toannexb_bsf.c	2022-01-30 21:54:34.220205302 -0800
--- FFmpeg-n4.3.1/libavcodec/h264_mp4toannexb_bsf.c	2021-09-13 14:19:52.152858778 -0700
***************
*** 62,68 ****
      *out_size += start_code_size + in_size;
  }
  
! static int h264_extradata_to_annexb(AVBSFContext *ctx, const int padding)
  {
      H264BSFContext *s = ctx->priv_data;
      GetByteContext ogb, *gb = &ogb;
--- 62,69 ----
      *out_size += start_code_size + in_size;
  }
  
! // NETINT: add argument side_data and side_size for sequence changing
! static int h264_extradata_to_annexb(AVBSFContext *ctx, const int padding, uint8_t *side_data, size_t side_size)
  {
      H264BSFContext *s = ctx->priv_data;
      GetByteContext ogb, *gb = &ogb;
***************
*** 72,78 ****
      static const uint8_t nalu_header[4] = { 0, 0, 0, 1 };
      int length_size, pps_offset = 0;
  
!     bytestream2_init(gb, ctx->par_in->extradata, ctx->par_in->extradata_size);
  
      bytestream2_skipu(gb, 4);
  
--- 73,86 ----
      static const uint8_t nalu_header[4] = { 0, 0, 0, 1 };
      int length_size, pps_offset = 0;
  
! 
!     // NETINT: add processing when sidedata is available
!     if (side_data == NULL) {
!         bytestream2_init(gb, ctx->par_in->extradata, ctx->par_in->extradata_size);
!     } else {
!         bytestream2_init(gb, side_data, side_size);
!     }
!     // End of NETINT
  
      bytestream2_skipu(gb, 4);
  
***************
*** 149,155 ****
          av_log(ctx, AV_LOG_VERBOSE,
                 "The input looks like it is Annex B already\n");
      } else if (extra_size >= 7) {
!         ret = h264_extradata_to_annexb(ctx, AV_INPUT_BUFFER_PADDING_SIZE);
          if (ret < 0)
              return ret;
  
--- 157,163 ----
          av_log(ctx, AV_LOG_VERBOSE,
                 "The input looks like it is Annex B already\n");
      } else if (extra_size >= 7) {
!         ret = h264_extradata_to_annexb(ctx, AV_INPUT_BUFFER_PADDING_SIZE, NULL, 0);//NETINT: extra 2 params
          if (ret < 0)
              return ret;
  
***************
*** 176,181 ****
--- 184,191 ----
      uint8_t *out;
      uint64_t out_size;
      int ret;
+     int side_size = 0; // NETINT for sequence changing
+     uint8_t *side = NULL;
  
      ret = ff_bsf_get_packet(ctx, &in);
      if (ret < 0)
***************
*** 188,193 ****
--- 198,214 ----
          return 0;
      }
  
+     // NETINT: check new extra data which maybe contains new header    
+     side = av_packet_get_side_data(in, AV_PKT_DATA_NEW_EXTRADATA, &side_size);
+     if (side) {
+         av_log(ctx, AV_LOG_TRACE, "h264_mp4toannexb_bsf found %d bytes of side data in pkt\n", side_size);
+         ret = h264_extradata_to_annexb(ctx, AV_INPUT_BUFFER_PADDING_SIZE, side, side_size);
+         if (ret < 0) {
+            av_log(ctx, AV_LOG_WARNING, "extra data parsing failed\n");
+         }
+     }
+     // end of NETINT
+ 
      buf_end  = in->data + in->size;
  
  #define LOG_ONCE(...) \
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/hevc.h FFmpeg-n4.3.1/libavcodec/hevc.h
*** base_ffmpeg_n4.3.1/libavcodec/hevc.h	2022-01-30 21:54:34.224205359 -0800
--- FFmpeg-n4.3.1/libavcodec/hevc.h	2021-11-04 21:55:58.351592756 -0700
***************
*** 50,55 ****
--- 50,57 ----
      HEVC_NAL_CRA_NUT        = 21,
      HEVC_NAL_RSV_IRAP_VCL22 = 22,
      HEVC_NAL_RSV_IRAP_VCL23 = 23,
+     // NETINT: duplicate old enumeration name for IRAP_VCL23
+     HEVC_NAL_IRAP_VCL23     = 23,
      HEVC_NAL_RSV_VCL24      = 24,
      HEVC_NAL_RSV_VCL25      = 25,
      HEVC_NAL_RSV_VCL26      = 26,
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/hevc_mp4toannexb_bsf.c FFmpeg-n4.3.1/libavcodec/hevc_mp4toannexb_bsf.c
*** base_ffmpeg_n4.3.1/libavcodec/hevc_mp4toannexb_bsf.c	2022-01-30 21:54:34.224205359 -0800
--- FFmpeg-n4.3.1/libavcodec/hevc_mp4toannexb_bsf.c	2021-09-13 14:19:52.152858778 -0700
***************
*** 37,43 ****
      int      extradata_parsed;
  } HEVCBSFContext;
  
! static int hevc_extradata_to_annexb(AVBSFContext *ctx)
  {
      GetByteContext gb;
      int length_size, num_arrays, i, j;
--- 37,44 ----
      int      extradata_parsed;
  } HEVCBSFContext;
  
! // NETINT: add argument side and side_size for sequence changing
! static int hevc_extradata_to_annexb(AVBSFContext *ctx, uint8_t *side, size_t side_size)
  {
      GetByteContext gb;
      int length_size, num_arrays, i, j;
***************
*** 46,52 ****
      uint8_t *new_extradata = NULL;
      size_t   new_extradata_size = 0;
  
!     bytestream2_init(&gb, ctx->par_in->extradata, ctx->par_in->extradata_size);
  
      bytestream2_skip(&gb, 21);
      length_size = (bytestream2_get_byte(&gb) & 3) + 1;
--- 47,59 ----
      uint8_t *new_extradata = NULL;
      size_t   new_extradata_size = 0;
  
!     // NETINT: add processing when sidedata is available 
!     if (side == NULL) {
!         bytestream2_init(&gb, ctx->par_in->extradata, ctx->par_in->extradata_size);
!     } else {
!         bytestream2_init(&gb, side, side_size);
!     }
!     // End of NETINT
  
      bytestream2_skip(&gb, 21);
      length_size = (bytestream2_get_byte(&gb) & 3) + 1;
***************
*** 106,112 ****
          av_log(ctx, AV_LOG_VERBOSE,
                 "The input looks like it is Annex B already\n");
      } else {
!         ret = hevc_extradata_to_annexb(ctx);
          if (ret < 0)
              return ret;
          s->length_size      = ret;
--- 113,119 ----
          av_log(ctx, AV_LOG_VERBOSE,
                 "The input looks like it is Annex B already\n");
      } else {
!         ret = hevc_extradata_to_annexb(ctx, NULL, 0); //NETINT: extra 2 params
          if (ret < 0)
              return ret;
          s->length_size      = ret;
***************
*** 124,129 ****
--- 131,141 ----
  
      int got_irap = 0;
      int i, ret = 0;
+     // NetInt don't prepend extradata to IRAP frames if VPS/SPS/PPS already
+     // in the packet
+     int has_header = 0, has_vps = 0, has_sps = 0, has_pps = 0;
+     int side_size = 0; // NETINT: for sequence changing
+     uint8_t *side = NULL;
  
      ret = ff_bsf_get_packet(ctx, &in);
      if (ret < 0)
***************
*** 135,140 ****
--- 147,162 ----
          return 0;
      }
  
+     // NETINT: check new extra data which maybe contains new header    
+     side = av_packet_get_side_data(in, AV_PKT_DATA_NEW_EXTRADATA, &side_size);
+     if (side) {
+         ret = hevc_extradata_to_annexb(ctx, side, side_size);
+         if (ret < 0) {
+             av_log(ctx, AV_LOG_WARNING, "extra data parsing failed\n");
+         }
+     }
+     // end of NETINT
+ 
      bytestream2_init(&gb, in->data, in->size);
  
      while (bytestream2_get_bytes_left(&gb)) {
***************
*** 155,164 ****
          }
  
          nalu_type = (bytestream2_peek_byte(&gb) >> 1) & 0x3f;
  
          /* prepend extradata to IRAP frames */
          is_irap       = nalu_type >= 16 && nalu_type <= 23;
!         add_extradata = is_irap && !got_irap;
          extra_size    = add_extradata * ctx->par_out->extradata_size;
          got_irap     |= is_irap;
  
--- 177,190 ----
          }
  
          nalu_type = (bytestream2_peek_byte(&gb) >> 1) & 0x3f;
+         has_vps |= (HEVC_NAL_VPS == nalu_type);
+         has_sps |= (HEVC_NAL_SPS == nalu_type);
+         has_pps |= (HEVC_NAL_PPS == nalu_type);
+         has_header = (has_vps && has_sps && has_pps);
  
          /* prepend extradata to IRAP frames */
          is_irap       = nalu_type >= 16 && nalu_type <= 23;
!         add_extradata = is_irap && !has_header && !got_irap;
          extra_size    = add_extradata * ctx->par_out->extradata_size;
          got_irap     |= is_irap;
  
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/Makefile FFmpeg-n4.3.1/libavcodec/Makefile
*** base_ffmpeg_n4.3.1/libavcodec/Makefile	2022-01-30 21:54:34.172204617 -0800
--- FFmpeg-n4.3.1/libavcodec/Makefile	2021-09-13 14:19:52.152858778 -0700
***************
*** 17,22 ****
--- 17,23 ----
            dxva2.h                                                       \
            jni.h                                                         \
            mediacodec.h                                                  \
+           ni_hevc_extradata.h                                           \
            packet.h                                                      \
            qsv.h                                                         \
            vaapi.h                                                       \
***************
*** 46,54 ****
         jni.o                                                            \
         mathtables.o                                                     \
         mediacodec.o                                                     \
         mpeg12framerate.o                                                \
         options.o                                                        \
-        mjpegenc_huffman.o                                               \
         parser.o                                                         \
         parsers.o                                                        \
         profiles.o                                                       \
--- 47,56 ----
         jni.o                                                            \
         mathtables.o                                                     \
         mediacodec.o                                                     \
+        mjpegenc_huffman.o                                               \
         mpeg12framerate.o                                                \
+        ni_hevc_extradata.o                                              \
         options.o                                                        \
         parser.o                                                         \
         parsers.o                                                        \
         profiles.o                                                       \
***************
*** 376,381 ****
--- 378,387 ----
  OBJS-$(CONFIG_H264_V4L2M2M_ENCODER)    += v4l2_m2m_enc.o
  OBJS-$(CONFIG_HAP_DECODER)             += hapdec.o hap.o
  OBJS-$(CONFIG_HAP_ENCODER)             += hapenc.o hap.o
+ OBJS-$(CONFIG_H264_NI_DECODER)         += nidec_h264.o nicodec.o nidec.o
+ OBJS-$(CONFIG_H265_NI_DECODER)         += nidec_hevc.o nicodec.o nidec.o
+ OBJS-$(CONFIG_H265_NI_ENCODER)         += nienc_hevc.o nicodec.o nienc.o
+ OBJS-$(CONFIG_H264_NI_ENCODER)         += nienc_h264.o nicodec.o nienc.o
  OBJS-$(CONFIG_HCA_DECODER)             += hcadec.o
  OBJS-$(CONFIG_HCOM_DECODER)            += hcom.o
  OBJS-$(CONFIG_HEVC_DECODER)            += hevcdec.o hevc_mvs.o \
***************
*** 1116,1123 ****
--- 1122,1132 ----
  OBJS-$(CONFIG_H264_MP4TOANNEXB_BSF)       += h264_mp4toannexb_bsf.o
  OBJS-$(CONFIG_H264_REDUNDANT_PPS_BSF)     += h264_redundant_pps_bsf.o
  OBJS-$(CONFIG_HAPQA_EXTRACT_BSF)          += hapqa_extract_bsf.o hap.o
+ OBJS-$(CONFIG_HEVC_FRAME_SPLIT_BSF)       += ni_hevc_frame_split_bsf.o ni_hevc_rbsp.o
  OBJS-$(CONFIG_HEVC_METADATA_BSF)          += h265_metadata_bsf.o h265_profile_level.o
  OBJS-$(CONFIG_HEVC_MP4TOANNEXB_BSF)       += hevc_mp4toannexb_bsf.o
+ OBJS-$(CONFIG_HEVC_RAWTOTILE_BSF)         += ni_hevc_rawtotile_bsf.o ni_hevc_rbsp.o
+ OBJS-$(CONFIG_HEVC_TILE_REPACK_BSF)       += ni_hevc_tile_repack_bsf.o
  OBJS-$(CONFIG_IMX_DUMP_HEADER_BSF)        += imx_dump_header_bsf.o
  OBJS-$(CONFIG_MJPEG2JPEG_BSF)             += mjpeg2jpeg_bsf.o
  OBJS-$(CONFIG_MJPEGA_DUMP_HEADER_BSF)     += mjpega_dump_header_bsf.o
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/nicodec.c FFmpeg-n4.3.1/libavcodec/nicodec.c
*** base_ffmpeg_n4.3.1/libavcodec/nicodec.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/nicodec.c	2022-01-30 21:44:04.789494519 -0800
***************
*** 0 ****
--- 1,1947 ----
+ /*
+  * XCoder Codec Lib Wrapper
+  * Copyright (c) 2018 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ /**
+  * @file
+  * XCoder codec lib wrapper.
+  */
+ 
+ #include <ni_rsrc_api.h>
+ #include "nicodec.h"
+ #include "nidec.h"
+ #include "libavutil/pixdesc.h"
+ #include "libavutil/imgutils.h"
+ #include "libavutil/mastering_display_metadata.h"
+ #include "libavutil/hdr_dynamic_metadata.h"
+ #include "get_bits.h"
+ #include "internal.h"
+ #include "libavutil/intreadwrite.h"
+ #include "libavcodec/hevc.h"
+ #include "libavcodec/hevc_sei.h"
+ #include "libavcodec/h264.h"
+ #include "libavcodec/h264_sei.h"
+ #include "libavutil/hwcontext.h"
+ #include "libavutil/hwcontext_internal.h"
+ #include "libavutil/hwcontext_ni.h"
+ 
+ 
+ static inline void ni_buf_pool_free(void *opaque, uint8_t *data)
+ {
+   if (data)
+   {
+     ni_buf_t *buf = (ni_buf_t *)opaque;
+     ni_decoder_frame_buffer_pool_return_buf(buf, (ni_buf_pool_t *)buf->pool);
+   }
+ }
+ 
+ static void ni_frame_free(void *opaque, uint8_t *data)
+ {
+   if (data)
+   {
+     ni_event_handle_t event_handle = (ni_event_handle_t) opaque;
+     ni_hwframe_surface_t* p_data3 = (ni_hwframe_surface_t*) data; //for hwframes there is no data0,1,2
+     //TODO use int32t device_handle to kill the buffer!
+     if (p_data3->i8FrameIdx != NI_INVALID_HW_FRAME_IDX)
+     {
+ #ifdef _WIN32
+       int64_t handle = (((int64_t) p_data3->device_handle_ext) << 32) | p_data3->device_handle;
+       ni_decode_buffer_free(p_data3, (ni_device_handle_t) handle, event_handle);
+ #else
+       ni_decode_buffer_free(p_data3, p_data3->device_handle, event_handle);
+ #endif
+     }
+     free(p_data3);
+   }
+ }
+ 
+ static inline void ni_align_free_nop(void *opaque, uint8_t *data)
+ {
+ }
+ 
+ static inline void ni_free(void *opaque, uint8_t *data)
+ {
+   free(data);
+ }
+ 
+ int ff_xcoder_dec_init(AVCodecContext *avctx,
+                        XCoderH264DecContext *s)
+ {
+   /* ToDo: call xcode_dec_open to open a decoder instance */
+   int ret;
+   ni_encoder_params_t *p_param = &s->api_param;
+ 
+   s->api_ctx.hw_id = s->dev_dec_idx;
+   s->api_ctx.decoder_low_delay = s->low_delay;
+   strcpy(s->api_ctx.dev_xcoder, s->dev_xcoder);
+ 
+   ret = ni_device_session_open(&s->api_ctx, NI_DEVICE_TYPE_DECODER);
+   if (ret != 0)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Failed to open decoder (status = %d), "
+            "resource unavailable\n", ret);
+     ret = AVERROR_EXTERNAL;
+     ff_xcoder_dec_close(avctx, s);
+   }
+   else
+   {
+     s->dev_xcoder_name = s->api_ctx.dev_xcoder_name;
+     s->blk_xcoder_name = s->api_ctx.blk_xcoder_name;
+     s->dev_dec_idx = s->api_ctx.hw_id;
+     av_log(avctx, AV_LOG_VERBOSE, "XCoder %s Index %d (inst: %d) opened successfully\n",
+            s->dev_xcoder_name, s->dev_dec_idx, s->api_ctx.session_id);
+ 
+     if (s->hwFrames || p_param->dec_input_params.hwframes)
+     {
+       if (!avctx->hw_device_ctx)
+       {
+         av_log(avctx, AV_LOG_DEBUG, "nicodec.c:ff_xcoder_dec_init() hwdevice_ctx_create\n");
+ 
+         av_hwdevice_ctx_create(&avctx->hw_device_ctx, AV_HWDEVICE_TYPE_NI, NULL, NULL, 0); //create with null device
+       }
+       if (!avctx->hw_frames_ctx)
+       {
+         avctx->hw_frames_ctx = av_hwframe_ctx_alloc(avctx->hw_device_ctx);
+ 
+         if (!avctx->hw_frames_ctx)
+         {
+           ret = AVERROR(ENOMEM);
+           return ret;
+         }
+       }
+       s->hwfc = (AVHWFramesContext*)avctx->hw_frames_ctx->data;
+ 
+       s->hwfc->format = AV_PIX_FMT_NI;
+       s->hwfc->width = avctx->width;
+       s->hwfc->height = avctx->height;
+ 
+       s->hwfc->sw_format = avctx->sw_pix_fmt;
+       s->hwfc->initial_pool_size = -1; //Decoder has its own dedicated pool
+ 
+       ret = av_hwframe_ctx_init(avctx->hw_frames_ctx);
+       avctx->pix_fmt = AV_PIX_FMT_NI;
+       s->api_ctx.hw_action = NI_CODEC_HW_ENABLE;
+     }
+     else
+     {
+       avctx->pix_fmt = avctx->sw_pix_fmt; //reassign in case above conditions alter value
+       s->api_ctx.hw_action = NI_CODEC_HW_NONE;//
+     }
+   }
+ 
+   return ret;
+ }
+ 
+ int ff_xcoder_dec_close(AVCodecContext *avctx,
+                         XCoderH264DecContext *s)
+ {
+   AVHWFramesContext *ctx;
+   NIFramesContext *dst_ctx;
+   ni_retcode_t ret = NI_RETCODE_FAILURE;
+   ni_encoder_params_t *p_param = &s->api_param; //dec params in union with enc params struct
+ 
+   ret = ni_device_session_close(&s->api_ctx, s->eos, NI_DEVICE_TYPE_DECODER);
+   if (NI_RETCODE_SUCCESS != ret)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Failed to close Decode Session (status = %d)\n", ret);
+   }
+ 
+   if (p_param->dec_input_params.hwframes)
+   {
+ #if 1//def XCODER_IO_RW_ENABLED // asume always enable XCODER_IO_RW_ENABLED
+     av_log(avctx, AV_LOG_VERBOSE, "File BLK handle %d close suspended to frames Uninit\n", s->api_ctx.blk_io_handle); //suspended_device_handle
+     ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;
+     dst_ctx = ctx->internal->priv;
+     dst_ctx->suspended_device_handle = s->api_ctx.blk_io_handle;
+ #else
+     av_log(avctx, AV_LOG_VERBOSE, "File handle %d close suspended to frames Uninit\n", s->api_ctx.device_handle); //suspended_device_handle
+     AVHWFramesContext *ctx;
+     NIFramesContext *dst_ctx;
+     ctx = (AVHWFramesContext*)avctx->hw_frames_ctx->data;
+     dst_ctx = ctx->internal->priv;
+     dst_ctx->suspended_device_handle = s->api_ctx.device_handle;
+ #endif
+ 
+ #ifdef __linux__
+ #if 1//def XCODER_IO_RW_ENABLED
+     ni_device_close(s->api_ctx.device_handle);
+ #else
+     ni_device_close(s->api_ctx.blk_io_handle);
+ #endif
+ #endif
+   }
+   else
+   {
+ #ifdef _WIN32
+     ni_device_close(s->api_ctx.device_handle);
+ #elif __linux__
+     ni_device_close(s->api_ctx.device_handle);
+     ni_device_close(s->api_ctx.blk_io_handle);
+ #endif
+   }
+ 
+   s->api_ctx.device_handle = NI_INVALID_DEVICE_HANDLE;
+   s->api_ctx.blk_io_handle = NI_INVALID_DEVICE_HANDLE;
+ 
+   return 0;
+ }
+ 
+ /*!******************************************************************************
+  *  \brief  Extract custom sei payload data from AVPacket,
+  *  and save it to ni_packet_t
+  *
+  *  \param AVCodecContext *avctx - avcodec context
+  *  \param AVPacket *pkt - AVPacket
+  *  \param int start_index - pkt data index of custom sei first byte after SEI type
+  *  \param ni_packet_t *p_packet - netint internal packet
+  *  \param uint8_t sei_type - type of SEI
+  *  \param int got_slice - whether got vcl in the pkt data, 1 means got
+  *
+  *  \return - 0 on success, non-0 on failure
+  *******************************************************************************/
+ static int ff_xcoder_extract_custom_sei(AVCodecContext *avctx, AVPacket *pkt, int start_index,
+                                         ni_packet_t *p_packet, uint8_t sei_type, int got_slice)
+ {
+   int i;
+   uint8_t *udata;
+   uint8_t *sei_data;
+   int len = 0;
+   int sei_size = 0; // default is 0
+   int index = start_index;
+   int sei_index = 0;
+ 
+   av_log(avctx, AV_LOG_TRACE, "%s() enter\n", __FUNCTION__);
+   if (p_packet->p_all_custom_sei == NULL)
+   {
+     /* max size */
+     p_packet->p_all_custom_sei = (ni_all_custom_sei_t *)malloc(sizeof(ni_all_custom_sei_t));
+     if (p_packet->p_all_custom_sei == NULL)
+     {
+       av_log(avctx, AV_LOG_ERROR, "failed to allocate all custom sei buffer.\n");
+       return AVERROR(ENOMEM);
+     }
+     memset(p_packet->p_all_custom_sei, 0, sizeof(ni_custom_sei_t));
+   }
+ 
+   sei_index = p_packet->p_all_custom_sei->custom_sei_cnt;
+   if (sei_index >= NI_MAX_CUSTOM_SEI_CNT)
+   {
+     av_log(avctx, AV_LOG_WARNING, "number of custom sei in current frame is out of limit(%d).\n",
+            NI_MAX_CUSTOM_SEI_CNT);
+     return AVERROR(EINVAL);
+   }
+   sei_data = p_packet->p_all_custom_sei->ni_custom_sei[sei_index].custom_sei_data;
+ 
+   /*! extract SEI payload size.
+    *  the first byte after SEI type is the SEI payload size.
+    *  if the first byte is 255(0xFF), it means the SEI payload size is more than 255.
+    *  in this case, to get the SEI payload size is to do a summation.
+    *  the end of SEI size is the first non-0xFF value.
+    *  for example, 0xFF 0xFF 0x08, the SEI payload size equals to (0xFF+0xFF+0x08).
+    */
+   while ((index < pkt->size) && (pkt->data[index] == 255))
+   {
+     sei_size += pkt->data[index++];
+   }
+ 
+   if (index >= pkt->size)
+   {
+     av_log(avctx, AV_LOG_WARNING, "custom sei corrupted: length truncated.\n");
+     return AVERROR(EINVAL);
+   }
+   sei_size += pkt->data[index++];
+ 
+   /* check sei size*/
+   if (sei_size > NI_MAX_CUSTOM_SEI_SZ)
+   {
+     av_log(avctx, AV_LOG_WARNING, "custom sei corrupted: size(%d) out of limit(%d).\n",
+            sei_size, NI_MAX_CUSTOM_SEI_SZ);
+     return AVERROR(EINVAL);
+   }
+ 
+   udata = &pkt->data[index];
+ 
+   /* extract SEI payload data
+    * SEI payload data in NAL is EBSP(Encapsulated Byte Sequence Payload),
+    * need change EBSP to RBSP(Raw Byte Sequence Payload) for exact size
+   */
+   for (i = 0; (i < (pkt->size - index)) && len < sei_size; i++)
+   {
+     /* if the latest 3-byte data pattern matchs '00 00 03' which means udata[i] is an escaping byte,
+      * discard udata[i]. */
+     if (i >= 2 && udata[i - 2] == 0 && udata[i - 1] == 0 && udata[i] == 3)
+     {
+       continue;
+     }
+     sei_data[len++] = udata[i];
+   }
+ 
+   if (len != sei_size)
+   {
+     av_log(avctx, AV_LOG_WARNING, "custom sei corrupted: data truncated, "
+            "requied size:%d, actual size:%d.\n", sei_size, len);
+     return AVERROR(EINVAL);
+   }
+ 
+   p_packet->p_all_custom_sei->ni_custom_sei[sei_index].custom_sei_size = sei_size;
+   p_packet->p_all_custom_sei->ni_custom_sei[sei_index].custom_sei_type = sei_type;
+   if (got_slice)
+   {
+     p_packet->p_all_custom_sei->ni_custom_sei[sei_index].custom_sei_loc = NI_CUSTOM_SEI_LOC_AFTER_VCL;
+   }
+   else
+   {
+     p_packet->p_all_custom_sei->ni_custom_sei[sei_index].custom_sei_loc = NI_CUSTOM_SEI_LOC_BEFORE_VCL;
+   }
+   p_packet->p_all_custom_sei->custom_sei_cnt ++;
+   av_log(avctx, AV_LOG_TRACE, "%s() exit, custom_sei_cnt=%d, size=%d type=%d\n",
+          __FUNCTION__, p_packet->p_all_custom_sei->custom_sei_cnt, sei_size, sei_type);
+ 
+   return 0;
+ }
+ 
+ /*!******************************************************************************
+  *  \brief  detect custom SEI payload data in AVPacket data,
+  *          custom SEI has two meanings:
+  *          a. the SEI type is not in the standard protocol, which is added by customes,
+  *             for example SEI type 100, note that custom SEI is not user data unregistered SEI.
+  *          b. the SEI NAL location does not conform to protocol. It's after VCL NALs.
+  *          So there are cases to handle here:
+  *          case a: enable custom_sei, detext custom SEIs before VCL.
+  *          case b: enable custom_sei and enable_check_packet, detect custom SEIs before VCL,
+  *                  and all SEIs after VCL.
+  *          all of these SEIs are passthroughed in the same places after encoding.
+  *
+  *  \param AVCodecContext *avctx - avcodec context
+  *  \param XCoderH264DecContext *s - netint decoder context
+  *  \param AVPacket *pkt - AVPacket
+  *  \param int start_index - pkt data index of custom sei first byte after SEI type
+  *  \param ni_packet_t *p_packet - netint internal packet
+  *
+  *  \return - 0 on success or not detect correct custom sei, non-0 on failure
+  *******************************************************************************/
+ static int ff_xcoder_detect_custom_sei(AVCodecContext *avctx, XCoderH264DecContext *s,
+                                        AVPacket *pkt, ni_packet_t *p_packet)
+ {
+   int ret = 0;
+   const uint8_t *ptr = NULL;
+   const uint8_t *end = NULL;
+   uint8_t custom_sei_type = s->custom_sei;
+   uint8_t chk_pkt = s->enable_check_packet;
+   uint8_t nalu_type;
+   uint8_t sei_type;
+   uint32_t stc = -1;
+   int got_slice = 0;
+ 
+   av_log(avctx, AV_LOG_TRACE, "%s(): custom SEI type %d\n", __FUNCTION__, custom_sei_type);
+ 
+   if (!pkt->data || !avctx)
+   {
+     return ret;
+   }
+ 
+   // search custom sei in the lone buffer
+   // if there is a custom sei in the lone sei, the firmware can't recoginze it.
+   // passthrough the custom sei here.
+   if (s->api_ctx.lone_sei_size)
+   {
+     av_log(avctx, AV_LOG_TRACE, "%s(): detect in lone SEI, size=%d\n",
+            __FUNCTION__, s->api_ctx.lone_sei_size);
+     ptr = s->api_ctx.buf_lone_sei;
+     end = s->api_ctx.buf_lone_sei + s->api_ctx.lone_sei_size;
+     stc = -1;
+     ptr = avpriv_find_start_code(ptr, end, &stc);
+     while (ptr < end)
+     {
+       if (avctx->codec_id == AV_CODEC_ID_H264)
+       { // if h264
+         nalu_type = stc & 0x1F;
+         sei_type = *ptr;
+         if ((nalu_type == H264_NAL_SEI) && (sei_type == custom_sei_type))
+         {
+           /* extract SEI payload, store in ni_packet and pass to libxcoder. */
+           ret = ff_xcoder_extract_custom_sei(avctx, pkt, ptr + 1 - pkt->data, p_packet, sei_type, got_slice);
+           if (ret == AVERROR(ENOMEM))
+           {
+             return ret;
+           }
+           else if (ret != 0)
+           {
+             if ((p_packet->p_all_custom_sei) && (p_packet->p_all_custom_sei->custom_sei_cnt == 0))
+             {
+               free(p_packet->p_all_custom_sei);
+               p_packet->p_all_custom_sei = NULL;
+             }
+             return 0;
+           }
+         }
+       }
+       else if (avctx->codec_id == AV_CODEC_ID_HEVC)
+       { //if hevc
+         nalu_type = (stc >> 1) & 0x3F;
+         sei_type = *(ptr + 1);
+         // check nalu_type, check nuh_temporal_id_plus1 = 1, check sei_pype
+         if ((nalu_type == HEVC_NAL_SEI_PREFIX) && (*ptr == 1) && (sei_type == custom_sei_type))
+         {
+           /* extract SEI payload, store in ni_packet and pass to libxcoder. */
+           ret = ff_xcoder_extract_custom_sei(avctx, pkt, ptr + 2 - pkt->data, p_packet, sei_type, got_slice);
+           if (ret == AVERROR(ENOMEM))
+           {
+             return ret;
+           }
+           else if (ret != 0)
+           {
+             if ((p_packet->p_all_custom_sei) && (p_packet->p_all_custom_sei->custom_sei_cnt == 0))
+             {
+               free(p_packet->p_all_custom_sei);
+               p_packet->p_all_custom_sei = NULL;
+             }
+             return 0;
+           }
+         }
+       }
+       else
+       {
+         av_log(avctx, AV_LOG_ERROR, "%s wrong codec %d !\n", __FUNCTION__,
+                avctx->codec_id);
+         break;
+       }
+ 
+       stc = -1;
+       ptr = avpriv_find_start_code(ptr, end, &stc);
+     }
+   }
+ 
+   // search custom sei in the packet
+   av_log(avctx, AV_LOG_TRACE, "%s(): detect in packet, size=%d\n",
+          __FUNCTION__, pkt->size);
+   ptr = pkt->data;
+   end = pkt->data + pkt->size;
+   stc = -1;
+   ptr = avpriv_find_start_code(ptr, end, &stc);
+   while (ptr < end)
+   {
+     if (avctx->codec_id == AV_CODEC_ID_H264)
+     { // if h264
+       nalu_type = stc & 0x1F;
+       sei_type = *ptr;
+       if ((nalu_type == H264_NAL_SEI) &&
+           ((sei_type == custom_sei_type) || (got_slice && chk_pkt)))
+       {
+         /* extract SEI payload, store in ni_packet and pass to libxcoder. */
+         ret = ff_xcoder_extract_custom_sei(avctx, pkt, ptr + 1 - pkt->data, p_packet, sei_type, got_slice);
+         if (ret == AVERROR(ENOMEM))
+         {
+           return ret;
+         }
+         else if (ret != 0)
+         {
+           return 0;
+         }
+       }
+       else if ((nalu_type >= H264_NAL_SLICE) && (nalu_type <= H264_NAL_IDR_SLICE)) //VCL
+       {
+         ret = 0;
+         got_slice = 1;
+         /* if disable check packet and VCL is found, then stop searching for SEI after VCL. */
+         if (!chk_pkt)
+         {
+           break;
+         }
+       }
+     }
+     else if (avctx->codec_id == AV_CODEC_ID_HEVC)
+     { //if hevc
+       nalu_type = (stc >> 1) & 0x3F;
+       sei_type = *(ptr + 1);
+       // check nalu_type, check nuh_temporal_id_plus1 = 1, check sei_pype
+       // if enable chk_pkt, continue search SEI after VCL
+       if ((nalu_type == HEVC_NAL_SEI_PREFIX) && (*ptr == 1) &&
+           ((sei_type == custom_sei_type) || (got_slice && chk_pkt)))
+       {
+         /* extract SEI payload, store in ni_packet and pass to libxcoder. */
+         ret = ff_xcoder_extract_custom_sei(avctx, pkt, ptr + 2 - pkt->data, p_packet, sei_type, got_slice);
+         if (ret == AVERROR(ENOMEM))
+         {
+           return ret;
+         }
+         else if (ret != 0)
+         {
+           return 0;
+         }
+       }
+       else if (nalu_type >= HEVC_NAL_TRAIL_N && nalu_type <= HEVC_NAL_RSV_VCL31) //found VCL
+       {
+         ret = 0;
+         got_slice = 1;
+         /* if disable check packet and VCL is found, then stop searching for SEI after VCL. */
+         if (!chk_pkt)
+         {
+           break;
+         }
+       }
+     }
+     else
+     {
+       av_log(avctx, AV_LOG_ERROR, "%s wrong codec %d !\n", __FUNCTION__,
+              avctx->codec_id);
+       break;
+     }
+ 
+     stc = -1;
+     ptr = avpriv_find_start_code(ptr, end, &stc);
+   }
+ 
+   if (p_packet->p_all_custom_sei)
+   {
+     av_log(avctx, AV_LOG_TRACE, "%s(): total custom SEI number %d\n", __FUNCTION__,
+           p_packet->p_all_custom_sei->custom_sei_cnt);
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_TRACE, "%s(): no custom SEI detected\n", __FUNCTION__);
+   }
+ 
+   return ret;
+ }
+ 
+ // return 1 if need to prepend saved header to pkt data, 0 otherwise
+ int ff_xcoder_add_headers(AVCodecContext *avctx, AVPacket *pkt)
+ {
+   XCoderH264DecContext *s = avctx->priv_data;
+   int ret = 0;
+   const uint8_t *ptr = pkt->data;
+   const uint8_t *end = pkt->data + pkt->size;
+   uint32_t stc = -1;
+   uint8_t nalu_type = 0;
+ 
+   if (!pkt->data || !avctx)
+   {
+     return ret;
+   }
+ 
+   while (ptr < end)
+   {
+     stc = -1;
+     ptr = avpriv_find_start_code(ptr, end, &stc);
+     if (ptr == end)
+     {
+       break;
+     }
+ 
+     if (AV_CODEC_ID_H264 == avctx->codec_id)
+     {
+       nalu_type = stc & 0x1F;
+ 
+       // update saved header if it has changed
+       if (s->got_first_idr && H264_NAL_IDR_SLICE == nalu_type)
+       {
+         if (s->extradata_size != avctx->extradata_size ||
+             memcmp(s->extradata, avctx->extradata, s->extradata_size))
+         {
+           s->got_first_idr = 0;
+         }
+       }
+ 
+       if (! s->got_first_idr && H264_NAL_IDR_SLICE == nalu_type)
+       {
+         free(s->extradata);
+         s->extradata = malloc(avctx->extradata_size);
+         if (! s->extradata)
+         {
+           av_log(avctx, AV_LOG_ERROR, "%s memory allocation failed !\n", __FUNCTION__);
+           ret = 0;
+           break;
+         }
+         av_log(avctx, AV_LOG_TRACE, "%s size %d\n",
+                __FUNCTION__, avctx->extradata_size);
+         memcpy(s->extradata, avctx->extradata, avctx->extradata_size);
+         s->extradata_size = avctx->extradata_size;
+         s->got_first_idr = 1;
+         ret = 1;
+         break;
+       }
+ 
+       // when header (SPS/PPS) already exists, no need to prepend it again;
+       // we use one of the header info to simplify the checking.
+       if (H264_NAL_SPS == nalu_type || H264_NAL_PPS == nalu_type)
+       {
+         // save the header if not done yet for subsequent comparison
+         if (! s->extradata_size || ! s->extradata)
+         {
+           s->extradata = malloc(avctx->extradata_size);
+           if (! s->extradata)
+           {
+             av_log(avctx, AV_LOG_ERROR, "%s memory allocation failed !\n",
+                    __FUNCTION__);
+             ret = 0;
+             break;
+           }
+           av_log(avctx, AV_LOG_TRACE, "%s size %d\n", __FUNCTION__,
+                  avctx->extradata_size);
+           memcpy(s->extradata, avctx->extradata, avctx->extradata_size);
+           s->extradata_size = avctx->extradata_size;
+         }
+         s->got_first_idr = 1;
+         ret = 0;
+         break;
+       }
+       else if (nalu_type >= H264_NAL_SLICE && nalu_type <= H264_NAL_IDR_SLICE)
+       {
+         // VCL types results in no header inserted
+         ret = 0;
+         break;
+       }
+     }
+     else if (AV_CODEC_ID_HEVC == avctx->codec_id)
+     {
+       nalu_type = (stc >> 1) & 0x3F;
+ 
+       // IRAP picture types include: BLA, CRA, IDR and IRAP reserve types,
+       // 16-23, and insert header in front of IRAP at start or if header changes
+       if (s->got_first_idr && (nalu_type >= HEVC_NAL_BLA_W_LP &&
+                                nalu_type <= HEVC_NAL_IRAP_VCL23))
+       {
+         if (s->extradata_size != avctx->extradata_size ||
+             memcmp(s->extradata, avctx->extradata, s->extradata_size))
+         {
+           s->got_first_idr = 0;
+         }
+       }
+ 
+       if (! s->got_first_idr && (nalu_type >= HEVC_NAL_BLA_W_LP &&
+                                  nalu_type <= HEVC_NAL_IRAP_VCL23))
+       {
+         free(s->extradata);
+         s->extradata = malloc(avctx->extradata_size);
+         if (! s->extradata)
+         {
+           av_log(avctx, AV_LOG_ERROR, "%s memory allocation failed !\n",
+                  __FUNCTION__);
+           ret = 0;
+           break;
+         }
+         av_log(avctx, AV_LOG_TRACE, "%s size %d\n",
+                __FUNCTION__, avctx->extradata_size);
+         memcpy(s->extradata, avctx->extradata, avctx->extradata_size);
+         s->extradata_size = avctx->extradata_size;
+         s->got_first_idr = 1;
+         ret = 1;
+         break;
+       }
+ 
+       // when header (VPS/SPS/PPS) already exists, no need to prepend it again;
+       // we use one of the header info to simplify the checking.
+       if (HEVC_NAL_VPS == nalu_type || HEVC_NAL_SPS == nalu_type ||
+           HEVC_NAL_PPS == nalu_type)
+       {
+         // save the header if not done yet for subsequent comparison
+         if (! s->extradata_size || ! s->extradata)
+         {
+           s->extradata = malloc(avctx->extradata_size);
+           if (! s->extradata)
+           {
+             av_log(avctx, AV_LOG_ERROR, "%s memory allocation failed !\n",
+                    __FUNCTION__);
+             ret = 0;
+             break;
+           }
+           av_log(avctx, AV_LOG_TRACE, "%s size %d\n",
+                  __FUNCTION__, avctx->extradata_size);
+           memcpy(s->extradata, avctx->extradata, avctx->extradata_size);
+           s->extradata_size = avctx->extradata_size;
+         }
+         s->got_first_idr = 1;
+         ret = 0;
+         break;
+       }
+       else if (nalu_type >= HEVC_NAL_TRAIL_N && nalu_type <= HEVC_NAL_RSV_VCL31)
+       {
+         // VCL types results in no header inserted
+         ret = 0;
+         break;
+       }
+     }
+     else
+     {
+       av_log(avctx, AV_LOG_ERROR, "%s wrong codec %d!\n",
+              __FUNCTION__, avctx->codec_id);
+       break;
+     }
+   }
+   return ret;
+ }
+ 
+ // check if the packet is SEI only, 1 yes, 0 otherwise
+ // check if getting the header of streams in decoder low delay mode, and update its value
+ // check the new sequence headers and cache them.
+ static int xcoder_packet_parse(AVCodecContext *avctx, XCoderH264DecContext *s,
+                                AVPacket *pkt, ni_packet_t *p_packet)
+ {
+   int pkt_sei_alone = 0;
+   int got_slice = 0;
+   int low_delay = s->low_delay;
+   int pkt_nal_bitmap = 0;
+   int chk_pkt = s->enable_check_packet;
+   const uint8_t *ptr = pkt->data;
+   const uint8_t *end = pkt->data + pkt->size;
+   uint32_t stc = -1;
+   uint8_t nalu_type = 0;
+   int nalu_count = 0;
+ 
+   if (!pkt->data || !avctx)
+   {
+     return pkt_sei_alone;
+   }
+ 
+   if (s->pkt_nal_bitmap & NI_GENERATE_ALL_NAL_HEADER_BIT)
+   {
+     av_log(avctx, AV_LOG_TRACE, "%s(): already find the header of streams.\n", __FUNCTION__);
+     low_delay = 0;
+   }
+ 
+   pkt_sei_alone = 1;
+   while ((pkt_sei_alone || low_delay || chk_pkt) && (ptr < end))
+   {
+     stc = -1;
+     ptr = avpriv_find_start_code(ptr, end, &stc);
+     if (ptr == end)
+     {
+       if (0 == nalu_count)
+       {
+         pkt_sei_alone = 0;
+         av_log(avctx, AV_LOG_TRACE, "%s(): no NAL found in pkt.\n", __FUNCTION__);
+       }
+       break;
+     }
+     nalu_count++;
+ 
+     if (AV_CODEC_ID_H264 == avctx->codec_id)
+     {
+       nalu_type = stc & 0x1F;
+ 
+       //check whether the packet is sei alone
+       pkt_sei_alone = (pkt_sei_alone && H264_NAL_SEI == nalu_type);
+ 
+       //check whether the packet contains SEI NAL after VCL NAL units
+       if (got_slice && (H264_NAL_SEI == nalu_type))
+       {
+         chk_pkt = 0;
+         // 5 bytes = 3 bytes start code + 1 byte nal type(0x06) + 1 byte sei type
+         p_packet->len_of_sei_after_vcl = (end - ptr) + 5;
+         av_log(avctx, AV_LOG_TRACE, "%s(): found SEI NAL after VCL NAL, len = %d.\n",
+                __FUNCTION__, p_packet->len_of_sei_after_vcl);
+       }
+       else if ((nalu_type >= H264_NAL_SLICE) && (nalu_type <= H264_NAL_IDR_SLICE)) //VCL
+       {
+         got_slice = 1;
+       }
+ 
+       // FFmpeg stores a complete frame in each AVPacket. A complete frame
+       // includes headers, SEIs, video slices, and other NALs such as access
+       // unit delimiters, etc. The decoder expects a complete frame for each
+       // packet writing to the decoder. Otherwise it can cause all sorts of
+       // problems. However in some cases the first NALU could be unit delimiter
+       // so we need to force to check NALU split to collect all the headers in
+       // case of decoder VPU recovery.
+       switch (nalu_type)
+       {
+         case H264_NAL_SPS:
+           chk_pkt = 1;
+           pkt_nal_bitmap |= NI_NAL_SPS_BIT;
+           break;
+         case H264_NAL_PPS:
+           chk_pkt = 1;
+           pkt_nal_bitmap |= NI_NAL_PPS_BIT;
+           break;
+         case H264_NAL_SEI:
+         case H264_NAL_AUD:
+           chk_pkt = 1;
+           break;
+         default:
+           chk_pkt = s->enable_check_packet;
+           break;
+       }
+ 
+       // Set decoder low delay mode one-time.
+       if (pkt_nal_bitmap & (NI_NAL_SPS_BIT | NI_NAL_PPS_BIT))
+       {
+         av_log(avctx, AV_LOG_TRACE, "%s(): Detect SPS, PPS and IDR, enable "
+                "decoder low delay mode.\n", __FUNCTION__);
+         pkt_nal_bitmap |= NI_GENERATE_ALL_NAL_HEADER_BIT;
+         if (low_delay)
+         {
+           s->api_ctx.decoder_low_delay = low_delay;
+           low_delay = 0;
+         }
+ 
+         // Update cached packet including SPS+PPS+IDR slice. A complete frame
+         // needs to be cached for stream with intraPeriod = 0
+         if (pkt != &s->seq_hdr_pkt && got_slice)
+         {
+           av_packet_unref(&s->seq_hdr_pkt);
+           av_packet_ref(&s->seq_hdr_pkt, pkt);
+         }
+       }
+     }
+     else if (AV_CODEC_ID_HEVC == avctx->codec_id)
+     {
+       nalu_type = (stc >> 1) & 0x3F;
+ 
+       //check whether the packet is sei alone
+       pkt_sei_alone = (pkt_sei_alone && (HEVC_NAL_SEI_PREFIX == nalu_type ||
+                                          HEVC_NAL_SEI_SUFFIX == nalu_type));
+ 
+       //check whether the packet contains SEI NAL after VCL NAL units
+       if (got_slice && (HEVC_NAL_SEI_PREFIX == nalu_type || HEVC_NAL_SEI_SUFFIX == nalu_type))
+       {
+         chk_pkt = 0;
+         // 5 bytes = 3 bytes start code + 2 bytes nal type(0x4e 0x01)
+         p_packet->len_of_sei_after_vcl = (end - ptr) + 5;
+         av_log(avctx, AV_LOG_TRACE, "%s(): found SEI NAL after VCL NAL, len = %d.\n",
+                __FUNCTION__, p_packet->len_of_sei_after_vcl);
+       }
+       else if ((nalu_type >= HEVC_NAL_TRAIL_N) && (nalu_type <= HEVC_NAL_RSV_VCL31)) //VCL
+       {
+         got_slice = 1;
+       }
+ 
+       // FFmpeg stores a complete frame in each AVPacket. A complete frame
+       // includes headers, SEIs, video slices, and other NALs such as access
+       // unit delimiters, etc. The decoder expects a complete frame for each
+       // packet writing to the decoder. Otherwise it can cause all sorts of
+       // problems. However in some cases the first NALU could be unit delimiter
+       // so we need to force to check NALU split to collect all the headers in
+       // case of decoder VPU recovery.
+       switch (nalu_type)
+       {
+         case HEVC_NAL_VPS:
+           chk_pkt = 1;
+           pkt_nal_bitmap |= NI_NAL_VPS_BIT;
+           break;
+         case HEVC_NAL_SPS:
+           chk_pkt = 1;
+           pkt_nal_bitmap |= NI_NAL_SPS_BIT;
+           break;
+         case HEVC_NAL_PPS:
+           chk_pkt = 1;
+           pkt_nal_bitmap |= NI_NAL_PPS_BIT;
+           break;
+         case HEVC_NAL_AUD:
+         case HEVC_NAL_EOS_NUT:
+         case HEVC_NAL_EOB_NUT:
+         case HEVC_NAL_FD_NUT:
+         case HEVC_NAL_SEI_PREFIX:
+         case HEVC_NAL_SEI_SUFFIX:
+           chk_pkt = 1;
+           break;
+         default:
+           chk_pkt = s->enable_check_packet;
+           break;
+       }
+ 
+       // Set decoder low delay mode one-time.
+       if (pkt_nal_bitmap & (NI_NAL_VPS_BIT | NI_NAL_SPS_BIT | NI_NAL_PPS_BIT))
+       {
+         av_log(avctx, AV_LOG_TRACE, "%s(): Detect VPS, SPS, PPS and IDR, "
+                "enable decoder low delay mode.\n", __FUNCTION__);
+         pkt_nal_bitmap |= NI_GENERATE_ALL_NAL_HEADER_BIT;
+         if (low_delay)
+         {
+           s->api_ctx.decoder_low_delay = low_delay;
+           low_delay = 0;
+         }
+ 
+         // Update cached packet including VPS+SPS+PPS+IDR slice. A complete frame
+         // needs to be cached for stream with intraPeriod = 0
+         if (pkt != &s->seq_hdr_pkt && got_slice)
+         {
+           av_packet_unref(&s->seq_hdr_pkt);
+           av_packet_ref(&s->seq_hdr_pkt, pkt);
+         }
+       }
+     }
+     else
+     {
+       av_log(avctx, AV_LOG_ERROR, "%s() wrong codec %d !\n",
+              __FUNCTION__, avctx->codec_id);
+       pkt_sei_alone = 0;
+       break;
+     }
+   }
+ 
+   s->pkt_nal_bitmap |= pkt_nal_bitmap;
+   return pkt_sei_alone;
+ }
+ 
+ int ff_xcoder_dec_send(AVCodecContext *avctx,
+                        XCoderH264DecContext *s,
+                        AVPacket *pkt)
+ {
+   /* call ni_decoder_session_write to send compressed video packet to the decoder
+      instance */
+   int need_draining = 0;
+   size_t size;
+   ni_packet_t *xpkt = &s->api_pkt.data.packet;
+   int ret;
+   int sent;
+   int send_size = 0;
+   int new_packet = 0;
+   int extra_prev_size = 0;
+ 
+   size = pkt->size;
+ 
+   if (s->flushing)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Decoder is flushing and cannot accept new "
+                                 "buffer until all output buffers have been released\n");
+     return AVERROR_EXTERNAL;
+   }
+ 
+   if (pkt->size == 0)
+   {
+     need_draining = 1;
+     // Once VPU recovery, the s->draining can be lost during session reset.
+     // And so be s->eos in the last session read.
+     s->eos |= s->draining;
+   }
+ 
+   if (s->draining && s->eos)
+   {
+     av_log(avctx, AV_LOG_DEBUG, "Decoder is draining, eos\n");
+     return AVERROR_EOF;
+   }
+ 
+   if (xpkt->data_len == 0)
+   {
+     memset(xpkt, 0, sizeof(ni_packet_t));
+     xpkt->pts = pkt->pts;
+     xpkt->dts = pkt->dts;
+     //    xpkt->pos = pkt->pos;
+     xpkt->video_width = avctx->width;
+     xpkt->video_height = avctx->height;
+     xpkt->p_data = NULL;
+     xpkt->data_len = pkt->size;
+     xpkt->p_all_custom_sei = NULL;
+     xpkt->len_of_sei_after_vcl = 0;
+ 
+     if (avctx->extradata_size > 0 &&
+         (avctx->extradata_size != s->extradata_size) &&
+         ff_xcoder_add_headers(avctx, pkt))
+     {
+       if (avctx->extradata_size > s->api_ctx.max_nvme_io_size * 2)
+       {
+         av_log(avctx, AV_LOG_ERROR, "%s extradata_size %d exceeding max size "
+                "supported: %d\n", __FUNCTION__, avctx->extradata_size,
+                s->api_ctx.max_nvme_io_size * 2);
+       }
+       else
+       {
+         av_log(avctx, AV_LOG_DEBUG, "%s extradata_size %d copied to pkt start.\n",
+                __FUNCTION__, avctx->extradata_size);
+         s->api_ctx.prev_size = avctx->extradata_size;
+         memcpy(s->api_ctx.p_leftover, avctx->extradata, avctx->extradata_size);
+       }
+     }
+ 
+     if (s->low_delay && s->got_first_idr && !(s->pkt_nal_bitmap & NI_GENERATE_ALL_NAL_HEADER_BIT))
+     {
+       s->api_ctx.decoder_low_delay = s->low_delay;
+       s->pkt_nal_bitmap |= NI_GENERATE_ALL_NAL_HEADER_BIT;
+       av_log(avctx, AV_LOG_TRACE, "%s got first IDR in decoder low delay mode, "
+              "delay time %dms, pkt_nal_bitmap %d\n", __FUNCTION__, s->low_delay,
+              s->pkt_nal_bitmap);
+     }
+ 
+     // check if the packet is SEI only, save it to be sent with the next data frame.
+     // check if getting the header of streams in decoder low delay mode, and update its value.
+     // check if new sequence headers come and cache them.
+     if (xcoder_packet_parse(avctx, s, pkt, xpkt))
+     {
+       // skip the packet if it's corrupted and/or exceeding lone SEI buf size
+       if (pkt->size + s->api_ctx.lone_sei_size <= NI_MAX_SEI_DATA)
+       {
+         memcpy(s->api_ctx.buf_lone_sei + s->api_ctx.lone_sei_size,
+                pkt->data, pkt->size);
+         s->api_ctx.lone_sei_size += pkt->size;
+         av_log(avctx, AV_LOG_TRACE, "%s pkt lone SEI, saved, and return %d\n",
+                __FUNCTION__, pkt->size);
+       }
+       else
+       {
+         av_log(avctx, AV_LOG_WARNING, "lone SEI size %d > buf size %ld, "
+                "corrupted? skipped ..\n", pkt->size, NI_MAX_SEI_DATA);
+       }
+ 
+       xpkt->data_len = 0;
+       return pkt->size;
+     }
+ 
+     if (s->custom_sei != NI_INVALID_SEI_TYPE)
+     {
+       ret = ff_xcoder_detect_custom_sei(avctx, s, pkt, xpkt);
+       if (ret != 0)
+       {
+         goto fail;
+       }
+     }
+ 
+     // embed lone SEI saved previously (if any) to send to decoder
+     if (s->api_ctx.lone_sei_size)
+     {
+       av_log(avctx, AV_LOG_TRACE, "%s copy over lone SEI data size: %d\n",
+              __FUNCTION__, s->api_ctx.lone_sei_size);
+       memcpy((uint8_t *)s->api_ctx.p_leftover + s->api_ctx.prev_size,
+              s->api_ctx.buf_lone_sei, s->api_ctx.lone_sei_size);
+       s->api_ctx.prev_size += s->api_ctx.lone_sei_size;
+       s->api_ctx.lone_sei_size = 0;
+     }
+ 
+     if ((pkt->size + s->api_ctx.prev_size) > 0)
+     {
+       ni_packet_buffer_alloc(xpkt, (pkt->size + s->api_ctx.prev_size - xpkt->len_of_sei_after_vcl));
+       if (!xpkt->p_data)
+       {
+         ret = AVERROR(ENOMEM);
+         goto fail;
+       }
+     }
+     new_packet = 1;
+   }
+   else
+   {
+     send_size = xpkt->data_len;
+   }
+ 
+   av_log(avctx, AV_LOG_DEBUG, "%s: pkt->size=%d\n", __FUNCTION__, pkt->size);
+ 
+   if (s->started == 0)
+   {
+     xpkt->start_of_stream = 1;
+     s->started = 1;
+   }
+ 
+   if (need_draining && !s->draining)
+   {
+     av_log(avctx, AV_LOG_DEBUG, "Sending End Of Stream signal\n");
+     xpkt->end_of_stream = 1;
+     xpkt->data_len = 0;
+ 
+     av_log(avctx, AV_LOG_TRACE, "ni_packet_copy before: size=%d, s->prev_size=%d, send_size=%d, "
+            "len_of_sei_after_slice=%d (end of stream)\n",
+            pkt->size, s->api_ctx.prev_size, send_size, xpkt->len_of_sei_after_vcl);
+     if (new_packet)
+     {
+       extra_prev_size = s->api_ctx.prev_size;
+       send_size = ni_packet_copy(xpkt->p_data, pkt->data, (pkt->size - xpkt->len_of_sei_after_vcl),
+                                  s->api_ctx.p_leftover, &s->api_ctx.prev_size);
+       // increment offset of data sent to decoder and save it
+       xpkt->pos = s->offset;
+       if (s->api_ctx.is_dec_pkt_512_aligned)
+       {
+         s->offset += send_size;
+       }
+       else
+       {
+         s->offset += pkt->size + extra_prev_size;
+       }
+     }
+     av_log(avctx, AV_LOG_TRACE, "ni_packet_copy after: size=%d, s->prev_size=%d, send_size=%d, "
+            "xpkt->data_len=%d, len_of_sei_after_slice=%d (end of stream)\n",
+            pkt->size, s->api_ctx.prev_size, send_size, xpkt->data_len, xpkt->len_of_sei_after_vcl);
+ 
+     if (send_size < 0)
+     {
+       av_log(avctx, AV_LOG_ERROR, "Failed to copy pkt (status = %d)\n",
+              send_size);
+       ret = AVERROR_EXTERNAL;
+       goto fail;
+     }
+     if (s->api_ctx.is_dec_pkt_512_aligned)
+     {
+       xpkt->data_len = send_size;
+     }
+     else
+     {
+       xpkt->data_len += extra_prev_size;
+     }
+ 
+     sent = 0;
+     if (xpkt->data_len > 0)
+     {
+       sent = ni_device_session_write(&(s->api_ctx), &(s->api_pkt), NI_DEVICE_TYPE_DECODER);
+     }
+     if (sent < 0)
+     {
+       av_log(avctx, AV_LOG_ERROR, "Failed to send eos signal (status = %d)\n",
+              sent);
+       if (NI_RETCODE_ERROR_VPU_RECOVERY == sent)
+       {
+         ret = xcoder_decode_reset(avctx);
+         if (0 == ret)
+         {
+           ret = AVERROR(EAGAIN);
+         }
+       }
+       else
+       {
+         ret = AVERROR_EOF;
+       }
+       goto fail;
+     }
+     av_log(avctx, AV_LOG_DEBUG, "Queued eos (status = %d) ts=%llu\n",
+            sent, xpkt->pts);
+     s->draining = 1;
+     s->vpu_reset = 0;
+ 
+     ni_device_session_flush(&(s->api_ctx), NI_DEVICE_TYPE_DECODER);
+   }
+   else
+   {
+ #if 0
+     if (pkt->pts == AV_NOPTS_VALUE)
+       av_log(avctx, AV_LOG_DEBUG, "DEC avpkt pts : NOPTS size %d  pos %lld \n",
+        pkt->size,  pkt->pos);
+     else
+       av_log(avctx, AV_LOG_DEBUG, "DEC avpkt pts : %lld  dts : %lld  size %d  pos %lld \n", pkt->pts, pkt->dts, pkt->size,
+        pkt->pos);
+ #endif
+     av_log(avctx, AV_LOG_TRACE, "ni_packet_copy before: size=%d, s->prev_size=%d, send_size=%d, len_of_sei_after_slice=%d\n",
+            pkt->size, s->api_ctx.prev_size, send_size, xpkt->len_of_sei_after_vcl);
+     if (new_packet)
+     {
+       extra_prev_size = s->api_ctx.prev_size;
+       send_size = ni_packet_copy(xpkt->p_data, pkt->data, (pkt->size - xpkt->len_of_sei_after_vcl),
+                                  s->api_ctx.p_leftover, &s->api_ctx.prev_size);
+       // increment offset of data sent to decoder and save it
+       xpkt->pos = s->offset;
+       if (s->api_ctx.is_dec_pkt_512_aligned)
+       {
+         s->offset += send_size;
+       }
+       else
+       {
+         s->offset += pkt->size + extra_prev_size;
+       }
+     }
+     av_log(avctx, AV_LOG_TRACE, "ni_packet_copy after: size=%d, s->prev_size=%d, send_size=%d, "
+            "xpkt->data_len=%d, len_of_sei_after_slice=%d\n",
+            pkt->size, s->api_ctx.prev_size, send_size, xpkt->data_len, xpkt->len_of_sei_after_vcl);
+ 
+     if (send_size < 0)
+     {
+       av_log(avctx, AV_LOG_ERROR, "Failed to copy pkt (status = %d)\n",
+              send_size);
+       ret = AVERROR_EXTERNAL;
+       goto fail;
+     }
+     if (s->api_ctx.is_dec_pkt_512_aligned)
+     {
+       xpkt->data_len = send_size;
+     }
+     else
+     {
+       xpkt->data_len += extra_prev_size;
+     }
+ 
+     sent = 0;
+     if (xpkt->data_len > 0)
+     {
+       sent = ni_device_session_write(&s->api_ctx, &(s->api_pkt), NI_DEVICE_TYPE_DECODER);
+       av_log(avctx, AV_LOG_DEBUG, "%s pts=%" PRIi64 ", dts=%" PRIi64 ", "
+              "pos=%" PRIi64 ", sent=%d\n", __FUNCTION__, pkt->pts, pkt->dts,
+              pkt->pos, sent);
+     }
+     if (sent < 0)
+     {
+       av_log(avctx, AV_LOG_ERROR, "Failed to send compressed pkt (status = "
+                                   "%d)\n", sent);
+       if (NI_RETCODE_ERROR_VPU_RECOVERY == sent)
+       {
+         ret = xcoder_decode_reset(avctx);
+         if (0 == ret)
+         {
+           ret = AVERROR(EAGAIN);
+         }
+       }
+       else
+       {
+         ret = AVERROR_EOF;
+       }
+       goto fail;
+     }
+     else if (sent == 0)
+     {
+       av_log(avctx, AV_LOG_DEBUG, "Queued input buffer size=0\n");
+     }
+     else if (sent < size)
+     {
+       /* partial sent; keep trying */
+       av_log(avctx, AV_LOG_DEBUG, "Queued input buffer size=%d\n", sent);
+     }
+   }
+ 
+   if (sent != 0)
+   {
+     //keep the current pkt to resend next time
+     ni_packet_buffer_free(xpkt);
+   }
+ 
+   if (xpkt->data_len == 0)
+   {
+     /* if this packet is done sending, free any sei buffer. */
+     free(xpkt->p_all_custom_sei);
+     xpkt->p_all_custom_sei = NULL;
+   }
+ 
+   if (sent == 0)
+   {
+     return AVERROR(EAGAIN);
+   }
+ 
+   return sent;
+ 
+ fail:
+   ni_packet_buffer_free(xpkt);
+   free(xpkt->p_all_custom_sei);
+   xpkt->p_all_custom_sei = NULL;
+ 
+   return ret;
+ }
+ 
+ int retrieve_frame(AVCodecContext *avctx, AVFrame *data, int *got_frame,
+                    ni_frame_t *xfme)
+ {
+   XCoderH264DecContext *s = avctx->priv_data;
+ 
+   int buf_size = xfme->data_len[0] + xfme->data_len[1] + xfme->data_len[2] + xfme->data_len[3];
+   uint8_t *buf = xfme->p_data[0];
+   int stride = 0;
+   int res = 0;
+   AVHWFramesContext *ctx;
+   NIFramesContext *dst_ctx;
+   AVFrame *frame = data;
+   bool is_hw = xfme->data_len[3] > 0;
+ 
+   av_log(avctx, AV_LOG_TRACE, "%s: buf %p data_len [%d %d %d %d] buf_size %d\n",
+          __FUNCTION__, buf, xfme->data_len[0], xfme->data_len[1],
+          xfme->data_len[2], xfme->data_len[3], buf_size);
+ 
+   if(is_hw)
+   {
+     if (frame->hw_frames_ctx)
+     {
+       ctx = (AVHWFramesContext*)frame->hw_frames_ctx->data;
+       dst_ctx = ctx->internal->priv;
+     }
+     if (s->api_ctx.frame_num == 1)
+     {
+       if (frame->hw_frames_ctx)
+       {
+         av_log(avctx, AV_LOG_VERBOSE, "First frame, set hw_frame_context to copy decode sessions threads\n");
+         res = ni_device_session_copy(&s->api_ctx, &dst_ctx->api_ctx);
+         if (NI_RETCODE_SUCCESS != res)
+         {
+           return res;
+         }
+         av_log(avctx, AV_LOG_VERBOSE, "%s: blk_io_handle %d device_handle %d\n",
+                __FUNCTION__, s->api_ctx.blk_io_handle, s->api_ctx.device_handle);
+       }
+     }
+   }
+ 
+   av_log(avctx, AV_LOG_DEBUG, "decoding %" PRId64 " frame ...\n", s->api_ctx.frame_num);
+ 
+   if (avctx->width <= 0)
+   {
+     av_log(avctx, AV_LOG_ERROR, "width is not set\n");
+     return AVERROR_INVALIDDATA;
+   }
+   if (avctx->height <= 0)
+   {
+     av_log(avctx, AV_LOG_ERROR, "height is not set\n");
+     return AVERROR_INVALIDDATA;
+   }
+ 
+   stride = s->api_ctx.active_video_width;
+ 
+   av_log(avctx, AV_LOG_DEBUG, "XFRAME SIZE: %d, STRIDE: %d\n", buf_size, stride);
+ 
+   if (!is_hw && (stride == 0 || buf_size < stride * avctx->height))
+   {
+     av_log(avctx, AV_LOG_ERROR, "Packet too small (%d)\n", buf_size);
+     return AVERROR_INVALIDDATA;
+   }
+ 
+   frame->key_frame = 0;
+   switch (xfme->ni_pict_type)
+   {
+   case PIC_TYPE_I:
+     frame->pict_type = AV_PICTURE_TYPE_I;
+     break;
+   case PIC_TYPE_IDR:
+   case PIC_TYPE_CRA:
+     frame->pict_type = AV_PICTURE_TYPE_I;
+     frame->key_frame = 1;
+     break;
+   case PIC_TYPE_P:
+       frame->pict_type = AV_PICTURE_TYPE_P;
+       break;
+   case PIC_TYPE_B:
+       frame->pict_type = AV_PICTURE_TYPE_B;
+       break;
+   default:
+       frame->pict_type = AV_PICTURE_TYPE_NONE;
+   }
+ 
+   res = ff_decode_frame_props(avctx, frame);
+   if (res < 0)
+     return res;
+ 
+   frame->pkt_pos = avctx->internal->last_pkt_props->pos;
+   frame->pkt_duration = avctx->internal->last_pkt_props->duration;
+ 
+   if ((res = av_image_check_size(xfme->video_width, xfme->video_height, 0, avctx)) < 0)
+     return res;
+ 
+   if (is_hw)
+   {
+     frame->buf[0] = av_buffer_create(buf, buf_size, ni_frame_free,
+                                      (void *) s->api_ctx.event_handle, 0);
+   }
+   else
+   {
+     frame->buf[0] = av_buffer_create(buf, buf_size, ni_buf_pool_free, xfme->dec_buf, 0);
+   }
+ 
+   buf = frame->buf[0]->data;
+ 
+   // User Data Unregistered SEI if available
+   if (s->enable_user_data_sei_passthru &&
+       xfme->sei_user_data_unreg_len && xfme->sei_user_data_unreg_offset)
+   {
+     uint8_t *sei_buf = (uint8_t *)xfme->p_data[0] +
+     xfme->sei_user_data_unreg_offset;
+     AVBufferRef *sei_ref = av_buffer_create(sei_buf,
+                                             xfme->sei_user_data_unreg_len,
+                                             ni_align_free_nop, NULL, 0);
+     if (! sei_ref ||
+         ! av_frame_new_side_data_from_buf(frame, AV_FRAME_DATA_NETINT_UDU_SEI,
+                                           sei_ref))
+     {
+       return AVERROR(ENOMEM);
+     }
+   }
+ 
+   // close caption data if available
+   if (xfme->sei_cc_len && xfme->sei_cc_offset)
+   {
+     uint8_t *sei_buf = (uint8_t *)xfme->p_data[0] + xfme->sei_cc_offset;
+     AVBufferRef *sei_ref = av_buffer_create(sei_buf, xfme->sei_cc_len,
+                                             ni_align_free_nop, NULL, 0);
+     if (! sei_ref ||
+         ! av_frame_new_side_data_from_buf(frame, AV_FRAME_DATA_A53_CC,
+                                           sei_ref))
+     {
+       return AVERROR(ENOMEM);
+     }
+   }
+ 
+   // hdr10 sei data if available
+   if (xfme->sei_hdr_mastering_display_color_vol_len &&
+       xfme->sei_hdr_mastering_display_color_vol_offset)
+   {
+     const int chroma_den = 50000;
+     const int luma_den = 10000;
+     AVMasteringDisplayMetadata *mdm;
+     ni_dec_mastering_display_colour_volume_t *pColourVolume;
+ 
+     mdm = av_mastering_display_metadata_create_side_data(frame);
+     if (!mdm)
+     {
+       return AVERROR(ENOMEM);
+     }
+ 
+     pColourVolume = (ni_dec_mastering_display_colour_volume_t *)(
+       (uint8_t*)xfme->p_data[0] + xfme->sei_hdr_mastering_display_color_vol_offset);
+ 
+     // HEVC uses a g,b,r ordering, which we convert to a more natural r,g,b,
+     // this is so we are compatible with FFmpeg default soft decoder
+     mdm->display_primaries[0][0].num = pColourVolume->display_primaries_x[2];
+     mdm->display_primaries[0][0].den = chroma_den;
+     mdm->display_primaries[0][1].num = pColourVolume->display_primaries_y[2];
+     mdm->display_primaries[0][1].den = chroma_den;
+     mdm->display_primaries[1][0].num = pColourVolume->display_primaries_x[0];
+     mdm->display_primaries[1][0].den = chroma_den;
+     mdm->display_primaries[1][1].num = pColourVolume->display_primaries_y[0];
+     mdm->display_primaries[1][1].den = chroma_den;
+     mdm->display_primaries[2][0].num = pColourVolume->display_primaries_x[1];
+     mdm->display_primaries[2][0].den = chroma_den;
+     mdm->display_primaries[2][1].num = pColourVolume->display_primaries_y[1];
+     mdm->display_primaries[2][1].den = chroma_den;
+ 
+     mdm->white_point[0].num = pColourVolume->white_point_x;
+     mdm->white_point[0].den = chroma_den;
+     mdm->white_point[1].num = pColourVolume->white_point_y;
+     mdm->white_point[1].den = chroma_den;
+ 
+     mdm->min_luminance.num = pColourVolume->min_display_mastering_luminance;
+     mdm->min_luminance.den = luma_den;
+     mdm->max_luminance.num = pColourVolume->max_display_mastering_luminance;
+     mdm->max_luminance.den = luma_den;
+ 
+     mdm->has_luminance = mdm->has_primaries = 1;
+   }
+ 
+   if (xfme->sei_hdr_content_light_level_info_len &&
+       xfme->sei_hdr_content_light_level_info_offset)
+   {
+     AVContentLightMetadata *clm;
+     ni_content_light_level_info_t *pLightLevel;
+ 
+     clm = av_content_light_metadata_create_side_data(frame);
+     if (! clm)
+     {
+       return AVERROR(ENOMEM);
+     }
+ 
+     pLightLevel = (ni_content_light_level_info_t *)(
+       (uint8_t*)xfme->p_data[0] + xfme->sei_hdr_content_light_level_info_offset);
+     clm->MaxCLL  = pLightLevel->max_content_light_level;
+     clm->MaxFALL = pLightLevel->max_pic_average_light_level;
+   }
+ 
+   // hdr10+ sei data if available
+   if (xfme->sei_hdr_plus_len && xfme->sei_hdr_plus_offset)
+   {
+     uint8_t *sei_buf = (uint8_t *)xfme->p_data[0] + xfme->sei_hdr_plus_offset;
+     AVDynamicHDRPlus *hdrp = av_dynamic_hdr_plus_create_side_data(frame);
+     GetBitContext gb;
+     int w, i, j, i_limit, j_limit;
+ 
+     if (! hdrp)
+     {
+       return AVERROR(ENOMEM);
+     }
+     init_get_bits8(&gb, sei_buf, xfme->sei_hdr_plus_len);
+ 
+     hdrp->itu_t_t35_country_code = 0xB5;
+     hdrp->application_version = 0;
+     // first 7 bytes of t35 SEI data header already matched HDR10+, and:
+     skip_bits(&gb, 7 * 8);
+ 
+     // num_windows u(2)
+     hdrp->num_windows = get_bits(&gb, 2);
+     av_log(avctx, AV_LOG_TRACE, "hdr10+ num_windows %u\n", hdrp->num_windows);
+     if (! (1 == hdrp->num_windows || 2 == hdrp->num_windows ||
+            3 == hdrp->num_windows))
+     {
+       // wrong format and skip this HDR10+ SEI
+ 
+     }
+     else
+     {
+       // the following block will be skipped for hdrp->num_windows == 1
+       for (w = 1; w < hdrp->num_windows; w++)
+       {
+         hdrp->params[w - 1].window_upper_left_corner_x = av_make_q(
+           get_bits(&gb, 16), 1);
+         hdrp->params[w - 1].window_upper_left_corner_y = av_make_q(
+           get_bits(&gb, 16), 1);
+         hdrp->params[w - 1].window_lower_right_corner_x = av_make_q(
+           get_bits(&gb, 16), 1);
+         hdrp->params[w - 1].window_lower_right_corner_y = av_make_q(
+           get_bits(&gb, 16), 1);
+         hdrp->params[w - 1].center_of_ellipse_x = get_bits(&gb, 16);
+         hdrp->params[w - 1].center_of_ellipse_y = get_bits(&gb, 16);
+         hdrp->params[w - 1].rotation_angle = get_bits(&gb, 8);
+         hdrp->params[w - 1].semimajor_axis_internal_ellipse =
+         get_bits(&gb, 16);
+         hdrp->params[w - 1].semimajor_axis_external_ellipse =
+         get_bits(&gb, 16);
+         hdrp->params[w - 1].semiminor_axis_external_ellipse =
+           get_bits(&gb, 16);
+         hdrp->params[w - 1].overlap_process_option =
+         (enum AVHDRPlusOverlapProcessOption)get_bits(&gb, 1);
+       }
+ 
+       // values are scaled down according to standard spec
+       hdrp->targeted_system_display_maximum_luminance.num = get_bits(&gb, 27);
+       hdrp->targeted_system_display_maximum_luminance.den = 10000;
+ 
+       hdrp->targeted_system_display_actual_peak_luminance_flag =
+       get_bits(&gb, 1);
+ 
+       av_log(avctx, AV_LOG_TRACE, "hdr10+ targeted_system_display_maximum_luminance %d\n", hdrp->targeted_system_display_maximum_luminance.num);
+       av_log(avctx, AV_LOG_TRACE, "hdr10+ targeted_system_display_actual_peak_luminance_flag %u\n", hdrp->targeted_system_display_actual_peak_luminance_flag);
+ 
+       if (hdrp->targeted_system_display_actual_peak_luminance_flag)
+       {
+         i_limit = hdrp->num_rows_targeted_system_display_actual_peak_luminance =
+         get_bits(&gb, 5);
+         j_limit = hdrp->num_cols_targeted_system_display_actual_peak_luminance =
+         get_bits(&gb, 5);
+ 
+         av_log(avctx, AV_LOG_TRACE, "hdr10+ num_rows_targeted_system_display_actual_peak_luminance x num_cols_targeted_system_display_actual_peak_luminance %u x %u\n",
+                i_limit, j_limit);
+ 
+         i_limit = i_limit > 25 ? 25 : i_limit;
+         j_limit = j_limit > 25 ? 25 : j_limit;
+         for (i = 0; i < i_limit; i++)
+           for (j = 0; j < j_limit; j++)
+           {
+             hdrp->targeted_system_display_actual_peak_luminance[i][j].num =
+             get_bits(&gb, 4);
+             hdrp->targeted_system_display_actual_peak_luminance[i][j].den = 15;
+             av_log(avctx, AV_LOG_TRACE, "hdr10+ targeted_system_display_actual_peak_luminance[%d][%d] %d\n", i, j,
+                    hdrp->targeted_system_display_actual_peak_luminance[i][j].num);
+           }
+       }
+ 
+       for (w = 0; w < hdrp->num_windows; w++)
+       {
+         for (i = 0; i < 3; i++)
+         {
+           hdrp->params[w].maxscl[i].num = get_bits(&gb, 17);
+           hdrp->params[w].maxscl[i].den = 100000;
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ maxscl[%d][%d] %d\n", w, i,
+                  hdrp->params[w].maxscl[i].num);
+         }
+         hdrp->params[w].average_maxrgb.num = get_bits(&gb, 17);
+         hdrp->params[w].average_maxrgb.den = 100000;
+         av_log(avctx, AV_LOG_TRACE, "hdr10+ average_maxrgb[%d] %d\n",
+                w, hdrp->params[w].average_maxrgb.num);
+ 
+         i_limit = hdrp->params[w].num_distribution_maxrgb_percentiles =
+         get_bits(&gb, 4);
+         av_log(avctx, AV_LOG_TRACE,
+                "hdr10+ num_distribution_maxrgb_percentiles[%d] %d\n",
+                w, hdrp->params[w].num_distribution_maxrgb_percentiles);
+ 
+         i_limit = i_limit > 15 ? 15 : i_limit;
+         for (i = 0; i < i_limit; i++)
+         {
+           hdrp->params[w].distribution_maxrgb[i].percentage = get_bits(&gb, 7);
+           hdrp->params[w].distribution_maxrgb[i].percentile.num =
+           get_bits(&gb, 17);
+           hdrp->params[w].distribution_maxrgb[i].percentile.den = 100000;
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ distribution_maxrgb_percentage[%d][%d] %u\n",
+                  w, i, hdrp->params[w].distribution_maxrgb[i].percentage);
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ distribution_maxrgb_percentile[%d][%d] %d\n",
+                  w, i, hdrp->params[w].distribution_maxrgb[i].percentile.num);
+         }
+ 
+         hdrp->params[w].fraction_bright_pixels.num = get_bits(&gb, 10);
+         hdrp->params[w].fraction_bright_pixels.den = 1000;
+         av_log(avctx, AV_LOG_TRACE, "hdr10+ fraction_bright_pixels[%d] %d\n",
+                w, hdrp->params[w].fraction_bright_pixels.num);
+       }
+ 
+       hdrp->mastering_display_actual_peak_luminance_flag = get_bits(&gb, 1);
+       av_log(avctx, AV_LOG_TRACE,
+              "hdr10+ mastering_display_actual_peak_luminance_flag %u\n",
+              hdrp->mastering_display_actual_peak_luminance_flag);
+       if (hdrp->mastering_display_actual_peak_luminance_flag)
+       {
+         i_limit = hdrp->num_rows_mastering_display_actual_peak_luminance =
+         get_bits(&gb, 5);
+         j_limit = hdrp->num_cols_mastering_display_actual_peak_luminance =
+         get_bits(&gb, 5);
+         av_log(avctx, AV_LOG_TRACE, "hdr10+ num_rows_mastering_display_actual_peak_luminance x num_cols_mastering_display_actual_peak_luminance %u x %u\n",
+                i_limit, j_limit);
+ 
+         i_limit = i_limit > 25 ? 25 : i_limit;
+         j_limit = j_limit > 25 ? 25 : j_limit;
+         for (i = 0; i < i_limit; i++)
+           for (j = 0; j < j_limit; j++)
+           {
+             hdrp->mastering_display_actual_peak_luminance[i][j].num =
+             get_bits(&gb, 4);
+             hdrp->mastering_display_actual_peak_luminance[i][j].den = 15;
+             av_log(avctx, AV_LOG_TRACE, "hdr10+ mastering_display_actual_peak_luminance[%d][%d] %d\n", i, j,
+                    hdrp->mastering_display_actual_peak_luminance[i][j].num);
+           }
+       }
+ 
+       for (w = 0; w < hdrp->num_windows; w++)
+       {
+         hdrp->params[w].tone_mapping_flag = get_bits(&gb, 1);
+         av_log(avctx, AV_LOG_TRACE, "hdr10+ tone_mapping_flag[%d] %u\n",
+                w, hdrp->params[w].tone_mapping_flag);
+ 
+         if (hdrp->params[w].tone_mapping_flag)
+         {
+           hdrp->params[w].knee_point_x.num = get_bits(&gb, 12);
+           hdrp->params[w].knee_point_x.den = 4095;
+           hdrp->params[w].knee_point_y.num = get_bits(&gb, 12);
+           hdrp->params[w].knee_point_y.den = 4095;
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ knee_point_x[%d] %u\n",
+                w, hdrp->params[w].knee_point_x.num);
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ knee_point_y[%d] %u\n",
+                w, hdrp->params[w].knee_point_y.num);
+ 
+           hdrp->params[w].num_bezier_curve_anchors = get_bits(&gb, 4);
+           av_log(avctx, AV_LOG_TRACE,
+                  "hdr10+ num_bezier_curve_anchors[%d] %u\n",
+                  w, hdrp->params[w].num_bezier_curve_anchors);
+           for (i = 0; i < hdrp->params[w].num_bezier_curve_anchors; i++)
+           {
+             hdrp->params[w].bezier_curve_anchors[i].num = get_bits(&gb, 10);
+             hdrp->params[w].bezier_curve_anchors[i].den = 1023;
+             av_log(avctx, AV_LOG_TRACE,
+                    "hdr10+ bezier_curve_anchors[%d][%d] %d\n",
+                    w, i, hdrp->params[w].bezier_curve_anchors[i].num);
+           }
+         }
+ 
+         hdrp->params[w].color_saturation_mapping_flag = get_bits(&gb, 1);
+         av_log(avctx, AV_LOG_TRACE,
+                "hdr10+ color_saturation_mapping_flag[%d] %u\n",
+                w, hdrp->params[w].color_saturation_mapping_flag);
+         if (hdrp->params[w].color_saturation_mapping_flag)
+         {
+           hdrp->params[w].color_saturation_weight.num = get_bits(&gb, 6);
+           hdrp->params[w].color_saturation_weight.den = 8;
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ color_saturation_weight[%d] %d\n",
+                  w, hdrp->params[w].color_saturation_weight.num);
+         }
+       } // num_windows
+ 
+     } // correct num_windows
+   } // hdr10+ sei
+ 
+   if (xfme->p_custom_sei)
+   {
+     AVBufferRef *sei_ref = av_buffer_create(xfme->p_custom_sei,
+                                             sizeof(ni_all_custom_sei_t),
+                                             ni_free, NULL, 0);
+     if (! sei_ref ||
+         ! av_frame_new_side_data_from_buf(frame, AV_FRAME_DATA_NETINT_CUSTOM_SEI,
+                                     sei_ref))
+     {
+         return AVERROR(ENOMEM);
+     }
+     xfme->p_custom_sei = NULL;
+   }
+ 
+   frame->pkt_dts = xfme->pts;
+   if (xfme->pts != NI_NOPTS_VALUE)
+   {
+     frame->pts = xfme->pts;
+   }
+   else
+   {
+     s->current_pts += frame->pkt_duration;
+     frame->pts = s->current_pts;
+   }
+ 
+   if (is_hw)
+   {
+     ni_hwframe_surface_t* p_data3;
+     p_data3 = (ni_hwframe_surface_t*)((uint8_t*)xfme->p_buffer
+                                 + xfme->data_len[0] + xfme->data_len[1]
+                                 + xfme->data_len[2]);
+     frame->data[3] = (uint8_t*) p_data3;
+     av_log(avctx, AV_LOG_DEBUG, "%s: OUT0 data[3] i8FrameIdx=%d, device_handle=%ld"
+            " bitdep=%d, WxH %d x %d\n", __FUNCTION__,
+            p_data3->i8FrameIdx,
+            p_data3->device_handle,
+            p_data3->bit_depth,
+            p_data3->ui16width,
+            p_data3->ui16height);
+   }
+ 
+   av_log(avctx, AV_LOG_DEBUG, "%s: frame->buf[0]=%p, "
+          "frame->data=%p, frame->pts=%" PRId64 ", frame size=%d, "
+          "s->current_pts=%" PRId64 ", frame->pkt_pos=%" PRId64 ", "
+          "frame->pkt_duration=%" PRId64 " sei size %d offset %u\n",
+          __FUNCTION__, frame->buf[0], frame->data, frame->pts, buf_size,
+          s->current_pts, frame->pkt_pos, frame->pkt_duration,
+          xfme->sei_cc_len, xfme->sei_cc_offset);
+ 
+   /* av_buffer_ref(avpkt->buf); */
+   if (!frame->buf[0])
+   {
+     return AVERROR(ENOMEM);
+   }
+ 
+   av_log(avctx, AV_LOG_DEBUG, "%s: fill array, linesize[0]=%d, fmt=%d, width=%d"
+          ", height=%d\n", __FUNCTION__, frame->linesize[0], avctx->sw_pix_fmt,
+          s->api_ctx.active_video_width, s->api_ctx.active_video_height);
+   if (!is_hw && ((res = av_image_fill_arrays(frame->data, frame->linesize,
+                                               buf, avctx->sw_pix_fmt,
+                                               s->api_ctx.active_video_width,
+                                               s->api_ctx.active_video_height, 1)) < 0))
+   {
+     av_buffer_unref(&frame->buf[0]);
+     return res;
+   }
+ 
+   av_log(avctx, AV_LOG_DEBUG, "%s: success av_image_fill_arrays return %d\n",
+          __FUNCTION__, res);
+   frame->width = s->api_ctx.active_video_width;
+   frame->height = s->api_ctx.active_video_height;
+   frame->crop_top = xfme->crop_top;
+   frame->crop_bottom = s->api_ctx.active_video_height - xfme->crop_bottom;
+   frame->crop_left = xfme->crop_left;
+   frame->crop_right = s->api_ctx.active_video_width - xfme->crop_right;
+ 
+   if (is_hw)
+   {
+     av_log(avctx, AV_LOG_TRACE, "%s: hw frame av_buffer_get_ref_count=%d\n",
+            __FUNCTION__, av_buffer_get_ref_count(frame->buf[0]));
+     dst_ctx->pc_width = frame->width;
+     dst_ctx->pc_height = frame->height;
+     dst_ctx->pc_crop_bottom = frame->crop_bottom;
+     dst_ctx->pc_crop_right = frame->crop_right;
+   }
+ 
+   *got_frame = 1;
+   return buf_size;
+ }
+ 
+ static int decoder_frame_alloc(AVCodecContext *avctx, XCoderH264DecContext *s,
+                                ni_session_data_io_t *p_session_data)
+ {
+   int ret, width, height, alloc_mem;
+ 
+   // If active video resolution has been obtained we just use it as it's the
+   // exact size of frame to be returned, otherwise we use what we are told by
+   // upper stream as the initial setting and it will be adjusted.
+   width = s->api_ctx.active_video_width > 0 ? s->api_ctx.active_video_width : avctx->width;
+   height = s->api_ctx.active_video_height > 0 ? s->api_ctx.active_video_height : avctx->height;
+ 
+   // allocate memory only after resolution is known (buffer pool set up)
+   alloc_mem = (s->api_ctx.active_video_width > 0) &&
+               (s->api_ctx.active_video_height > 0 ? 1 : 0);
+ 
+   // HW frame
+   if (avctx->pix_fmt == AV_PIX_FMT_NI)
+   {
+     ret = ni_frame_buffer_alloc(&p_session_data->data.frame,
+                                 width,
+                                 height,
+                                 avctx->codec_id == AV_CODEC_ID_H264,
+                                 1,
+                                 s->api_ctx.bit_depth_factor,
+                                 1);
+   }
+   else
+   {
+     ret = ni_decoder_frame_buffer_alloc(s->api_ctx.dec_fme_buf_pool,
+                                         &p_session_data->data.frame,
+                                         alloc_mem,
+                                         width,
+                                         height,
+                                         avctx->codec_id == AV_CODEC_ID_H264,
+                                         s->api_ctx.bit_depth_factor);
+   }
+ 
+   return ret;
+ }
+ 
+ static void decoder_frame_free(AVCodecContext *avctx,
+                                ni_session_data_io_t *p_session_data)
+ {
+   if (avctx->pix_fmt == AV_PIX_FMT_NI)
+   {
+     ni_frame_buffer_free(&p_session_data->data.frame);
+   }
+   else
+   {
+     ni_decoder_frame_buffer_free(&p_session_data->data.frame);
+   }
+ }
+ 
+ int ff_xcoder_dec_receive(AVCodecContext *avctx, XCoderH264DecContext *s,
+                           AVFrame *frame, bool wait)
+ {
+   /* call xcode_dec_receive to get a decoded YUV frame from the decoder
+      instance */
+   int ret = 0;
+   int got_frame = 0;
+   ni_session_data_io_t session_io_data;
+   ni_session_data_io_t *p_session_data = &session_io_data;
+   int avctx_bit_depth = 0;
+   int is_hw_frm = (avctx->pix_fmt == AV_PIX_FMT_NI);
+ 
+   if (s->draining && s->eos)
+   {
+     return AVERROR_EOF;
+   }
+ 
+   memset(p_session_data, 0, sizeof(ni_session_data_io_t));
+ 
+   ret = decoder_frame_alloc(avctx, s, p_session_data);
+   if (NI_RETCODE_SUCCESS != ret)
+   {
+     return AVERROR_EXTERNAL;
+   }
+ 
+   if (is_hw_frm)
+   {
+     ret = ni_device_session_read_hwdesc(&s->api_ctx, p_session_data);
+   }
+   else
+   {
+     ret = ni_device_session_read(&s->api_ctx, p_session_data, NI_DEVICE_TYPE_DECODER);
+   }
+ 
+   if (ret == 0)
+   {
+     s->eos = p_session_data->data.frame.end_of_stream;
+     decoder_frame_free(avctx, p_session_data);
+     return AVERROR(EAGAIN);
+   }
+   else if (ret > 0)
+   {
+     if (s->vpu_reset)
+     {
+       // On decoder VPU recovery the first received frame corresponding to the
+       // cached seq_hdr_pkt should be dropped since the data is outdated.
+       s->vpu_reset = 0;
+       decoder_frame_free(avctx, p_session_data);
+       return AVERROR(EAGAIN);
+     }
+ 
+     av_log(avctx, AV_LOG_DEBUG, "Got output buffer pts=%lld dts=%lld eos=%d sos=%d\n",
+            p_session_data->data.frame.pts, p_session_data->data.frame.dts,
+            p_session_data->data.frame.end_of_stream, p_session_data->data.frame.start_of_stream);
+ 
+     s->eos = p_session_data->data.frame.end_of_stream;
+ 
+     // update ctxt resolution if change has been detected
+     frame->width = p_session_data->data.frame.video_width;
+     frame->height = p_session_data->data.frame.video_height;
+ 
+     if (is_hw_frm)
+     {
+       avctx_bit_depth = p_session_data->data.frame.bit_depth;
+     }
+     else
+     {
+       avctx_bit_depth = (avctx->pix_fmt == AV_PIX_FMT_YUV420P10LE)?10:8;
+     }
+ 
+     if (frame->width != avctx->width || frame->height != avctx->height || avctx_bit_depth  != p_session_data->data.frame.bit_depth)
+     {
+       av_log(avctx, AV_LOG_WARNING, "%s: sequence changed: %dx%d %dbits to "
+              "%dx%d %dbits\n", __FUNCTION__, avctx->width, avctx->height,
+              avctx_bit_depth, frame->width, frame->height,
+              p_session_data->data.frame.bit_depth);
+       avctx->width = frame->width;
+       avctx->height = frame->height;
+ 
+       if (is_hw_frm)
+       {
+         s->hwfc->width = frame->width;
+         s->hwfc->height = frame->height;
+       }
+       else
+       {
+         avctx->sw_pix_fmt = (p_session_data->data.frame.bit_depth == 10)? AV_PIX_FMT_YUV420P10LE : AV_PIX_FMT_YUV420P;
+         avctx->pix_fmt = avctx->sw_pix_fmt;
+       }
+     }
+ 
+     frame->format = avctx->pix_fmt;
+ 
+     if (avctx->pix_fmt == AV_PIX_FMT_NI)
+     {
+       frame->hw_frames_ctx = av_buffer_ref(avctx->hw_frames_ctx);
+     }
+ 
+     retrieve_frame(avctx, frame, &got_frame, &(p_session_data->data.frame));
+ 
+     av_log(avctx, AV_LOG_DEBUG, "%s: got_frame=%d, frame->width=%d, frame->height=%d, "
+            "crop top %" SIZE_SPECIFIER " bottom %" SIZE_SPECIFIER " left "
+            "%" SIZE_SPECIFIER " right %" SIZE_SPECIFIER ", frame->format=%d, "
+            "frame->linesize=%d/%d/%d\n", __FUNCTION__, got_frame, frame->width,
+            frame->height, frame->crop_top, frame->crop_bottom, frame->crop_left,
+            frame->crop_right, frame->format,
+            frame->linesize[0], frame->linesize[1], frame->linesize[2]);
+ 
+ #if FF_API_PKT_PTS
+     FF_DISABLE_DEPRECATION_WARNINGS
+     frame->pkt_pts = frame->pts;
+     FF_ENABLE_DEPRECATION_WARNINGS
+ #endif
+     frame->best_effort_timestamp = frame->pts;
+ #if 0
+     av_log(avctx, AV_LOG_DEBUG, "\n   NI dec out frame: pts  %lld  pkt_dts  %lld   pkt_pts  %lld \n\n", frame->pts, frame->pkt_dts,
+      frame->pkt_pts);
+ #endif
+     av_log(avctx, AV_LOG_DEBUG, "%s: pkt_timebase= %d/%d, frame_rate=%d/%d, "
+            "frame->pts=%" PRId64 ", frame->pkt_dts=%" PRId64 "\n", __FUNCTION__,
+            avctx->pkt_timebase.num, avctx->pkt_timebase.den, avctx->framerate.num,
+            avctx->framerate.den, frame->pts, frame->pkt_dts);
+ 
+     // release buffer ownership and let frame owner return frame buffer to
+     // buffer pool later
+     p_session_data->data.frame.dec_buf = NULL;
+     free(p_session_data->data.frame.p_custom_sei);
+     p_session_data->data.frame.p_custom_sei = NULL;
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_ERROR, "Failed to get output buffer (status=%d)\n", ret);
+ 
+     if (NI_RETCODE_ERROR_VPU_RECOVERY == ret)
+     {
+       av_log(avctx, AV_LOG_WARNING, "%s VPU recovery, need to reset\n", __FUNCTION__);
+       decoder_frame_free(avctx, p_session_data);
+       return ret;
+     }
+ 
+     return AVERROR_EOF;
+   }
+ 
+   ret = 0;
+ 
+   return ret;
+ }
+ 
+ int ff_xcoder_dec_is_flushing(AVCodecContext *avctx,
+                               XCoderH264DecContext *s)
+ {
+   return s->flushing;
+ }
+ 
+ int ff_xcoder_dec_flush(AVCodecContext *avctx,
+                         XCoderH264DecContext *s)
+ {
+   s->draining = 0;
+   s->flushing = 0;
+   s->eos = 0;
+ 
+ #if 0
+   int ret;
+   ret = ni_device_session_flush(s, NI_DEVICE_TYPE_DECODER);
+   if (ret < 0) {
+     av_log(avctx, AV_LOG_ERROR, "Failed to flush decoder (status = %d)\n", ret);
+     return AVERROR_EXTERNAL;
+   }
+ #endif
+ 
+   /* Future: for now, always return 1 to indicate the codec has been flushed
+      and it leaves the flushing state and can process again ! will consider
+      case of user retaining frames in HW "surface" usage */
+   return 1;
+ }
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/nicodec.h FFmpeg-n4.3.1/libavcodec/nicodec.h
*** base_ffmpeg_n4.3.1/libavcodec/nicodec.h	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/nicodec.h	2022-01-30 21:44:04.789494519 -0800
***************
*** 0 ****
--- 1,204 ----
+ /*
+  * XCoder Codec Lib Wrapper
+  * Copyright (c) 2018 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ /**
+  * @file
+  * XCoder codec lib wrapper header.
+  */
+ 
+ #ifndef AVCODEC_NICODEC_H
+ #define AVCODEC_NICODEC_H
+ 
+ #include <stdbool.h>
+ #include <time.h>
+ #include "avcodec.h"
+ #include "libavutil/fifo.h"
+ #include "libavutil/hwcontext.h"
+ #include "libavutil/hwcontext_ni.h"
+ 
+ #include <ni_device_api.h>
+ 
+ #define NI_NAL_VPS_BIT                  (0x01)
+ #define NI_NAL_SPS_BIT                  (0x01<<1)
+ #define NI_NAL_PPS_BIT                  (0x01<<2)
+ #define NI_GENERATE_ALL_NAL_HEADER_BIT  (0x01<<3)
+ 
+ /* enum for specifying xcoder device/coder index; can be specified in either
+    decoder or encoder options. */
+ enum {
+   BEST_DEVICE_INST = -2,
+   BEST_DEVICE_LOAD = -1
+ };
+ 
+ /* enum for specifying hardware accelbrate index */
+ enum {
+   HW_FRAMES_OFF = 0,
+   HW_FRAMES_ON = 1
+ };
+ 
+ typedef struct XCoderH264DecContext {
+   AVClass *avclass;
+ 
+   char *dev_xcoder;         /* from the user command, which device allocation method we use */
+   char *dev_xcoder_name;    /* dev name of the xcoder card to use */
+   char *blk_xcoder_name;    /* blk name of the xcoder card to use */
+   int  dev_dec_idx;         /* index of the decoder on the xcoder card */
+   int  nvme_io_size;        /* custom nvme io size */
+   int  keep_alive_timeout;    /* keep alive timeout setting */
+   ni_device_context_t *rsrc_ctx;  /* resource management context */
+ 
+   ni_session_context_t api_ctx;
+   ni_encoder_params_t  api_param;
+   ni_session_data_io_t api_pkt;
+ 
+   AVPacket buffered_pkt;
+   AVPacket seq_hdr_pkt;
+ 
+   // stream header copied/saved from AVCodecContext.extradata
+   int got_first_idr;
+   uint8_t *extradata;
+   int extradata_size;
+ 
+   int64_t current_pts;
+   unsigned long long offset;
+ 
+   int started;
+   int draining;
+   int flushing;
+   int eos;
+   int vpu_reset;
+   AVHWFramesContext    *hwfc;
+ 
+   /* below are all command line options */
+   char *xcoder_opts;
+   int enable_user_data_sei_passthru;
+   int enable_check_packet;  // check source packet. Skip SEI payloads after VCL
+   int custom_sei;
+   int low_delay;
+   int pkt_nal_bitmap;
+   int hwFrames;
+ } XCoderH264DecContext;
+ 
+ typedef struct XCoderH265EncContext {
+   AVClass *avclass;
+ 
+   char *dev_xcoder;         /* from the user command, which device allocation method we use */
+   char *dev_xcoder_name;    /* dev name of the xcoder card to use */
+   char *blk_xcoder_name;    /* blk name of the xcoder card to use */
+   int  dev_enc_idx;         /* index of the encoder on the xcoder card */
+   int  nvme_io_size;        /* custom nvme io size */
+   uint8_t d_serial_number[20]; /*Serial number of card (dec) in use*/
+   uint8_t e_serial_number[20]; /*Serial number of card (enc) in use*/
+   int  keep_alive_timeout;    /* keep alive timeout setting */
+   ni_device_context_t *rsrc_ctx;  /* resource management context */
+   unsigned long xcode_load_pixel; /* xcode load in pixels by this encode task */
+ 
+   // frame fifo, to be used for sequence change frame buffering
+   AVFifoBuffer *fme_fifo;
+   int fme_fifo_capacity;
+   int eos_fme_received;
+   AVFrame buffered_fme;
+ 
+   ni_session_data_io_t  api_pkt; /* used for receiving bitstream from xcoder */
+   ni_session_data_io_t   api_fme; /* used for sending YUV data to xcoder */
+   ni_session_context_t api_ctx;
+   ni_encoder_params_t  api_param;
+ 
+   int started;
+   uint8_t *p_spsPpsHdr;
+   int spsPpsHdrLen;
+   int spsPpsArrived;
+   int firstPktArrived;
+   int64_t dtsOffset;
+   int gop_offset_count;/*this is a counter to guess the pts only dtsOffset times*/
+   uint64_t total_frames_received;
+   int64_t first_frame_pts;
+   int64_t latest_dts;
+   int vpu_reset;
+   int encoder_flushing;
+   int encoder_eof;
+ 
+   // ROI
+   int roi_side_data_size;
+   AVRegionOfInterest *av_rois;  // last passed in AVRegionOfInterest
+   int nb_rois;
+   ni_enc_avc_roi_custom_map_t *avc_roi_map; // actual AVC/HEVC map(s)
+   uint8_t *hevc_sub_ctu_roi_buf;
+   ni_enc_hevc_roi_custom_map_t *hevc_roi_map;
+ 
+   /* backup copy of original values of -enc command line option */
+   int  orig_dev_enc_idx;
+ 
+   // for hw trancoding
+   // refer the hw frame when sending to encoder,
+   // unrefer the hw frame after received the encoded packet.
+   // Then it can recycle the HW frame buffer
+   AVFrame *sframe_pool[MAX_NUM_FRAMEPOOL_HWAVFRAME];
+   int aFree_Avframes_list[MAX_NUM_FRAMEPOOL_HWAVFRAME+1];
+   int freeHead;
+   int freeTail;
+ 
+  /* below are all command line options */
+   char *xcoder_opts;
+   char *xcoder_gop;
+ 
+   int reconfigCount;
+   ni_encoder_change_params_t *g_enc_change_params;
+ 
+   // low delay mode flags
+   int gotPacket; /* used to stop receiving packets when a packet is already received */
+   int sentFrame; /* used to continue receiving packets when a frame is sent and a packet is not yet received */
+ 
+   // HRD parameters
+   uint32_t au_cpb_removal_delay_length_minus1;
+   uint32_t dpb_output_delay_length_minus1;
+   uint32_t initial_cpb_removal_delay_length_minus1;
+   int64_t bit_rate_unscale;
+   int64_t cpb_size_unscale;
+   uint32_t au_cpb_removal_delay_minus1;
+ 
+ } XCoderH265EncContext;
+ 
+ int ff_xcoder_dec_close(AVCodecContext *avctx,
+                         XCoderH264DecContext *s);
+ 
+ int ff_xcoder_dec_init(AVCodecContext *avctx,
+                        XCoderH264DecContext *s);
+ 
+ int ff_xcoder_dec_send(AVCodecContext *avctx,
+                        XCoderH264DecContext *s,
+                        AVPacket *pkt);
+ 
+ int ff_xcoder_dec_receive(AVCodecContext *avctx,
+                           XCoderH264DecContext *s,
+                           AVFrame *frame,
+                           bool wait);
+ 
+ int ff_xcoder_dec_is_flushing(AVCodecContext *avctx,
+                               XCoderH264DecContext *s);
+ 
+ int ff_xcoder_dec_flush(AVCodecContext *avctx,
+                         XCoderH264DecContext *s);
+ 
+ int retrieve_frame(AVCodecContext *avctx, AVFrame *data, int *got_frame,
+                    ni_frame_t *xfme);
+ int ff_xcoder_add_headers(AVCodecContext *avctx, AVPacket *pkt);
+ #endif /* AVCODEC_NICODEC_H */
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/nidec.c FFmpeg-n4.3.1/libavcodec/nidec.c
*** base_ffmpeg_n4.3.1/libavcodec/nidec.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/nidec.c	2022-01-30 21:44:04.789494519 -0800
***************
*** 0 ****
--- 1,437 ----
+ /*
+  * NetInt XCoder H.264/HEVC Decoder common code
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ /**
+  * @file
+  * XCoder decoder.
+  */
+ 
+ #include "nidec.h"
+ 
+ int xcoder_decode_close(AVCodecContext *avctx)
+ {
+   XCoderH264DecContext *s = avctx->priv_data;
+   av_log(avctx, AV_LOG_DEBUG, "XCoder decode close\n");
+ 
+   /* this call shall release resource based on s->api_ctx */
+   ff_xcoder_dec_close(avctx, s);
+ 
+   av_packet_unref(&s->buffered_pkt);
+   av_packet_unref(&s->seq_hdr_pkt);
+ 
+   free(s->extradata);
+   s->extradata = NULL;
+   s->extradata_size = 0;
+   s->got_first_idr = 0;
+ 
+   ni_rsrc_free_device_context(s->rsrc_ctx);
+   s->rsrc_ctx = NULL;
+ 
+   return 0;
+ }
+ 
+ static int xcoder_setup_decoder(AVCodecContext *avctx)
+ {
+   XCoderH264DecContext *s = avctx->priv_data;
+ 
+   av_log(avctx, AV_LOG_DEBUG, "XCoder setup device decoder\n");
+   //s->api_ctx.session_id = NI_INVALID_SESSION_ID;
+   ni_device_session_context_init(&(s->api_ctx));
+   s->api_ctx.codec_format = NI_CODEC_FORMAT_H264;
+   if (avctx->codec_id == AV_CODEC_ID_HEVC)
+   {
+     s->api_ctx.codec_format = NI_CODEC_FORMAT_H265;
+   }
+ 
+   if (0 == strcmp(s->dev_xcoder, LIST_DEVICES_STR))
+   {
+     av_log(avctx, AV_LOG_DEBUG, "XCoder: printing out all xcoder devices and their load, and exit ...\n");
+     ni_rsrc_print_all_devices_capability();
+     return AVERROR_EXIT;
+   }
+   else if (avctx->width > NI_MAX_RESOLUTION_WIDTH ||
+            avctx->height > NI_MAX_RESOLUTION_HEIGHT ||
+            avctx->width * avctx->height > NI_MAX_RESOLUTION_AREA)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Error XCoder resolution %dx%d not supported\n",
+            avctx->width, avctx->height);
+     av_log(avctx, AV_LOG_ERROR, "Max Supported Width: %d Height %d Area %d\n",
+            NI_MAX_RESOLUTION_WIDTH, NI_MAX_RESOLUTION_HEIGHT, NI_MAX_RESOLUTION_AREA);
+     return AVERROR_EXTERNAL;
+   }
+ 
+   s->offset = 0LL;
+ 
+   s->draining = 0;
+ 
+   s->api_ctx.bit_depth_factor = 1;
+   if (AV_PIX_FMT_YUV420P10BE == avctx->sw_pix_fmt ||
+       AV_PIX_FMT_YUV420P10LE == avctx->sw_pix_fmt)
+   {
+     s->api_ctx.bit_depth_factor = 2;
+   }
+ 
+   return 0;
+ }
+ 
+ int xcoder_decode_init(AVCodecContext *avctx)
+ {
+   int ret = 0;
+   XCoderH264DecContext *s = avctx->priv_data;
+   const AVPixFmtDescriptor *desc;
+   ni_encoder_params_t *p_param = &s->api_param;
+ 
+   ni_log_set_level(ff_to_ni_log_level(av_log_get_level()));
+ 
+   av_log(avctx, AV_LOG_DEBUG, "XCoder decode init\n");
+ 
+   if (s->dev_xcoder == NULL)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Error: XCoder decode options dev_xcoder is null\n");
+     return AVERROR_INVALIDDATA;
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_VERBOSE, "XCoder options: dev_xcoder: %s dev_dec_idx %d\n",
+            s->dev_xcoder, s->dev_dec_idx);
+   }
+ 
+   avctx->sw_pix_fmt = avctx->pix_fmt;
+ 
+   desc = av_pix_fmt_desc_get(avctx->sw_pix_fmt);
+   av_log(avctx, AV_LOG_VERBOSE, "width: %d height: %d sw_pix_fmt: %s\n",
+          avctx->width, avctx->height, desc ? desc->name : "NONE");
+ 
+   if (0 == avctx->width || 0 == avctx->height)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Error probing input stream\n");
+     return AVERROR_INVALIDDATA;
+   }
+ 
+   switch (avctx->pix_fmt)
+   {
+     case AV_PIX_FMT_YUV420P:
+     case AV_PIX_FMT_YUV420P10BE:
+     case AV_PIX_FMT_YUV420P10LE:
+     case AV_PIX_FMT_YUVJ420P:
+       break;
+     default:
+       av_log(avctx, AV_LOG_ERROR, "Error: pixel format %s not supported.\n",
+              desc ? desc->name : "NONE");
+       return AVERROR_INVALIDDATA;
+   }
+ 
+   av_log(avctx, AV_LOG_DEBUG, "(avctx->field_order = %d)\n", avctx->field_order);
+   if (avctx->field_order > AV_FIELD_PROGRESSIVE)
+   { //AVFieldOrder with bottom or top coding order represents interlaced video
+     av_log(avctx, AV_LOG_ERROR, "interlaced video not supported!\n");
+     return AVERROR_INVALIDDATA;
+   }
+ 
+   if (s->nvme_io_size > 0 && s->nvme_io_size % 4096 != 0)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Error XCoder iosize is not 4KB aligned!\n");
+     return AVERROR_EXTERNAL;
+   }
+ 
+   if ((ret = xcoder_setup_decoder(avctx)) < 0)
+   {
+     return ret;
+   }
+ 
+   // reference h264_decode_init in h264dec.c
+   if (avctx->ticks_per_frame == 1)
+   {
+     if (avctx->time_base.den < INT_MAX / 2)
+     {
+       avctx->time_base.den *= 2;
+     }
+     else
+     {
+       avctx->time_base.num /= 2;
+     }
+   }
+ 
+   avctx->ticks_per_frame = 2;
+ 
+   s->started = 0;
+   memset(&s->api_pkt, 0, sizeof(ni_packet_t));
+   s->got_first_idr = 0;
+   s->pkt_nal_bitmap = 0;
+ 
+   av_log(avctx, AV_LOG_VERBOSE, "XCoder decode init: time_base = %d/%d, "
+          "frame rate = %d/%d, ticks_per_frame=%d\n", avctx->time_base.num,
+          avctx->time_base.den, avctx->framerate.num, avctx->framerate.den,
+          avctx->ticks_per_frame);
+ 
+   //overwrite the nvme io size here with a custom value if it was provided
+   if (s->nvme_io_size > 0)
+   {
+     s->api_ctx.max_nvme_io_size = s->nvme_io_size;
+     av_log(avctx, AV_LOG_VERBOSE, "Custom NVMEe IO Size set to = %d\n",
+            s->api_ctx.max_nvme_io_size);
+   }
+ 
+   //overwrite keep alive timeout value here with a custom value if it was provided
+   s->api_ctx.keep_alive_timeout = s->keep_alive_timeout;
+   av_log(avctx, AV_LOG_VERBOSE, "Custom NVMEe Keep Alive Timeout set to = %d\n",
+          s->api_ctx.keep_alive_timeout);
+ 
+   //Xcoder User Configuration
+ 
+   if (ni_decoder_init_default_params(p_param, avctx->framerate.num,
+       avctx->framerate.den, avctx->bit_rate, avctx->width, avctx->height) < 0)
+   {
+     av_log(avctx, AV_LOG_INFO, "Error setting params\n");
+     return AVERROR(EINVAL);
+   }
+ 
+   if (s->xcoder_opts)
+   {
+     AVDictionary *dict = NULL;
+     AVDictionaryEntry *en = NULL;
+ 
+     if (! av_dict_parse_string(&dict, s->xcoder_opts, "=", ":", 0))
+     {
+       while ((en = av_dict_get(dict, "", en, AV_DICT_IGNORE_SUFFIX)))
+       {
+         int parse_ret = ni_encoder_params_set_value(p_param, en->key,
+                                                     en->value, &s->api_ctx);
+         if (NI_RETCODE_SUCCESS != parse_ret)
+         {
+           av_log(avctx, AV_LOG_ERROR, "Error parsing xcoder-params: %d\n",
+                  parse_ret);
+           return AVERROR_EXTERNAL;
+         }
+       }
+       av_dict_free(&dict);
+     }
+   }
+ 
+   //hwframes can be set from 'out=hw' or 'hwframes 1' param
+   p_param->dec_input_params.hwframes = s->hwFrames | p_param->dec_input_params.hwframes;
+ 
+   if (s->hwFrames || p_param->dec_input_params.hwframes)
+   {
+     s->api_ctx.hw_action = NI_CODEC_HW_ENABLE;
+     av_log(avctx, AV_LOG_TRACE, "xcoder_decode_init: enable hw codec\n");
+   }
+   else
+   {
+     s->api_ctx.hw_action = NI_CODEC_HW_NONE;//
+   }
+ 
+   s->api_ctx.p_session_config = &s->api_param;
+ 
+   if ((ret = ff_xcoder_dec_init(avctx, s)) < 0)
+   {
+     goto done;
+   }
+ 
+   s->current_pts = 0;
+ 
+ done:
+   if (NI_INVALID_DEVICE_HANDLE == s->api_ctx.blk_io_handle ||
+       NI_INVALID_DEVICE_HANDLE == s->api_ctx.device_handle)
+   {
+     xcoder_decode_close(avctx);
+   }
+   return ret;
+ }
+ 
+ // reset and restart when xcoder decoder resets
+ int xcoder_decode_reset(AVCodecContext *avctx)
+ {
+   XCoderH264DecContext *s = avctx->priv_data;
+   ni_retcode_t ret = NI_RETCODE_FAILURE;
+   int64_t bcp_current_pts = s->current_pts;
+   int draining = s->draining;
+ 
+   av_log(avctx, AV_LOG_WARNING, "XCoder decode reset\n");
+ 
+   s->vpu_reset = 1;
+   ret = ni_device_session_close(&s->api_ctx, s->eos, NI_DEVICE_TYPE_DECODER);
+ 
+ #ifdef _WIN32
+   ni_device_close(s->api_ctx.device_handle);
+ #elif __linux__
+   ni_device_close(s->api_ctx.device_handle);
+   ni_device_close(s->api_ctx.blk_io_handle);
+ #endif
+   s->api_ctx.device_handle = NI_INVALID_DEVICE_HANDLE;
+   s->api_ctx.blk_io_handle = NI_INVALID_DEVICE_HANDLE;
+ 
+   ni_packet_buffer_free(&(s->api_pkt.data.packet));
+   ret = xcoder_decode_init(avctx);
+   s->draining = draining;  // recover the draining state when resetting.
+   s->current_pts = bcp_current_pts;
+   s->api_ctx.session_run_state = SESSION_RUN_STATE_RESETTING;
+ 
+   // On VPU recovery send the cached sequence headers with IDR first.
+   if (s->seq_hdr_pkt.size > 0 &&
+       ff_xcoder_dec_send(avctx, s, &s->seq_hdr_pkt) < 0)
+   {
+     s->vpu_reset = 0;
+     return AVERROR_EXTERNAL;
+   }
+ 
+   return ret;
+ }
+ 
+ static int xcoder_send_receive(AVCodecContext *avctx,
+                                XCoderH264DecContext *s,
+                                AVFrame *frame, bool wait)
+ {
+   int ret;
+ 
+   if (s->buffered_pkt.size > 0)
+   {
+     ret = ff_xcoder_dec_send(avctx, s, &s->buffered_pkt);
+     if (ret == AVERROR(EAGAIN))
+     {
+       av_log(avctx, AV_LOG_DEBUG, "ff_xcoder_dec_send() return eagain\n");
+     }
+     else if (ret < 0)
+     {
+       return ret;
+     }
+     else
+     {
+       av_packet_unref(&s->buffered_pkt);
+     }
+   }
+ 
+   /* check for new frame */
+   ret = ff_xcoder_dec_receive(avctx, s, frame, wait);
+   if (NI_RETCODE_ERROR_VPU_RECOVERY == ret)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Failed to receive frame because of VPU recovery\n");
+     ret = xcoder_decode_reset(avctx);
+     if (0 == ret)
+     {
+       return AVERROR(EAGAIN);
+     }
+   }
+ 
+   return ret;
+ }
+ 
+ int xcoder_receive_frame(AVCodecContext *avctx, AVFrame *frame)
+ {
+   XCoderH264DecContext *s = avctx->priv_data;
+   int ret;
+   const AVPixFmtDescriptor *desc;
+ 
+   av_log(avctx, AV_LOG_DEBUG, "XCoder receive frame\n");
+ 
+   /*
+    * reference mediacodec_receive_frame in mediacodec.c.
+    *
+    * After we have buffered an input packet, check if the codec is in the
+    * flushing state. If it is, we need to call ff_xcoder_dec_flush.
+    *
+    * ff_xcoder_dec_flush returns 0 if the flush cannot be performed on
+    * the codec (because the user retains frames). The codec stays in the
+    * flushing state.
+    *
+    * ff_xcoder_dec_flush returns 1 if the flush can actually be
+    * performed on the codec. The codec leaves the flushing state and can
+    * process again packets.
+    *
+    * ff_xcoder_dec_flush returns a negative value if an error has
+    * occurred.
+    *
+    * NetInt: for now we don't consider the case of user retaining the frame
+    *         (connected decoder-encoder case), so the return can only be 1
+    *         (flushed successfully), or < 0 (failure)
+    */
+   if (ff_xcoder_dec_is_flushing(avctx, s))
+   {
+     if (!ff_xcoder_dec_flush(avctx, s))
+     {
+       return AVERROR(EAGAIN);
+     }
+   }
+ 
+   // give priority to sending data to decoder
+   if (s->buffered_pkt.size == 0)
+   {
+     ret = ff_decode_get_packet(avctx, &s->buffered_pkt);
+     if (ret < 0)
+     {
+       av_log(avctx, AV_LOG_DEBUG, "ff_decode_get_packet 1 rc: %s\n", av_err2str(ret));
+     }
+     else
+     {
+       av_log(avctx, AV_LOG_DEBUG, "ff_decode_get_packet 1 rc: Success\n");
+     }
+   }
+ 
+   /* flush buffered packet and check for new frame */
+   ret = xcoder_send_receive(avctx, s, frame, false);
+   if (ret != AVERROR(EAGAIN))
+   {
+     return ret;
+   }
+ 
+   /* skip fetching new packet if we still have one buffered */
+   if (s->buffered_pkt.size > 0)
+   {
+     return xcoder_send_receive(avctx, s, frame, true);
+   }
+ 
+   /* fetch new packet or eof */
+   ret = ff_decode_get_packet(avctx, &s->buffered_pkt);
+   if (ret < 0)
+   {
+     av_log(avctx, AV_LOG_DEBUG, "ff_decode_get_packet 2 rc: %s\n", av_err2str(ret));
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_DEBUG, "ff_decode_get_packet 2 rc: Success\n");
+   }
+ 
+   if (ret == AVERROR_EOF)
+   {
+     AVPacket null_pkt = {0};
+     ret = ff_xcoder_dec_send(avctx, s, &null_pkt);
+ 
+     /* ToDelete: mark end of stream; this should be signalled by Lib
+        s->eos = 1; */
+     if (ret < 0)
+     {
+       return ret;
+     }
+   }
+   else if (ret < 0)
+   {
+     return ret;
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_DEBUG, "width: %d  height: %d\n", avctx->width, avctx->height);
+     desc = av_pix_fmt_desc_get(avctx->pix_fmt);
+     av_log(avctx, AV_LOG_DEBUG, "pix_fmt: %s\n", desc ? desc->name : "NONE");
+   }
+ 
+   /* crank decoder with new packet */
+   return xcoder_send_receive(avctx, s, frame, true);
+ }
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/nidec.h FFmpeg-n4.3.1/libavcodec/nidec.h
*** base_ffmpeg_n4.3.1/libavcodec/nidec.h	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/nidec.h	2021-11-04 21:55:58.347593967 -0700
***************
*** 0 ****
--- 1,51 ----
+ /*
+  * NetInt XCoder H.264/HEVC Decoder common code header
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ #ifndef AVCODEC_NIDEC_H
+ #define AVCODEC_NIDEC_H
+ 
+ #include <stdbool.h>
+ #include <ni_rsrc_api.h>
+ #include <ni_util.h>
+ #include <ni_device_api.h>
+ 
+ #include "avcodec.h"
+ #include "decode.h"
+ #include "internal.h"
+ 
+ #include "libavutil/internal.h"
+ #include "libavutil/frame.h"
+ #include "libavutil/buffer.h"
+ #include "libavutil/pixdesc.h"
+ #include "libavutil/opt.h"
+ 
+ #include "nicodec.h"
+ 
+ int xcoder_decode_close(AVCodecContext *avctx);
+ 
+ int xcoder_decode_init (AVCodecContext *avctx);
+ 
+ int xcoder_decode_reset(AVCodecContext *avctx);
+ 
+ int xcoder_receive_frame(AVCodecContext *avctx, AVFrame *frame);
+ 
+ 
+ #endif /* AVCODEC_NIDEC_H */
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/nidec_h264.c FFmpeg-n4.3.1/libavcodec/nidec_h264.c
*** base_ffmpeg_n4.3.1/libavcodec/nidec_h264.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/nidec_h264.c	2021-11-04 21:55:58.347593967 -0700
***************
*** 0 ****
--- 1,96 ----
+ /*
+  * XCoder H.264 Decoder
+  * Copyright (c) 2018 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ /**
+  * @file
+  * XCoder decoder.
+  */
+ 
+ #include "nidec.h"
+ 
+ 
+ #define OFFSETDEC(x) offsetof(XCoderH264DecContext, x)
+ #define VD AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_DECODING_PARAM
+ static const AVOption dec_options[] = {
+   { "xcoder",    "Select which XCoder card to use.",  OFFSETDEC(dev_xcoder),
+     AV_OPT_TYPE_STRING, { .str = "bestload" }, CHAR_MIN, CHAR_MAX, VD, "xcoder" },
+ 
+   { "bestload",      "Pick the least loaded XCoder/decoder available.", 0, AV_OPT_TYPE_CONST,
+     { .str = "bestload" }, 0, 0, VD, "xcoder" },
+ 
+   { "bestinst",      "Pick the XCoder/decoder with the least number of running decoding instances.", 0, AV_OPT_TYPE_CONST,
+     { .str = "bestinst" }, 0, 0, VD, "xcoder" },
+ 
+   { "list",      "List the available XCoder cards.", 0, AV_OPT_TYPE_CONST,
+     { .str = "list" }, 0, 0, VD, "xcoder" },
+ 
+   { "dec",       "Select which decoder to use by index. First is 0, second is 1, and so on.", OFFSETDEC(dev_dec_idx),
+     AV_OPT_TYPE_INT, { .i64 = BEST_DEVICE_LOAD }, -1, INT_MAX, VD, "dec" },
+     
+   { "iosize",       "Specify a custom NVMe IO transfer size (multiples of 4096 only).", OFFSETDEC(nvme_io_size),
+     AV_OPT_TYPE_INT, { .i64 = BEST_DEVICE_LOAD }, -1, INT_MAX, VD, "iosize" },
+ 
+   { "keep_alive_timeout",       "Specify a custom session keep alive timeout in seconds.", OFFSETDEC(keep_alive_timeout),
+     AV_OPT_TYPE_INT, { .i64 = NI_DEFAULT_KEEP_ALIVE_TIMEOUT }, NI_MIN_KEEP_ALIVE_TIMEOUT, NI_MAX_KEEP_ALIVE_TIMEOUT, VD, "keep_alive_timeout" },
+ 
+   { "user_data_sei_passthru",       "Enable user data unregistered SEI passthrough.", OFFSETDEC(enable_user_data_sei_passthru),
+     AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VD, "user_data_sei_passthru" },
+ 
+   { "check_packet",       "Enable checking source packets. Skip SEI payloads after SLICE", OFFSETDEC(enable_check_packet),
+     AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VD, "check_packet" },
+ 
+   { "custom_sei_passthru",       "Specify a custom SEI type to passthrough.", OFFSETDEC(custom_sei),
+     AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 254, VD, "custom_sei_passthru" },
+ 
+   { "low_delay",       "Specify a decode timeout value (in milliseconds, recommended value is 600) "
+     "to enable low delay mode. Should be used only for streams that are in sequence.", OFFSETDEC(low_delay),
+     AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 10000, VD, "low_delay" },
+ 
+   { "hwframes",       "Use hwframes to reduce YUV buffer traffic.", OFFSETDEC(hwFrames),
+     AV_OPT_TYPE_INT,{ .i64 = HW_FRAMES_OFF }, 0, INT_MAX, VD, "hwFrames" },
+ 
+   { "xcoder-params", "Set the XCoder configuration using a :-separated list of key=value parameters", OFFSETDEC(xcoder_opts),
+     AV_OPT_TYPE_STRING,{ 0 }, 0, 0, VD },
+ 
+   { NULL }
+ };
+ 
+ static const AVClass h264_xcoderdec_class = {
+   .class_name = "h264_ni_dec",
+   .item_name = av_default_item_name,
+   .option = dec_options,
+   .version = LIBAVUTIL_VERSION_INT,
+ };
+ 
+ AVCodec ff_h264_ni_decoder = {
+   .name           = "h264_ni_dec",
+   .long_name      = NULL_IF_CONFIG_SMALL("H.264 NetInt decoder v" NI_XCODER_REVISION),
+   .type           = AVMEDIA_TYPE_VIDEO,
+   .id             = AV_CODEC_ID_H264,
+   .priv_data_size = sizeof(XCoderH264DecContext),
+   .priv_class     = &h264_xcoderdec_class,
+   .init           = xcoder_decode_init,
+   .receive_frame  = xcoder_receive_frame,
+   .close          = xcoder_decode_close,
+   .capabilities   = AV_CODEC_CAP_AVOID_PROBING | AV_CODEC_CAP_DELAY |
+                     FF_CODEC_CAP_SETS_PKT_DTS | AV_CODEC_CAP_HARDWARE,
+   .bsfs           = "h264_mp4toannexb",
+ };
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/nidec_hevc.c FFmpeg-n4.3.1/libavcodec/nidec_hevc.c
*** base_ffmpeg_n4.3.1/libavcodec/nidec_hevc.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/nidec_hevc.c	2021-11-04 21:55:58.347593967 -0700
***************
*** 0 ****
--- 1,96 ----
+ /*
+  * XCoder HEVC Decoder
+  * Copyright (c) 2018 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ /**
+  * @file
+  * XCoder decoder.
+  */
+ 
+ #include "nidec.h"
+ 
+ 
+ #define OFFSETDEC(x) offsetof(XCoderH264DecContext, x)
+ #define VD AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_DECODING_PARAM
+ static const AVOption dec_options[] = {
+   { "xcoder",    "Select which XCoder card to use.",  OFFSETDEC(dev_xcoder),
+     AV_OPT_TYPE_STRING, { .str = "bestload" }, CHAR_MIN, CHAR_MAX, VD, "xcoder" },
+ 
+   { "bestload",      "Pick the least loaded XCoder/decoder available.", 0, AV_OPT_TYPE_CONST,
+     { .str = "bestload" }, 0, 0, VD, "xcoder" },
+ 
+   { "bestinst",      "Pick the XCoder/decoder with the least number of running decoding instances.", 0, AV_OPT_TYPE_CONST,
+     { .str = "bestinst" }, 0, 0, VD, "xcoder" },
+ 
+   { "list",      "List the available XCoder cards.", 0, AV_OPT_TYPE_CONST,
+     { .str = "list" }, 0, 0, VD, "xcoder" },
+ 
+   { "dec",       "Select which decoder to use by index. First is 0, second is 1, and so on.", OFFSETDEC(dev_dec_idx),
+     AV_OPT_TYPE_INT, { .i64 = BEST_DEVICE_LOAD }, -1, INT_MAX, VD, "dec" },
+     
+   { "iosize",       "Specify a custom NVMe IO transfer size (multiples of 4096 only).", OFFSETDEC(nvme_io_size),
+     AV_OPT_TYPE_INT, { .i64 = BEST_DEVICE_LOAD }, -1, INT_MAX, VD, "iosize" },
+ 
+   { "keep_alive_timeout",       "Specify a custom session keep alive timeout in seconds.", OFFSETDEC(keep_alive_timeout),
+     AV_OPT_TYPE_INT, { .i64 = NI_DEFAULT_KEEP_ALIVE_TIMEOUT }, NI_MIN_KEEP_ALIVE_TIMEOUT, NI_MAX_KEEP_ALIVE_TIMEOUT, VD, "keep_alive_timeout" },
+ 
+   { "user_data_sei_passthru",       "Enable user data unregistered SEI passthrough.", OFFSETDEC(enable_user_data_sei_passthru),
+     AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VD, "user_data_sei_passthru" },
+ 
+   { "check_packet",       "Enable checking source packets. Skip SEI payloads after SLICE", OFFSETDEC(enable_check_packet),
+     AV_OPT_TYPE_BOOL, { .i64 = 0 }, 0, 1, VD, "check_packet" },
+ 
+   { "custom_sei_passthru",       "Specify a custom SEI type to passthrough.", OFFSETDEC(custom_sei),
+     AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 254, VD, "custom_sei_passthru" },
+ 
+   { "low_delay",       "Specify a decode timeout value (in milliseconds, recommended value is 600) "
+     "to enable low delay mode. Should be used only for streams that are in sequence.", OFFSETDEC(low_delay),
+     AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 10000, VD, "low_delay" },
+ 
+   { "hwframes",       "Use hwframes to reduce YUV buffer traffic.", OFFSETDEC(hwFrames),
+     AV_OPT_TYPE_INT,{ .i64 = HW_FRAMES_OFF }, 0, INT_MAX, VD, "hwFrames" },
+ 
+   { "xcoder-params", "Set the XCoder configuration using a :-separated list of key=value parameters", OFFSETDEC(xcoder_opts),
+     AV_OPT_TYPE_STRING,{ 0 }, 0, 0, VD },
+ 
+   { NULL }
+ };
+ 
+ static const AVClass h265_xcoderdec_class = {
+   .class_name = "h265_ni_dec",
+   .item_name = av_default_item_name,
+   .option = dec_options,
+   .version = LIBAVUTIL_VERSION_INT,
+ };
+ 
+ AVCodec ff_h265_ni_decoder = {
+   .name           = "h265_ni_dec",
+   .long_name      = NULL_IF_CONFIG_SMALL("H.265 NetInt decoder v" NI_XCODER_REVISION),
+   .type           = AVMEDIA_TYPE_VIDEO,
+   .id             = AV_CODEC_ID_HEVC,
+   .priv_data_size = sizeof(XCoderH264DecContext),
+   .priv_class     = &h265_xcoderdec_class,
+   .init           = xcoder_decode_init,
+   .receive_frame  = xcoder_receive_frame,
+   .close          = xcoder_decode_close,
+   .capabilities   = AV_CODEC_CAP_AVOID_PROBING | AV_CODEC_CAP_DELAY |
+                     FF_CODEC_CAP_SETS_PKT_DTS | AV_CODEC_CAP_HARDWARE,
+   .bsfs           = "hevc_mp4toannexb",
+ };
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/nienc.c FFmpeg-n4.3.1/libavcodec/nienc.c
*** base_ffmpeg_n4.3.1/libavcodec/nienc.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/nienc.c	2022-01-30 21:44:04.793495205 -0800
***************
*** 0 ****
--- 1,4501 ----
+ /*
+  * NetInt XCoder H.264/HEVC Encoder common code
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ #ifdef __linux__
+ #include <unistd.h>
+ #include <arpa/inet.h>
+ #endif
+ #include "libavutil/mastering_display_metadata.h"
+ #include "libavcodec/put_bits.h"
+ #include "libavcodec/golomb.h"
+ #include "libavcodec/hevc.h"
+ #include "libavcodec/hevc_sei.h"
+ #include "libavcodec/h264.h"
+ #include "libavcodec/h264_sei.h"
+ #include "libavutil/hdr_dynamic_metadata.h"
+ #include "libavutil/hwcontext.h"
+ #include "libavutil/hwcontext_internal.h"
+ #include "libavutil/hwcontext_ni.h"
+ #include "bytestream.h"
+ #include "nienc.h"
+ 
+ #define ODD2EVEN(X) ((X&1)&&(X>31))?(X+1):(X)
+ #define BR_SHIFT  6
+ #define CPB_SHIFT 4
+ 
+ #ifdef NIENC_MULTI_THREAD
+ threadpool_t pool;
+ int sessionCounter = 0;
+ 
+ typedef struct _write_thread_arg_struct_t
+ {
+   pthread_mutex_t mutex; //mutex
+   pthread_cond_t cond;   //cond
+   int running;
+   XCoderH265EncContext *ctx;
+   ni_retcode_t ret;
+ }write_thread_arg_struct_t;
+ #endif
+ 
+ typedef enum
+ {
+   SLICE_TYPE_B = 0,
+   SLICE_TYPE_P = 1,
+   SLICE_TYPE_I = 2,
+   SLICE_TYPE_MP = 3
+ } slice_type_t;
+ 
+ typedef enum
+ {
+   GOP_PRESET_CUSTOM        = 0,
+   GOP_PRESET_I_1           = 1,
+   GOP_PRESET_P_1           = 2,
+   GOP_PRESET_B_1           = 3,
+   GOP_PRESET_BP_2          = 4,
+   GOP_PRESET_BBBP_3        = 5,
+   GOP_PRESET_LP_4          = 6,
+   GOP_PRESET_LD_4          = 7,
+   GOP_PRESET_RA_8          = 8,
+   // single_ref
+   GOP_PRESET_SP_1          = 9,
+   GOP_PRESET_BSP_2         = 10,
+   GOP_PRESET_BBBSP_3       = 11,
+   GOP_PRESET_LSP_4         = 12,
+ 
+   // newly added
+   GOP_PRESET_BBP_3         = 13,
+   GOP_PRESET_BBSP_3        = 14,
+   GOP_PRESET_BBBBBBBP_8    = 15,
+   GOP_PRESET_BBBBBBBSP_8   = 16,
+   NUM_GOP_PRESET_NUM       = 17,
+ } gop_preset_t;
+ 
+ static const int32_t GOP_SIZE[NUM_GOP_PRESET_NUM] = {0, 1, 1, 1, 2, 4, 4, 4, 8, 1, 2, 4, 4};
+ static const int32_t LT_GOP_PRESET_I_1[6] = {SLICE_TYPE_I,  1, 0, 0, 0, 0};
+ static const int32_t LT_GOP_PRESET_P_1[6] = {SLICE_TYPE_MP, 1, 1, 0, 0, -1};
+ static const int32_t LT_GOP_PRESET_B_1[6] = {SLICE_TYPE_B,  1, 1, 0, 0, -1};
+ // gop_size = 2
+ static const int32_t LT_GOP_PRESET_BP_2[12] =
+ {
+   SLICE_TYPE_MP, 2, 1, 0, 0, -2,
+   SLICE_TYPE_B,  1, 3, 0, 0, 2,
+ };
+ // gop_size = 4
+ static const int32_t LT_GOP_PRESET_BBBP_4[24] =
+ {
+   SLICE_TYPE_MP, 4, 1, 0, 0, -4,
+   SLICE_TYPE_B,  2, 3, 0, 0, 4,
+   SLICE_TYPE_B,  1, 5, 0, 0, 2,
+   SLICE_TYPE_B,  3, 5, 0, 2, 4,
+ };
+ 
+ static const int32_t LT_GOP_PRESET_LP_4[24] =
+ {
+   SLICE_TYPE_MP, 1, 5, 0, 0, -4,
+   SLICE_TYPE_MP, 2, 3, 0, 1, 0,
+   SLICE_TYPE_MP, 3, 5, 0, 2, 0,
+   SLICE_TYPE_MP, 4, 1, 0, 3, 0,
+ };
+ static const int32_t LT_GOP_PRESET_LD_4[24] =
+ {
+   SLICE_TYPE_B, 1, 5, 0, 0, -4,
+   SLICE_TYPE_B, 2, 3, 0, 1, 0,
+   SLICE_TYPE_B, 3, 5, 0, 2, 0,
+   SLICE_TYPE_B, 4, 1, 0, 3, 0,
+ };
+ // gop_size = 8
+ static const int32_t LT_GOP_PRESET_RA_8[48] =
+ {
+   SLICE_TYPE_B, 8, 1, 0, 0, -8,
+   SLICE_TYPE_B, 4, 3, 0, 0, 8,
+   SLICE_TYPE_B, 2, 5, 0, 0, 4,
+   SLICE_TYPE_B, 1, 8, 0, 0, 2,
+   SLICE_TYPE_B, 3, 8, 0, 2, 4,
+   SLICE_TYPE_B, 6, 5, 0, 4, 8,
+   SLICE_TYPE_B, 5, 8, 0, 4, 6,
+   SLICE_TYPE_B, 7, 8, 0, 6, 8,
+ };
+ // single-ref-P
+ static const int32_t LT_GOP_PRESET_SP_1[6] = {SLICE_TYPE_P, 1, 1, 0, 0, -1};
+ 
+ static const int32_t LT_GOP_PRESET_BSP_2[12] =
+ {
+   SLICE_TYPE_P, 2, 1, 0, 0, -2,
+   SLICE_TYPE_B, 1, 3, 0, 0, 2,
+ };
+ static const int32_t LT_GOP_PRESET_BBBSP_4[24] =
+ {
+   SLICE_TYPE_P, 4, 1, 0, 0, -4,
+   SLICE_TYPE_B, 2, 3, 0, 0, 4,
+   SLICE_TYPE_B, 1, 5, 0, 0, 2,
+   SLICE_TYPE_B, 3, 5, 0, 2, 4,
+ };
+ static const int32_t LT_GOP_PRESET_LSP_4[24] =
+ {
+   SLICE_TYPE_P, 1, 5, 0, 0, -4,
+   SLICE_TYPE_P, 2, 3, 0, 1, 0,
+   SLICE_TYPE_P, 3, 5, 0, 2, 0,
+   SLICE_TYPE_P, 4, 1, 0, 3, 0,
+ };
+ 
+ static const int32_t LT_GOP_PRESET_BBP_3[18] =
+ {
+   SLICE_TYPE_MP, 3, 1, 0, 0, -3,
+   SLICE_TYPE_B, 1, 3, 0, 0, 3,
+   SLICE_TYPE_B, 2, 6, 0, 1, 3,
+ };
+ 
+ static const int32_t LT_GOP_PRESET_BBSP_3[18] =
+ {
+   SLICE_TYPE_P, 3, 1, 0, 0, 0,
+   SLICE_TYPE_B, 1, 3, 0, 0, 3,
+   SLICE_TYPE_B, 2, 6, 0, 1, 3,
+ };
+ 
+ static const int32_t LT_GOP_PRESET_BBBBBBBP_8[48] =
+ {
+   SLICE_TYPE_MP, 8, 1, 0, 0, -8,
+   SLICE_TYPE_B, 4, 3, 0, 0, 8,
+   SLICE_TYPE_B, 2, 5, 0, 0, 4,
+   SLICE_TYPE_B, 1, 8, 0, 0, 2,
+   SLICE_TYPE_B, 3, 8, 0, 2, 4,
+   SLICE_TYPE_B, 6, 5, 0, 4, 8,
+   SLICE_TYPE_B, 5, 8, 0, 4, 6,
+   SLICE_TYPE_B, 7, 8, 0, 6, 8,
+ };
+ static const int32_t LT_GOP_PRESET_BBBBBBBSP_8[48] =
+ {
+   SLICE_TYPE_P, 8, 1, 0, 0, 0,
+   SLICE_TYPE_B, 4, 3, 0, 0, 8,
+   SLICE_TYPE_B, 2, 5, 0, 0, 4,
+   SLICE_TYPE_B, 1, 8, 0, 0, 2,
+   SLICE_TYPE_B, 3, 8, 0, 2, 4,
+   SLICE_TYPE_B, 6, 5, 0, 4, 8,
+   SLICE_TYPE_B, 5, 8, 0, 4, 6,
+   SLICE_TYPE_B, 7, 8, 0, 6, 8,
+ };
+ static const int32_t* GOP_PRESET[NUM_GOP_PRESET_NUM] =
+ {
+   NULL,
+   LT_GOP_PRESET_I_1,
+   LT_GOP_PRESET_P_1,
+   LT_GOP_PRESET_B_1,
+   LT_GOP_PRESET_BP_2,
+   LT_GOP_PRESET_BBBP_4,
+   LT_GOP_PRESET_LP_4,
+   LT_GOP_PRESET_LD_4,
+   LT_GOP_PRESET_RA_8,
+ 
+   LT_GOP_PRESET_SP_1,
+   LT_GOP_PRESET_BSP_2,
+   LT_GOP_PRESET_BBBSP_4,
+   LT_GOP_PRESET_LSP_4,
+ 
+   LT_GOP_PRESET_BBP_3    ,
+   LT_GOP_PRESET_BBSP_3   ,
+   LT_GOP_PRESET_BBBBBBBP_8 ,
+   LT_GOP_PRESET_BBBBBBBSP_8,
+ };
+ 
+ static void init_gop_param(ni_custom_gop_params_t *gopParam, ni_encoder_params_t *param)
+ {
+   int i;
+   int j;
+   int gopSize;
+   int gopPreset = param->hevc_enc_params.gop_preset_index;
+ 
+   // GOP_PRESET_IDX_CUSTOM
+   if (gopPreset == 0)
+   {
+     memcpy(gopParam, &param->hevc_enc_params.custom_gop_params,
+            sizeof(ni_custom_gop_params_t));
+   }
+   else
+   {
+     const int32_t*  src_gop = GOP_PRESET[gopPreset];
+     gopSize = GOP_SIZE[gopPreset];
+     gopParam->custom_gop_size = gopSize;
+     for(i = 0, j = 0; i < gopSize; i++)
+     {
+       gopParam->pic_param[i].pic_type      = src_gop[j++];
+       gopParam->pic_param[i].poc_offset    = src_gop[j++];
+       gopParam->pic_param[i].pic_qp        = src_gop[j++] + param->hevc_enc_params.rc.intra_qp;
+       gopParam->pic_param[i].temporal_id   = src_gop[j++];
+       gopParam->pic_param[i].ref_poc_L0    = src_gop[j++];
+       gopParam->pic_param[i].ref_poc_L1    = src_gop[j++];
+     }
+   }
+ }
+ 
+ static int check_low_delay_flag(ni_encoder_params_t *param,
+                                 ni_custom_gop_params_t *gopParam)
+ {
+   int i;
+   int minVal = 0;
+   int low_delay = 0;
+   int gopPreset = param->hevc_enc_params.gop_preset_index;
+ 
+   // GOP_PRESET_IDX_CUSTOM
+   if (gopPreset == 0)
+   {
+     if (gopParam->custom_gop_size > 1)
+     {
+       minVal = gopParam->pic_param[0].poc_offset;
+       low_delay = 1;
+       for (i = 1; i < gopParam->custom_gop_size; i++)
+       {
+         if (minVal > gopParam->pic_param[i].poc_offset)
+         {
+           low_delay = 0;
+           break;
+         }
+         else
+         {
+           minVal = gopParam->pic_param[i].poc_offset;
+         }
+       }
+     }
+   }
+   else if (gopPreset == 1 || gopPreset == 2 || gopPreset == 3 ||
+            gopPreset == 6 || gopPreset == 7 || gopPreset == 9)
+   {
+     low_delay = 1;
+   }
+ 
+   return low_delay;
+ }
+ 
+ static int get_num_reorder_of_gop_structure(ni_encoder_params_t *param)
+ {
+   int i;
+   int j;
+   int ret_num_reorder = 0;
+   ni_custom_gop_params_t gopParam;
+ 
+   init_gop_param(&gopParam, param);
+   for(i = 0; i < gopParam.custom_gop_size; i++)
+   {
+     int check_reordering_num = 0;
+     int num_reorder = 0;
+ 
+     ni_gop_params_t *gopPicParam = &gopParam.pic_param[i];
+ 
+     for(j = 0; j < gopParam.custom_gop_size; j++)
+     {
+       ni_gop_params_t *gopPicParamCand = &gopParam.pic_param[j];
+       if (gopPicParamCand->poc_offset <= gopPicParam->poc_offset)
+         check_reordering_num = j;
+     }
+ 
+     for(j = 0; j < check_reordering_num; j++)
+     {
+       ni_gop_params_t *gopPicParamCand = &gopParam.pic_param[j];
+ 
+       if (gopPicParamCand->temporal_id <= gopPicParam->temporal_id &&
+           gopPicParamCand->poc_offset > gopPicParam->poc_offset)
+         num_reorder++;
+     }
+     ret_num_reorder = num_reorder;
+   }
+   return ret_num_reorder;
+ }
+ 
+ static int get_max_dec_pic_buffering_of_gop_structure(ni_encoder_params_t *param)
+ {
+   int max_dec_pic_buffering;
+   max_dec_pic_buffering = FFMIN(16/*MAX_NUM_REF*/, FFMAX(get_num_reorder_of_gop_structure(param) + 2, 6 /*maxnumreference in spec*/) + 1);
+   return max_dec_pic_buffering;
+ }
+ 
+ static int get_poc_of_gop_structure(ni_encoder_params_t *param,
+                                     uint32_t frame_idx)
+ {
+   int low_delay;
+   int gopSize;
+   int poc;
+   int gopIdx;
+   int gopNum;
+   ni_custom_gop_params_t gopParam;
+ 
+   init_gop_param(&gopParam, param);
+   gopSize = gopParam.custom_gop_size;
+   low_delay = check_low_delay_flag(param, &gopParam);
+ 
+   if (low_delay)
+   {
+     poc = frame_idx;
+   }
+   else
+   {
+     gopIdx = frame_idx % gopSize;
+     gopNum = frame_idx / gopSize;
+     poc = gopParam.pic_param[gopIdx].poc_offset + (gopSize * gopNum);
+   }
+   //printf("get_poc_of_gop_structure frameIdx=%d, poc=%d, low_delay=%d, gopIdx=%d, gopNum=%d, gopSize=%d \n", frame_idx, poc, low_delay, gopIdx, gopNum, gopSize);
+ 
+   poc += gopSize - 1; // use gop_size - 1 as offset
+   return poc;
+ }
+ 
+ static inline int calc_scale(uint32_t x)
+ {
+   static uint8_t lut[16] = {4, 0, 1, 0, 2, 0, 1, 0, 3, 0, 1, 0, 2, 0, 1, 0};
+   int y, z = (((x & 0xffff) - 1) >> 27) & 16;
+   x >>= z;
+   z += y = (((x & 0xff) - 1) >> 28) & 8;
+   x >>= y;
+   z += y = (((x & 0xf) - 1) >> 29) & 4;
+   x >>= y;
+   return z + lut[x&0xf];
+ }
+ 
+ static inline int clip3(int min, int max, int a)
+ {
+   return FFMIN(FFMAX(min, a), max);
+ }
+ 
+ static inline int calc_length(uint32_t x)
+ {
+   static uint8_t lut[16] = {4, 3, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0};
+   int y, z = (((x >> 16) - 1) >> 27) & 16;
+   x >>= z ^ 16;
+   z += y = ((x - 0x100) >> 28) & 8;
+   x >>= y ^ 8;
+   z += y = ((x - 0x10) >> 29) & 4;
+   x >>= y ^ 4;
+   return z + lut[x];
+ }
+ 
+ static uint32_t encode_buffering_period_sei(ni_encoder_params_t *p_param,
+                                             XCoderH265EncContext *ctx,
+                                             uint32_t frame_idx,
+                                             uint8_t *p_buf)
+ {
+   PutBitContext pbc;
+   int32_t payload_bit_size = 0, payload_byte_size = 0, put_bit_byte_size = 0;
+   uint32_t nal_initial_cpb_removal_delay, nal_initial_cpb_removal_offset;
+   int i;
+   uint32_t concatenation_flag = get_poc_of_gop_structure(p_param, frame_idx) == 0 ? 1 : 0;
+   if (ctx->api_ctx.frame_num == 0)
+   {
+     concatenation_flag = 1;
+   }
+   init_put_bits(&pbc, p_buf, NI_MAX_SEI_DATA);
+ 
+   payload_bit_size += 1; // bp_seq_parameter_set_id=0, 1 bit
+   payload_bit_size += 1; // irap_cpb_params_present_flag=0, 1 bit
+   payload_bit_size += 1; // concatenation_flag, 1 bit
+   // au_cpb_removal_delay_delta_minus1
+   payload_bit_size += (ctx->au_cpb_removal_delay_length_minus1 + 1);
+ 
+   // nal_hrd_parameters_present_flag=1
+   // CpbCnt = cpb_cnt_minus1[0] + 1 = 0 + 1
+   for (i = 0; i < 1; i++)
+   {
+     // nal_initial_cpb_removal_delay
+     payload_bit_size += ctx->initial_cpb_removal_delay_length_minus1 + 1;
+     // nal_initial_cpb_removal_offset
+     payload_bit_size += ctx->initial_cpb_removal_delay_length_minus1 + 1;
+   }
+ 
+   // vcl_hrd_parameters_present_flag=0
+ 
+   put_bits32(&pbc, 1); // NAL start code
+   // NAL unit header nal_unit_type=39, layer_id=0, temporal_id_plus1=1
+   put_bits(&pbc, 16, (39 << 9) | (0 << 3) | 1);
+   put_bits(&pbc, 8, 0); // payload_type=0 (buffering_period)
+   payload_byte_size = (payload_bit_size + 7) / 8;
+   put_bits(&pbc, 8, payload_byte_size);// payload size (byte)
+ 
+   // buffering period
+   set_ue_golomb_long(&pbc, 0); // bp_seq_parameter_set_id=0
+   put_bits(&pbc, 1, 0); // irap_cpb_params_present_flag=0
+   put_bits(&pbc, 1, concatenation_flag); // concatenation_flag
+   // au_cpb_removal_delay_delta_minus1=0
+   put_bits(&pbc, ctx->au_cpb_removal_delay_length_minus1 + 1, 0);
+ 
+   nal_initial_cpb_removal_delay =
+   (uint32_t)(90000 * ctx->cpb_size_unscale / ctx->bit_rate_unscale);
+   nal_initial_cpb_removal_offset =
+   (uint32_t)((90000 * ctx->cpb_size_unscale / ctx->bit_rate_unscale) -
+              nal_initial_cpb_removal_delay);
+ 
+   // nal_hrd_parameters_present_flag=1
+   // CpbCnt = cpb_cnt_minus1[0] + 1 = 0 + 1
+   for (i = 0; i < 1; i++)
+   {
+     // nal_initial_cpb_removal_delay
+     put_bits(&pbc, ctx->initial_cpb_removal_delay_length_minus1 + 1,
+              nal_initial_cpb_removal_delay);
+     // nal_initial_cpb_removal_offset
+     put_bits(&pbc, ctx->initial_cpb_removal_delay_length_minus1 + 1,
+              nal_initial_cpb_removal_offset);
+   }
+ 
+   // vcl_hrd_parameters_present_flag=0
+ 
+   if (payload_bit_size % 8)
+   {
+     // fill in bit 1 and padding 0s for byte alignment
+     put_bits(&pbc, 1, 1/*payload_bit_equal_to_one*/);
+     for (i = 0; i < 8 - (payload_bit_size % 8) - 1; i++)
+     {
+       put_bits(&pbc, 1, 0/*payload_bit_equal_to_zero*/);
+     }
+   }
+ 
+   // rbsp trailing stop bit and alignment padding 0s
+   put_bits(&pbc, 8, 0x80);
+ 
+   flush_put_bits(&pbc);
+   put_bit_byte_size = (put_bits_count(&pbc) + 7) / 8;
+ 
+   // emulation prevention checking of payload, skipping start code (4B) +
+   // NAL header (2B) + payload type (1B) + payload size (1B) = 8B
+   put_bit_byte_size += insert_emulation_prevent_bytes(
+     p_buf + 8, put_bit_byte_size - 8);
+ 
+   return put_bit_byte_size;
+ }
+ 
+ static uint32_t encode_pic_timing_sei2(ni_encoder_params_t *p_param,
+                                        XCoderH265EncContext *ctx,
+                                        uint8_t *p_buf, int is_i_or_idr,
+                                        int is_idr, uint32_t frame_idx)
+ {
+   PutBitContext pbc;
+   int32_t payload_bit_size = 0, payload_byte_size = 0, put_bit_byte_size = 0;
+   uint32_t pic_dpb_output_delay = 0;
+   int num_reorder_pic;
+   uint64_t poc_pic;
+ 
+   init_put_bits(&pbc, p_buf, NI_MAX_SEI_DATA);
+ 
+   // frame_field_info_present_flag=0 TBD
+   //payload_bit_size += 4/*pic_struct*/ + 2/*source_scan_type*/ + 1/*duplicate_flag*/;
+ 
+   // CpbDpbDelaysPresentFlag=1
+   // au_cpb_removal_delay_length_minus1
+   payload_bit_size += (ctx->au_cpb_removal_delay_length_minus1 + 1);
+   // pic_dpb_output_delay
+   payload_bit_size += (ctx->dpb_output_delay_length_minus1+ 1);
+ 
+   // sub_pic_hrd_params_present_flag=0
+ 
+   put_bits32(&pbc, 1); // NAL start code
+   // NAL unit header nal_unit_type=39, layer_id=0, temporal_id_plus1=1
+   put_bits(&pbc, 16, (39 << 9) | (0 << 3) | 1);
+   put_bits(&pbc, 8, 1); // payload_type=1 (picture_timing)
+   payload_byte_size = (payload_bit_size + 7) / 8;
+   put_bits(&pbc, 8, payload_byte_size);// payload size (byte)
+ 
+   // pic timing
+ 
+   num_reorder_pic = get_num_reorder_of_gop_structure(p_param);
+   poc_pic = get_poc_of_gop_structure(p_param, frame_idx);
+   pic_dpb_output_delay = num_reorder_pic + poc_pic - frame_idx;
+ 
+   //printf(" ----> num_reorder_pic %d + poc_pic %llu - frame_idx %u\n", num_reorder_pic,
+   //poc_pic, frame_idx);
+   //printf(" ----> #%u %s au_cpb_removal_delay_minus1 %u  pic_dpb_output_delay %u\n", frame_idx, is_idr ? "is_idr" : " ", ctx->au_cpb_removal_delay_minus1, pic_dpb_output_delay);
+ 
+   // CpbDpbDelaysPresentFlag=1
+   // au_cpb_removal_delay_length_minus1
+   put_bits(&pbc, ctx->au_cpb_removal_delay_length_minus1 + 1,
+            ctx->au_cpb_removal_delay_minus1);
+   ctx->au_cpb_removal_delay_minus1++;
+ 
+   if (1 == p_param->hevc_enc_params.gop_preset_index &&
+       p_param->hevc_enc_params.intra_period)
+   {
+     if (0 == frame_idx || is_idr ||
+         0 == (ctx->au_cpb_removal_delay_minus1 % p_param->hevc_enc_params.intra_period))
+     {
+       ctx->au_cpb_removal_delay_minus1 = 0;
+     }
+   }
+   else if (is_i_or_idr)
+   {
+     ctx->au_cpb_removal_delay_minus1 = 0;
+   }
+ 
+   // pic_dpb_output_delay
+   put_bits(&pbc, ctx->dpb_output_delay_length_minus1 + 1, pic_dpb_output_delay);
+ 
+   if (payload_bit_size & 7)
+   {
+     put_bits(&pbc, 1, 1/*payload_bit_equal_to_one*/);
+     put_bits(&pbc, (8 - (payload_bit_size & 7)-1), 0/*payload_bit_equal_to_zero*/);
+   }
+ 
+   // rbsp trailing stop bit and alignment padding 0s
+   put_bits(&pbc, 8, 0x80);
+ 
+   flush_put_bits(&pbc);
+   put_bit_byte_size = (put_bits_count(&pbc) + 7) / 8;
+ 
+   // emulation prevention checking of payload, skipping start code (4B) +
+   // NAL header (2B) + payload type (1B) + payload size (1B) = 8B
+   put_bit_byte_size += insert_emulation_prevent_bytes(
+     p_buf + 8, put_bit_byte_size - 8);
+ 
+   return put_bit_byte_size;
+ }
+ 
+ #define SAMPLE_SPS_MAX_SUB_LAYERS_MINUS1 0
+ #define MAX_VPS_MAX_SUB_LAYERS 16
+ #define MAX_CPB_COUNT 16
+ #define MAX_DURATION 0.5
+ 
+ static void setVui(AVCodecContext *avctx, ni_encoder_params_t *p_param,
+                    XCoderH265EncContext *ctx,
+                    enum AVColorPrimaries color_primaries,
+                    enum AVColorTransferCharacteristic color_trc,
+                    enum AVColorSpace color_space,
+                    int video_full_range_flag)
+ {
+   int isHEVC = (AV_CODEC_ID_HEVC == avctx->codec_id ? 1 : 0);
+   PutBitContext pbcPutBitContext;
+   unsigned int aspect_ratio_idc = 255; // default: extended_sar
+   int nal_hrd_parameters_present_flag=1, vcl_hrd_parameters_present_flag=0;
+   int layer, cpb;
+   int maxcpboutputdelay;
+   int maxdpboutputdelay;
+   int maxdelay;
+   uint32_t vbvbuffersize = (p_param->bitrate / 1000) * p_param->hevc_enc_params.rc.rc_init_delay;
+   uint32_t vbvmaxbitrate = p_param->bitrate;
+   uint32_t vps_max_sub_layers_minus1 = SAMPLE_SPS_MAX_SUB_LAYERS_MINUS1;
+   uint32_t bit_rate_value_minus1[MAX_CPB_COUNT][MAX_VPS_MAX_SUB_LAYERS];
+   uint32_t cpb_size_value_minus1[MAX_CPB_COUNT][MAX_VPS_MAX_SUB_LAYERS];
+   uint32_t cpb_cnt_minus1[MAX_VPS_MAX_SUB_LAYERS];
+ 
+   uint32_t fixed_pic_rate_general_flag[MAX_VPS_MAX_SUB_LAYERS];
+   uint32_t fixed_pic_rate_within_cvs_flag[MAX_VPS_MAX_SUB_LAYERS];
+   uint32_t elemental_duration_in_tc_minus1[MAX_VPS_MAX_SUB_LAYERS];
+ 
+   uint32_t bit_rate_scale = 2;
+   uint32_t cpb_size_scale = 5;
+   uint32_t numUnitsInTick = 1000;
+   uint32_t timeScale;
+   int32_t i32frameRateInfo = p_param->hevc_enc_params.frame_rate;
+ 
+   init_put_bits(&pbcPutBitContext, p_param->ui8VuiRbsp, NI_MAX_VUI_SIZE);
+ 
+   if (avctx->sample_aspect_ratio.num==0)
+   {
+     // sample aspect ratio is 0, don't include aspect_ratio_idc in vui
+     put_bits(&pbcPutBitContext, 1, 0);  //  aspect_ratio_info_present_flag=0
+   }
+   else
+   {
+     // sample aspect ratio is non-zero, include aspect_ratio_idc in vui
+     put_bits(&pbcPutBitContext, 1, 1);  //  aspect_ratio_info_present_flag=1
+ 
+     if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(1, 1)))
+     {
+       aspect_ratio_idc = 1;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(12, 11)))
+     {
+       aspect_ratio_idc = 2;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(10, 11)))
+     {
+       aspect_ratio_idc = 3;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(16, 11)))
+     {
+       aspect_ratio_idc = 4;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(40, 33)))
+     {
+       aspect_ratio_idc = 5;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(24, 11)))
+     {
+       aspect_ratio_idc = 6;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(20, 11)))
+     {
+       aspect_ratio_idc = 7;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(32, 11)))
+     {
+       aspect_ratio_idc = 8;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(80, 33)))
+     {
+       aspect_ratio_idc = 9;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(18, 11)))
+     {
+       aspect_ratio_idc = 10;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(15, 11)))
+     {
+       aspect_ratio_idc = 11;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(64, 33)))
+     {
+       aspect_ratio_idc = 12;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(160, 99)))
+     {
+       aspect_ratio_idc = 13;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(4, 3)))
+     {
+       aspect_ratio_idc = 14;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(3, 2)))
+     {
+       aspect_ratio_idc = 15;
+     }
+     else if (! av_cmp_q(avctx->sample_aspect_ratio, av_make_q(2, 1)))
+     {
+       aspect_ratio_idc = 16;
+     }
+ 
+     put_bits(&pbcPutBitContext, 8, aspect_ratio_idc);  // aspect_ratio_idc
+     if (255 == aspect_ratio_idc)
+     {
+       put_bits(&pbcPutBitContext, 16, avctx->sample_aspect_ratio.num);//sar_width
+       put_bits(&pbcPutBitContext, 16, avctx->sample_aspect_ratio.den);//sar_height
+     }
+   }
+ 
+   put_bits(&pbcPutBitContext, 1, 0);  //  overscan_info_present_flag=0
+ 
+   // for YUVJ420P pix fmt, indicate it's full range video
+   if (! video_full_range_flag && AV_PIX_FMT_YUVJ420P == avctx->pix_fmt)
+   {
+     av_log(avctx, AV_LOG_DEBUG, "setVui set video_full_range_flag for YUVJ420P "
+            "pix fmt.\n");
+     video_full_range_flag = 1;
+   }
+ 
+   // VUI Parameters
+   put_bits(&pbcPutBitContext, 1, 1);  //  video_signal_type_present_flag=1
+   put_bits(&pbcPutBitContext, 3, 5);  //  video_format=5 (unspecified)
+   put_bits(&pbcPutBitContext, 1, video_full_range_flag);
+   put_bits(&pbcPutBitContext, 1, 1);  //  colour_description_presenty_flag=1
+   put_bits(&pbcPutBitContext, 8, color_primaries);
+   put_bits(&pbcPutBitContext, 8, color_trc);
+   put_bits(&pbcPutBitContext, 8, color_space);
+ 
+   put_bits(&pbcPutBitContext, 1, 0);      //  chroma_loc_info_present_flag=0
+ 
+   if (isHEVC)
+   {   // H.265 Only VUI parameters
+     put_bits(&pbcPutBitContext, 1, 0);  //  neutral_chroma_indication_flag=0
+     put_bits(&pbcPutBitContext, 1, 0);  //  field_seq_flag=0
+     put_bits(&pbcPutBitContext, 1, 0);  //  frame_field_info_present_flag=0
+     put_bits(&pbcPutBitContext, 1, 0);  //  default_display_window_flag=0
+   }
+ 
+   put_bits(&pbcPutBitContext, 1, 1);      //  vui_timing_info_present_flag=1
+   p_param->pos_num_units_in_tick = put_bits_count(&pbcPutBitContext);
+   put_bits32(&pbcPutBitContext, 0);    //  vui_num_units_in_tick
+   p_param->pos_time_scale = put_bits_count(&pbcPutBitContext);
+   put_bits32(&pbcPutBitContext, 0);         //  vui_time_scale
+ 
+   if (isHEVC)
+   {
+     // H.265 Only VUI parameters
+     put_bits(&pbcPutBitContext, 1, 0);  //  vui_poc_proportional_to_timing_flag=0
+     if (! p_param->hrd_enable)
+     {
+       put_bits(&pbcPutBitContext, 1, 0);  //  vui_hrd_parameters_present_flag=0
+     }
+     else
+     {
+       put_bits(&pbcPutBitContext, 1, 1);  //  vui_hrd_parameters_present_flag=1
+ 
+       put_bits(&pbcPutBitContext, 1, 1); // nal_hrd_parameters_present_flag=1
+       put_bits(&pbcPutBitContext, 1, 0); // vcl_hrd_parameters_present_flag=0
+ 
+       put_bits(&pbcPutBitContext, 1, 0); // sub_pic_hrd_params_present_flag=0
+ 
+       ctx->initial_cpb_removal_delay_length_minus1 = 23;
+       ctx->au_cpb_removal_delay_length_minus1 = 23;
+ 
+       bit_rate_value_minus1[0][0] = 59374;
+       cpb_size_value_minus1[0][0] = 59374;
+       cpb_cnt_minus1[0] = 0;
+       fixed_pic_rate_general_flag[0] = 1;
+       fixed_pic_rate_within_cvs_flag[0] = 1;
+       elemental_duration_in_tc_minus1[0] = 0;
+ 
+       // normalize hrd size and rate to the value / scale notation
+       bit_rate_scale = clip3(0, 15, calc_scale(vbvmaxbitrate) - BR_SHIFT);
+       bit_rate_value_minus1[0][0] = (vbvmaxbitrate >> (bit_rate_scale + BR_SHIFT)) - 1;
+ 
+       cpb_size_scale = clip3(0, 15, calc_scale(vbvbuffersize) - CPB_SHIFT);
+       cpb_size_value_minus1[0][0] = (vbvbuffersize >> (cpb_size_scale + CPB_SHIFT)) - 1;
+ 
+       ctx->bit_rate_unscale = (bit_rate_value_minus1[0][0]+1) << (bit_rate_scale + BR_SHIFT);
+       ctx->cpb_size_unscale = (cpb_size_value_minus1[0][0]+1) << (cpb_size_scale + CPB_SHIFT);
+ 
+       if (p_param->fps_denominator != 0 &&
+           (p_param->fps_number % p_param->fps_denominator) != 0)
+       {
+         numUnitsInTick += 1;
+         i32frameRateInfo += 1;
+       }
+       timeScale = i32frameRateInfo * 1000;
+ 
+       maxcpboutputdelay = (int)(FFMIN(p_param->hevc_enc_params.intra_period * MAX_DURATION * timeScale / numUnitsInTick, INT_MAX));
+       maxdpboutputdelay = (int)(get_max_dec_pic_buffering_of_gop_structure(p_param) * MAX_DURATION * timeScale / numUnitsInTick);
+       maxdelay = (int)(90000.0 * ctx->cpb_size_unscale / ctx->bit_rate_unscale + 0.5);
+ 
+       ctx->initial_cpb_removal_delay_length_minus1 =
+       2 + clip3(4, 22, 32 - calc_length(maxdelay)) - 1;
+       ctx->au_cpb_removal_delay_length_minus1 =
+       clip3(4, 31, 32 - calc_length(maxcpboutputdelay)) - 1;
+       ctx->dpb_output_delay_length_minus1 =
+       clip3(4, 31, 32 - calc_length(maxdpboutputdelay)) - 1;
+ 
+       put_bits(&pbcPutBitContext, 4, bit_rate_scale); // bit_rate_scale
+       put_bits(&pbcPutBitContext, 4, cpb_size_scale); // cpb_size_scale
+ 
+       put_bits(&pbcPutBitContext, 5, ctx->initial_cpb_removal_delay_length_minus1);
+       put_bits(&pbcPutBitContext, 5, ctx->au_cpb_removal_delay_length_minus1);
+       put_bits(&pbcPutBitContext, 5, ctx->dpb_output_delay_length_minus1);
+ 
+       for (layer = 0; layer <= (int32_t)vps_max_sub_layers_minus1; layer++)
+       {
+         put_bits(&pbcPutBitContext, 1, fixed_pic_rate_general_flag[layer]);
+ 
+         if (! fixed_pic_rate_general_flag[layer])
+         {
+           put_bits(&pbcPutBitContext, 1, fixed_pic_rate_within_cvs_flag[layer]);
+         }
+ 
+         if (fixed_pic_rate_within_cvs_flag[layer])
+         {
+           set_ue_golomb_long(&pbcPutBitContext,
+                              elemental_duration_in_tc_minus1[layer]);
+         }
+ 
+         // low_delay_hrd_flag[layer] is not present and inferred to be 0
+ 
+         set_ue_golomb_long(&pbcPutBitContext, cpb_cnt_minus1[layer]);
+ 
+         if ((layer == 0 && nal_hrd_parameters_present_flag) ||
+             (layer == 1 && vcl_hrd_parameters_present_flag))
+         {
+           for(cpb = 0; cpb <= (int32_t)cpb_cnt_minus1[layer]; cpb++)
+           {
+             set_ue_golomb_long(&pbcPutBitContext,
+                                bit_rate_value_minus1[cpb][layer]);
+ 
+             set_ue_golomb_long(&pbcPutBitContext,
+                                cpb_size_value_minus1[cpb][layer]);
+ 
+             // cbr_flag is inferred to be 0 as well ?
+             put_bits(&pbcPutBitContext, 1, 0/*cbr_flag[cpb][layer]*/);
+           }
+         }
+       }
+     }
+     put_bits(&pbcPutBitContext, 1, 0);      //  bitstream_restriction_flag=0
+   }
+   else
+   {
+     int max_num_reorder_frames;
+     int num_ref_frames;
+     int max_dec_frame_buffering;
+     // H.264 Only VUI parameters
+     if (p_param->enable_vfr)
+     {
+       put_bits(&pbcPutBitContext, 1, 0);  //  fixed_frame_rate_flag=0
+     }
+     else
+     {
+       put_bits(&pbcPutBitContext, 1, 1);  //  fixed_frame_rate_flag=1
+     }
+     put_bits(&pbcPutBitContext, 1, 0);  //  nal_hrd_parameters_present_flag=0
+     put_bits(&pbcPutBitContext, 1, 0);  //  vui_hrd_parameters_present_flag=0
+     put_bits(&pbcPutBitContext, 1, 0);  //  pic_struct_present_flag=0
+ 
+     // this flag is set to 1 for H.264 to reduce decode delay, and fill in
+     // the rest of the section accordingly
+     put_bits(&pbcPutBitContext, 1, 1);  //  bitstream_restriction_flag=1
+     put_bits(&pbcPutBitContext, 1, 1);  //  motion_vectors_over_pic_boundaries_flag=1
+     set_ue_golomb_long(&pbcPutBitContext, 2); // max_bytes_per_pic_denom=2 (default)
+     set_ue_golomb_long(&pbcPutBitContext, 1); // max_bits_per_mb_denom=1 (default)
+     set_ue_golomb_long(&pbcPutBitContext, 15); // log2_max_mv_length_horizontal=15 (default)
+     set_ue_golomb_long(&pbcPutBitContext, 15); // log2_max_mv_length_vertical=15 (default)
+ 
+     // max_num_reorder_frames (0 for low delay gops)
+     max_num_reorder_frames = ni_get_num_reorder_of_gop_structure(p_param);
+     set_ue_golomb_long(&pbcPutBitContext, max_num_reorder_frames);
+     // max_dec_frame_buffering
+     num_ref_frames = ni_get_num_ref_frame_of_gop_structure(p_param);
+     max_dec_frame_buffering = (num_ref_frames > max_num_reorder_frames ?
+                                num_ref_frames : max_num_reorder_frames);
+     set_ue_golomb_long(&pbcPutBitContext, max_dec_frame_buffering);
+   }
+ 
+   p_param->ui32VuiDataSizeBits = put_bits_count(&pbcPutBitContext);
+   p_param->ui32VuiDataSizeBytes = (p_param->ui32VuiDataSizeBits + 7) / 8;
+   flush_put_bits(&pbcPutBitContext);      // flush bits
+ }
+ 
+ // convert FFmpeg ROIs to NetInt ROI map
+ static int set_roi_map(AVCodecContext *avctx, const AVFrameSideData *sd,
+                        int nb_roi, int width, int height, int intra_qp)
+ {
+   XCoderH265EncContext *ctx = avctx->priv_data;
+   int i, j, r, ctu;
+   const AVRegionOfInterest *roi = (const AVRegionOfInterest*)sd->data;
+   uint32_t self_size = roi->self_size;
+   uint8_t set_qp = 0;
+   float f_value;
+ 
+   if (AV_CODEC_ID_H264 == avctx->codec_id)
+   {
+     // roi for H.264 is specified for 16x16 pixel macroblocks - 1 MB
+     // is stored in each custom map entry.
+     // number of MBs in each row/column
+     uint32_t mbWidth = (width + 16 - 1) >> 4;
+     uint32_t mbHeight = (height + 16 - 1) >> 4;
+     uint32_t numMbs = mbWidth * mbHeight;
+     uint32_t customMapSize = sizeof(ni_enc_avc_roi_custom_map_t) * numMbs;
+     // make the QP map size 16-aligned to meet VPU requirement for subsequent
+     // SEI due to layout of data sent to encoder
+     customMapSize = ((customMapSize + 15) / 16) * 16;
+ 
+     if (! ctx->avc_roi_map)
+     {
+       ctx->avc_roi_map = (ni_enc_avc_roi_custom_map_t*)malloc(customMapSize);
+       if (! ctx->avc_roi_map)
+       {
+         av_log(avctx, AV_LOG_ERROR, "Error set_roi_map malloc failed.\n");
+         return AVERROR(ENOMEM);
+       }
+     }
+ 
+     // init to range midpoint
+     memset(ctx->avc_roi_map, 0, customMapSize);
+     for (i = 0; i < numMbs; i++)
+     {
+       ctx->avc_roi_map[i].field.mb_qp = NI_QP_MID_POINT;
+     }
+ 
+     // iterate ROI list from the last as regions are defined in order of
+     // decreasing importance.
+     for (r = nb_roi - 1; r >= 0; r--)
+     {
+       roi = (const AVRegionOfInterest*)(sd->data + self_size * r);
+       if (! roi->qoffset.den)
+       {
+         av_log(avctx, AV_LOG_ERROR, "AVRegionOfInterest.qoffset.den "
+                "must not be zero.\n");
+         continue;
+       }
+ 
+       f_value = roi->qoffset.num * 1.0f / roi->qoffset.den;
+       f_value = av_clipf(f_value, -1.0, 1.0);
+       set_qp = (int)(f_value * NI_INTRA_QP_RANGE) + NI_QP_MID_POINT;
+       av_log(avctx, AV_LOG_TRACE, "set_roi_map roi %d top %d bot %d left %d "
+              "right %d offset %d/%d set_qp %d\n", r, roi->top, roi->bottom,
+              roi->left, roi->right, roi->qoffset.num, roi->qoffset.den, set_qp);
+ 
+       // copy ROI MBs QPs into custom map
+       for (j = 0; j < mbHeight; j++)
+       {
+         for (i = 0; i < mbWidth; i++)
+         {
+           if (((int)(i % mbWidth) >= (int)((roi->left + 15) / 16) - 1) &&
+               ((int)(i % mbWidth) <= (int)((roi->right + 15) / 16) - 1) &&
+               ((int)(j % mbHeight) >= (int)((roi->top + 15) / 16) - 1) &&
+               ((int)(j % mbHeight) <= (int)((roi->bottom + 15) / 16) - 1))
+           {
+             ctx->avc_roi_map[i + j * mbWidth].field.mb_qp = set_qp;
+           }
+         }
+       }
+     } // for each roi
+ 
+     // average qp is set to midpoint of qp range to work with qp offset
+     ctx->api_ctx.roi_len = customMapSize;
+     ctx->api_ctx.roi_avg_qp = NI_QP_MID_POINT;
+   }
+   else if (AV_CODEC_ID_HEVC == avctx->codec_id)
+   {
+     // ROI for H.265 is specified for 32x32 pixel subCTU blocks -
+     // 4 subCTU QPs are stored in each custom CTU map entry.
+     // number of CTUs/sub CTUs in each row/column
+     uint32_t ctuWidth = (width + 64 - 1) >> 6;
+     uint32_t ctuHeight = (height + 64 - 1) >> 6;
+     uint32_t subCtuWidth = ctuWidth * 2;
+     uint32_t subCtuHeight = ctuHeight * 2;
+     uint32_t numSubCtus = subCtuWidth * subCtuHeight;
+     uint32_t customMapSize = sizeof(ni_enc_hevc_roi_custom_map_t) *
+     ctuWidth * ctuHeight;
+     customMapSize = ((customMapSize + 15) / 16) * 16;
+ 
+     if (! ctx->hevc_sub_ctu_roi_buf)
+     {
+       ctx->hevc_sub_ctu_roi_buf = (uint8_t *)malloc(numSubCtus);
+       if (! ctx->hevc_sub_ctu_roi_buf)
+       {
+         av_log(avctx, AV_LOG_ERROR, "Error set_roi_map malloc failed.\n");
+         return AVERROR(ENOMEM);
+       }
+     }
+ 
+     if (! ctx->hevc_roi_map)
+     {
+       ctx->hevc_roi_map = (ni_enc_hevc_roi_custom_map_t *)malloc(customMapSize);
+       if (! ctx->hevc_roi_map)
+       {
+         free(ctx->hevc_sub_ctu_roi_buf);
+         ctx->hevc_sub_ctu_roi_buf = NULL;
+         av_log(avctx, AV_LOG_ERROR, "Error set_roi_map malloc 2 failed.\n");
+         return AVERROR(ENOMEM);
+       }
+     }
+ 
+     // init to range midpoint
+     memset(ctx->hevc_roi_map, 0, customMapSize);
+     memset(ctx->hevc_sub_ctu_roi_buf, NI_QP_MID_POINT, numSubCtus);
+     for (r = nb_roi - 1; r >= 0; r--)
+     {
+       roi = (const AVRegionOfInterest*)(sd->data + self_size * r);
+       if (! roi->qoffset.den)
+       {
+         av_log(avctx, AV_LOG_ERROR, "AVRegionOfInterest.qoffset.den "
+                "must not be zero.\n");
+         continue;
+       }
+ 
+       f_value = roi->qoffset.num * 1.0f / roi->qoffset.den;
+       f_value = av_clipf(f_value, -1.0, 1.0);
+       set_qp = (int)(f_value * NI_INTRA_QP_RANGE) + NI_QP_MID_POINT;
+       av_log(avctx, AV_LOG_TRACE, "set_roi_map roi %d top %d bot %d left %d "
+              "right %d offset %d/%d set_qp %d\n", r, roi->top, roi->bottom,
+              roi->left, roi->right, roi->qoffset.num, roi->qoffset.den, set_qp);
+ 
+       for (j = 0; j < subCtuHeight; j++)
+       {
+         for (i = 0; i < subCtuWidth; i++)
+         {
+           if (((int)(i % subCtuWidth) >= (int)((roi->left + 31) / 32) - 1) &&
+               ((int)(i % subCtuWidth) <= (int)((roi->right + 31) / 32) - 1) &&
+               ((int)(j % subCtuHeight) >= (int)((roi->top + 31) / 32) - 1) &&
+               ((int)(j % subCtuHeight) <= (int)((roi->bottom + 31) / 32) - 1))
+           {
+             ctx->hevc_sub_ctu_roi_buf[i + j * subCtuWidth] = set_qp;
+           }
+         }
+       }
+     } // for each roi
+ 
+     // load into final custom map and calculate average qp
+     for (i = 0; i < ctuHeight; i++)
+     {
+       uint8_t *ptr = &ctx->hevc_sub_ctu_roi_buf[subCtuWidth * i * 2];
+       for (j = 0; j < ctuWidth; j++, ptr += 2)
+       {
+         ctu = i * ctuWidth + j;
+         ctx->hevc_roi_map[ctu].field.sub_ctu_qp_0 = *ptr;
+         ctx->hevc_roi_map[ctu].field.sub_ctu_qp_1 = *(ptr + 1);
+         ctx->hevc_roi_map[ctu].field.sub_ctu_qp_2 = *(ptr + subCtuWidth);
+         ctx->hevc_roi_map[ctu].field.sub_ctu_qp_3 = *(ptr + subCtuWidth + 1);
+       }
+     }
+     // average qp is set to midpoint of qp range to work with qp offset
+     ctx->api_ctx.roi_len = customMapSize;
+     ctx->api_ctx.roi_avg_qp = NI_QP_MID_POINT;
+   }
+   return 0;
+ }
+ 
+ static int do_open_encoder_device(AVCodecContext *avctx,
+                                   XCoderH265EncContext *ctx,
+                                   ni_encoder_params_t *p_param)
+ {
+   int ret;
+   int frame_width;
+   int frame_height;
+   int linesize_aligned;
+   int height_aligned;
+   int video_full_range_flag = 0;
+   AVFrame *in_frame = &ctx->buffered_fme;
+   NIFramesContext *nif_src_ctx;
+   AVHWFramesContext *avhwf_ctx;
+   enum AVColorPrimaries color_primaries;
+   enum AVColorTransferCharacteristic color_trc;
+   enum AVColorSpace color_space;
+ 
+   if (in_frame->width > 0 && in_frame->height > 0)
+   {
+     frame_width = ODD2EVEN(in_frame->width);
+     frame_height = ODD2EVEN(in_frame->height);
+     color_primaries = in_frame->color_primaries;
+     color_trc = in_frame->color_trc;
+     color_space = in_frame->colorspace;
+     // Force frame color metrics if specified in command line
+     if (in_frame->color_primaries != avctx->color_primaries &&
+         avctx->color_primaries != AVCOL_PRI_UNSPECIFIED)
+     {
+       color_primaries = avctx->color_primaries;
+     }
+     if (in_frame->color_trc != avctx->color_trc &&
+         avctx->color_trc != AVCOL_TRC_UNSPECIFIED)
+     {
+       color_trc = avctx->color_trc;
+     }
+     if (in_frame->colorspace != avctx->colorspace &&
+         avctx->colorspace != AVCOL_SPC_UNSPECIFIED)
+     {
+       color_space = avctx->colorspace;
+     }
+   }
+   else
+   {
+     frame_width = ODD2EVEN(avctx->width);
+     frame_height = ODD2EVEN(avctx->height);
+     color_primaries = avctx->color_primaries;
+     color_trc = avctx->color_trc;
+     color_space = avctx->colorspace;
+   }
+ 
+   // if frame stride size is not as we expect it,
+   // adjust using xcoder-params conf_win_right
+   linesize_aligned = ((frame_width + 7) / 8) * 8;
+   if (avctx->codec_id == AV_CODEC_ID_H264)
+   {
+     linesize_aligned = ((frame_width + 15) / 16) * 16;
+   }
+ 
+   if (linesize_aligned < NI_MIN_WIDTH)
+   {
+     p_param->hevc_enc_params.conf_win_right += NI_MIN_WIDTH - frame_width;
+     linesize_aligned = NI_MIN_WIDTH;
+   }
+   else if (linesize_aligned > frame_width)
+   {
+     p_param->hevc_enc_params.conf_win_right += linesize_aligned - frame_width;
+   }
+   p_param->source_width = linesize_aligned;
+ 
+   height_aligned = ((frame_height + 7) / 8) * 8;
+   if (avctx->codec_id == AV_CODEC_ID_H264)
+   {
+     height_aligned = ((frame_height + 15) / 16) * 16;
+   }
+ 
+   if (height_aligned < NI_MIN_HEIGHT)
+   {
+     p_param->hevc_enc_params.conf_win_bottom += NI_MIN_HEIGHT - frame_height;
+     p_param->source_height = NI_MIN_HEIGHT;
+     height_aligned = NI_MIN_HEIGHT;
+   }
+   else if (height_aligned > frame_height)
+   {
+     p_param->hevc_enc_params.conf_win_bottom += height_aligned - frame_height;
+     p_param->source_height = height_aligned;
+   }
+ 
+   // DolbyVision support
+   if (5 == p_param->dolby_vision_profile &&
+       AV_CODEC_ID_HEVC == avctx->codec_id)
+   {
+     color_primaries = color_trc = color_space = 2;
+     video_full_range_flag = 1;
+   }
+ 
+   // HDR HLG support
+   if ((5 == p_param->dolby_vision_profile &&
+        AV_CODEC_ID_HEVC == avctx->codec_id) ||
+       color_primaries == AVCOL_PRI_BT2020 ||
+       color_trc == AVCOL_TRC_SMPTE2084 ||
+       color_trc == AVCOL_TRC_ARIB_STD_B67 ||
+       color_space == AVCOL_SPC_BT2020_NCL ||
+       color_space == AVCOL_SPC_BT2020_CL)
+   {
+     p_param->hdrEnableVUI = 1;
+     setVui(avctx, p_param, ctx,
+            color_primaries, color_trc, color_space, video_full_range_flag);
+     av_log(avctx, AV_LOG_VERBOSE, "XCoder HDR color info color_primaries: %d "
+            "color_trc: %d color_space %d video_full_range_flag %d sar %d/%d\n",
+            color_primaries, color_trc, color_space, video_full_range_flag,
+            avctx->sample_aspect_ratio.num, avctx->sample_aspect_ratio.den);
+   }
+   else
+   {
+     p_param->hdrEnableVUI = 0;
+     setVui(avctx, p_param, ctx,
+            color_primaries, color_trc, color_space, video_full_range_flag);
+   }
+ 
+   ctx->api_ctx.hw_id = ctx->dev_enc_idx;
+   strcpy(ctx->api_ctx.dev_xcoder, ctx->dev_xcoder);
+ 
+   if (in_frame->width > 0 && in_frame->height > 0)
+   {
+     av_log(avctx, AV_LOG_VERBOSE, "XCoder buffered_fme.linesize: %d/%d/%d "
+            "width/height %dx%d conf_win_right %d  conf_win_bottom %d , "
+            "color primaries %u trc %u space %u\n",
+            in_frame->linesize[0], in_frame->linesize[1], in_frame->linesize[2],
+            in_frame->width, in_frame->height,
+            p_param->hevc_enc_params.conf_win_right,
+            p_param->hevc_enc_params.conf_win_bottom,
+            color_primaries, color_trc, color_space);
+ 
+     if (in_frame->format == AV_PIX_FMT_NI)
+     {
+       ni_hwframe_surface_t *surface = (ni_hwframe_surface_t *)in_frame->data[3];
+ #ifdef _WIN32
+       int64_t handle = (((int64_t) surface->device_handle_ext) << 32) | surface->device_handle;
+       ctx->api_ctx.sender_handle = (ni_device_handle_t) handle;
+ #else
+       ctx->api_ctx.sender_handle = (ni_device_handle_t) surface->device_handle;
+ #endif
+       ctx->api_ctx.hw_action = NI_CODEC_HW_ENABLE;
+       av_log(avctx, AV_LOG_VERBOSE, "XCoder frame sender_handle:%p, hw_id:%d\n",
+              (void *) ctx->api_ctx.sender_handle, ctx->api_ctx.hw_id);
+     }
+ 
+     if (in_frame->hw_frames_ctx && ctx->api_ctx.hw_id == -1)
+     {
+       avhwf_ctx = (AVHWFramesContext*) in_frame->hw_frames_ctx->data;
+       nif_src_ctx = avhwf_ctx->internal->priv;
+       ctx->api_ctx.hw_id = nif_src_ctx->api_ctx.hw_id;
+       av_log(avctx, AV_LOG_VERBOSE, "xcoder_send_frame: hw_id -1 collocated to %d \n", ctx->api_ctx.hw_id);
+     }
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_VERBOSE, "XCoder frame width/height %dx%d "
+            "conf_win_right %d  conf_win_bottom %d , color primaries %u trc %u "
+            "space %u\n",
+            avctx->width, avctx->height, p_param->hevc_enc_params.conf_win_right,
+            p_param->hevc_enc_params.conf_win_bottom,
+            avctx->color_primaries, avctx->color_trc, avctx->colorspace);
+   }
+ 
+   ret = ni_device_session_open(&ctx->api_ctx, NI_DEVICE_TYPE_ENCODER);
+   // As the file handle may change we need to assign back
+   ctx->dev_xcoder_name = ctx->api_ctx.dev_xcoder_name;
+   ctx->blk_xcoder_name = ctx->api_ctx.blk_xcoder_name;
+   ctx->dev_enc_idx = ctx->api_ctx.hw_id;
+ 
+   if (ret == NI_RETCODE_INVALID_PARAM)
+   {
+     av_log(avctx, AV_LOG_ERROR, "%s\n", ctx->api_ctx.param_err_msg);
+   }
+   if (ret != 0)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Failed to open encoder (status = %d), "
+            "critical error or resource unavailable\n", ret);
+     ret = AVERROR_EXTERNAL;
+     // xcoder_encode_close(avctx); will be called at codec close
+     return ret;
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_VERBOSE, "XCoder %s Index %d (inst: %d) opened successfully\n",
+            ctx->dev_xcoder_name, ctx->dev_enc_idx, ctx->api_ctx.session_id);
+   }
+ 
+   return ret;
+ }
+ 
+ static void do_close_encoder_device(XCoderH265EncContext *ctx)
+ {
+   ni_device_session_close(&ctx->api_ctx, ctx->encoder_eof,
+                           NI_DEVICE_TYPE_ENCODER);
+ #ifdef _WIN32
+   ni_device_close(ctx->api_ctx.device_handle);
+ #elif __linux__
+   ni_device_close(ctx->api_ctx.device_handle);
+   ni_device_close(ctx->api_ctx.blk_io_handle);
+ #endif
+   ctx->api_ctx.device_handle = NI_INVALID_DEVICE_HANDLE;
+   ctx->api_ctx.blk_io_handle = NI_INVALID_DEVICE_HANDLE;
+   ctx->api_ctx.auto_dl_handle = NI_INVALID_DEVICE_HANDLE;
+   ctx->api_ctx.sender_handle = NI_INVALID_DEVICE_HANDLE;
+ }
+ 
+ static int xcoder_encoder_headers(AVCodecContext *avctx)
+ {
+   // use a copy of encoder context, take care to restore original config
+   // cropping setting
+   int ret, recv, orig_conf_win_right, orig_conf_win_bottom;
+   ni_packet_t *xpkt;
+   XCoderH265EncContext ctx;
+   XCoderH265EncContext *s = avctx->priv_data;
+   ni_encoder_params_t *p_param = &s->api_param;
+ 
+   memcpy(&ctx, avctx->priv_data, sizeof(XCoderH265EncContext));
+ 
+   orig_conf_win_right = p_param->hevc_enc_params.conf_win_right;
+   orig_conf_win_bottom = p_param->hevc_enc_params.conf_win_bottom;
+ 
+   ret = do_open_encoder_device(avctx, &ctx, p_param);
+   if (ret < 0)
+   {
+     return ret;
+   }
+ 
+   xpkt = &ctx.api_pkt.data.packet;
+   ni_packet_buffer_alloc(xpkt, NI_MAX_TX_SZ);
+ 
+   while (1)
+   {
+     recv = ni_device_session_read(&ctx.api_ctx, &(ctx.api_pkt),
+                                   NI_DEVICE_TYPE_ENCODER);
+ 
+     if (recv > 0)
+     {
+       free(avctx->extradata);
+       avctx->extradata_size = recv - NI_FW_ENC_BITSTREAM_META_DATA_SIZE;
+       avctx->extradata = av_mallocz(avctx->extradata_size +
+                                     AV_INPUT_BUFFER_PADDING_SIZE);
+       memcpy(avctx->extradata,
+              (uint8_t*)xpkt->p_data + NI_FW_ENC_BITSTREAM_META_DATA_SIZE,
+              avctx->extradata_size);
+ 
+       av_log(avctx, AV_LOG_VERBOSE, "Xcoder encoder headers len: %d\n",
+              avctx->extradata_size);
+       break;
+     }
+     else if (recv == NI_RETCODE_SUCCESS)
+     {
+       continue;
+     }
+     else
+     {
+       av_log(avctx, AV_LOG_ERROR, "Xcoder encoder headers error: %d", recv);
+       break;
+     }
+   }
+ 
+   do_close_encoder_device(&ctx);
+ 
+   ni_packet_buffer_free(&ctx.api_pkt.data.packet);
+ 
+   ni_rsrc_free_device_context(ctx.rsrc_ctx);
+   ctx.rsrc_ctx = NULL;
+ 
+   p_param->hevc_enc_params.conf_win_right = orig_conf_win_right;
+   p_param->hevc_enc_params.conf_win_bottom = orig_conf_win_bottom;
+ 
+   return (recv < 0 ? recv : ret);
+ }
+ 
+ static int xcoder_setup_encoder(AVCodecContext *avctx)
+ {
+   XCoderH265EncContext *s = avctx->priv_data;
+   int i, ret = 0;
+   ni_encoder_params_t *p_param = &s->api_param;
+   ni_encoder_params_t *pparams = NULL;
+   ni_session_run_state_t prev_state = s->api_ctx.session_run_state;
+ 
+   av_log(avctx, AV_LOG_DEBUG, "XCoder setup device encoder\n");
+   //s->api_ctx.session_id = NI_INVALID_SESSION_ID;
+   ni_device_session_context_init(&(s->api_ctx));
+   s->api_ctx.session_run_state = prev_state;
+ 
+   s->api_ctx.codec_format = NI_CODEC_FORMAT_H264;
+   if (avctx->codec_id == AV_CODEC_ID_HEVC)
+   {
+     s->api_ctx.codec_format = NI_CODEC_FORMAT_H265;
+   }
+ 
+   s->firstPktArrived = 0;
+   s->spsPpsArrived = 0;
+   s->spsPpsHdrLen = 0;
+   s->p_spsPpsHdr = NULL;
+   s->xcode_load_pixel = 0;
+   s->reconfigCount = 0;
+   s->gotPacket = 0;
+   s->sentFrame = 0;
+   s->latest_dts = 0;
+ 
+   if (! s->vpu_reset &&
+       SESSION_RUN_STATE_SEQ_CHANGE_DRAINING != s->api_ctx.session_run_state)
+   {
+     av_log(avctx, AV_LOG_INFO, "Session state: %d allocate frame fifo.\n", s->api_ctx.session_run_state);
+     // FIFO 4 * FPS length of frames
+     s->fme_fifo_capacity = 4 * avctx->time_base.den / (avctx->time_base.num * avctx->ticks_per_frame);
+     s->fme_fifo = av_fifo_alloc(s->fme_fifo_capacity * sizeof(AVFrame));
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_INFO, "Session seq change, fifo size: %" PRIu64 "\n",
+            av_fifo_size(s->fme_fifo) / sizeof(AVFrame));
+   }
+ 
+   if (! s->fme_fifo)
+   {
+     return AVERROR(ENOMEM);
+   }
+   s->eos_fme_received = 0;
+ 
+   //Xcoder User Configuration
+   ret = ni_encoder_init_default_params(p_param, avctx->time_base.den, (avctx->time_base.num * avctx->ticks_per_frame), avctx->bit_rate, ODD2EVEN(avctx->width), ODD2EVEN(avctx->height));
+   if (ret == NI_RETCODE_PARAM_ERROR_WIDTH_TOO_BIG)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Invalid Picture Width: too big\n");
+     return AVERROR_EXTERNAL;
+   }
+   if (ret == NI_RETCODE_PARAM_ERROR_WIDTH_TOO_SMALL)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Invalid Picture Width: too small\n");
+     return AVERROR_EXTERNAL;
+   }
+   if (ret == NI_RETCODE_PARAM_ERROR_HEIGHT_TOO_BIG)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Invalid Picture Height: too big\n");
+     return AVERROR_EXTERNAL;
+   }
+   if (ret == NI_RETCODE_PARAM_ERROR_HEIGHT_TOO_SMALL)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Invalid Picture Height: too small\n");
+     return AVERROR_EXTERNAL;
+   }
+   if (ret == NI_RETCODE_PARAM_ERROR_AREA_TOO_BIG)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Invalid Picture Width x Height: exceeds %d\n", NI_MAX_RESOLUTION_AREA);
+     return AVERROR_EXTERNAL;
+   }
+   if (ret < 0)
+   {
+     int i;
+     av_log(avctx, AV_LOG_ERROR, "Error setting preset or log.\n");
+     av_log(avctx, AV_LOG_INFO, "Possible presets:");
+     for (i = 0; g_xcoder_preset_names[i]; i++)
+       av_log(avctx, AV_LOG_INFO, " %s", g_xcoder_preset_names[i]);
+     av_log(avctx, AV_LOG_INFO, "\n");
+ 
+     av_log(avctx, AV_LOG_INFO, "Possible log:");
+     for (i = 0; g_xcoder_log_names[i]; i++)
+       av_log(avctx, AV_LOG_INFO, " %s", g_xcoder_log_names[i]);
+     av_log(avctx, AV_LOG_INFO, "\n");
+ 
+     return AVERROR(EINVAL);
+   }
+ 
+   av_log(avctx, AV_LOG_DEBUG, "pix_fmt is %d, sw_pix_fmt is %d\n", avctx->pix_fmt, avctx->sw_pix_fmt);
+   if (avctx->pix_fmt != AV_PIX_FMT_NI)
+   {
+     av_log(avctx, AV_LOG_DEBUG, "sw_pix_fmt assigned to pix_fmt was %d, is now %d\n", avctx->pix_fmt, avctx->sw_pix_fmt);
+     avctx->sw_pix_fmt = avctx->pix_fmt;
+   }
+   else
+   {
+     p_param->hwframes = 1;
+     av_log(avctx, AV_LOG_DEBUG, "p_param->hwframes = %d\n", p_param->hwframes);
+   }
+ 
+   switch (avctx->sw_pix_fmt)
+   {
+     case AV_PIX_FMT_YUV420P:
+     case AV_PIX_FMT_YUV420P10BE:
+     case AV_PIX_FMT_YUV420P10LE:
+     case AV_PIX_FMT_YUVJ420P:
+       break;
+     default:
+       av_log(avctx, AV_LOG_ERROR, "Error: pixel format %d not supported.\n", avctx->sw_pix_fmt);
+       return AVERROR_INVALIDDATA;
+   }
+ 
+   if (s->xcoder_opts)
+   {
+     AVDictionary *dict = NULL;
+     AVDictionaryEntry *en = NULL;
+ 
+     if (!av_dict_parse_string(&dict, s->xcoder_opts, "=", ":", 0))
+     {
+       while ((en = av_dict_get(dict, "", en, AV_DICT_IGNORE_SUFFIX)))
+       {
+         int parse_ret = ni_encoder_params_set_value(p_param, en->key, en->value, &s->api_ctx);
+         switch (parse_ret)
+         {
+           case NI_RETCODE_PARAM_INVALID_NAME:
+             av_log(avctx, AV_LOG_ERROR, "Unknown option: %s.\n", en->key);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_ERROR_TOO_BIG:
+             av_log(avctx, AV_LOG_ERROR, "Invalid %s: too big\n", en->key);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_ERROR_TOO_SMALL:
+             av_log(avctx, AV_LOG_ERROR, "Invalid %s: too small\n", en->key);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_ERROR_OOR:
+             av_log(avctx, AV_LOG_ERROR, "Invalid %s: out of range\n", en->key);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_ERROR_ZERO:
+             av_log(avctx, AV_LOG_ERROR, "Error setting option %s to value 0\n", en->key);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_INVALID_VALUE:
+             av_log(avctx, AV_LOG_ERROR, "Invalid value for %s: %s.\n", en->key, en->value);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_GOP_INTRA_INCOMPATIBLE:
+             av_log(avctx, AV_LOG_ERROR, "Invalid value for %s: %s incompatible with GOP structure.\n", en->key, en->value);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_FAILURE:
+             av_log(avctx, AV_LOG_ERROR, "Generic failure during xcoder-params setting for %s\n", en->key);
+             return AVERROR_EXTERNAL;
+           default:
+             break;
+         }
+       }
+       av_dict_free(&dict);
+ 
+       if (ni_encoder_params_check(p_param, s->api_ctx.codec_format) !=
+           NI_RETCODE_SUCCESS)
+       {
+         av_log(avctx, AV_LOG_ERROR, "Validate encode parameters failed\n");
+         return AVERROR_EXTERNAL;
+       }
+ 
+     }
+   }
+ 
+   if (p_param->enable_vfr)
+   {
+     //in the vfr mode, we use the default framerate
+     //using the time_base to initial timing info
+     p_param->hevc_enc_params.frame_rate = 30;
+     s->api_ctx.prev_fps = 30;
+     s->api_ctx.ui32timing_scale = avctx->time_base.den;
+     s->api_ctx.ui32num_unit_in_tick = avctx->time_base.num;
+     s->api_ctx.prev_bitrate = p_param->bitrate;
+     s->api_ctx.last_change_framenum = 0;
+     s->api_ctx.fps_change_detect_count = 0;
+   }
+ 
+   if (s->xcoder_gop)
+   {
+     AVDictionary *dict = NULL;
+     AVDictionaryEntry *en = NULL;
+ 
+     if (!av_dict_parse_string(&dict, s->xcoder_gop, "=", ":", 0))
+     {
+       while ((en = av_dict_get(dict, "", en, AV_DICT_IGNORE_SUFFIX)))
+       {
+         int parse_ret = ni_encoder_gop_params_set_value(p_param, en->key, en->value);
+         switch (parse_ret)
+         {
+           case NI_RETCODE_PARAM_INVALID_NAME:
+             av_log(avctx, AV_LOG_ERROR, "Unknown option: %s.\n", en->key);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_ERROR_TOO_BIG:
+             av_log(avctx, AV_LOG_ERROR, "Invalid custom GOP parameters: %s too big\n", en->key);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_ERROR_TOO_SMALL:
+             av_log(avctx, AV_LOG_ERROR, "Invalid custom GOP parameters: %s too small\n", en->key);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_ERROR_OOR:
+             av_log(avctx, AV_LOG_ERROR, "Invalid custom GOP parameters: %s out of range \n", en->key);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_ERROR_ZERO:
+              av_log(avctx, AV_LOG_ERROR, "Invalid custom GOP paramaters: Error setting option %s to value 0 \n", en->key);
+              return AVERROR_EXTERNAL;
+           case NI_RETCODE_PARAM_INVALID_VALUE:
+             av_log(avctx, AV_LOG_ERROR, "Invalid value for GOP param %s: %s.\n", en->key, en->value);
+             return AVERROR_EXTERNAL;
+           case NI_RETCODE_FAILURE:
+             av_log(avctx, AV_LOG_ERROR, "Generic failure during xcoder-params setting for %s\n", en->key);
+             return AVERROR_EXTERNAL;
+           default:
+             break;
+         }
+       }
+       av_dict_free(&dict);
+     }
+   }
+   if (s->nvme_io_size > 0 && s->nvme_io_size % 4096 != 0)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Error XCoder iosize is not 4KB aligned!\n");
+     return AVERROR_EXTERNAL;
+   }
+ 
+   s->api_ctx.p_session_config = &s->api_param;
+   pparams = &s->api_param;
+   switch (pparams->hevc_enc_params.gop_preset_index)
+   {
+     /* dtsOffset is the max number of non-reference frames in a GOP
+      * (derived from x264/5 algo) In case of IBBBP the first dts of the I frame should be input_pts-(3*ticks_per_frame)
+      * In case of IBP the first dts of the I frame should be input_pts-(1*ticks_per_frame)
+      * thus we ensure pts>dts in all cases
+      * */
+     case 1 /*PRESET_IDX_ALL_I*/:
+     case 2 /*PRESET_IDX_IPP*/:
+     case 6 /*PRESET_IDX_IPPPP*/:
+     case 9 /*PRESET_IDX_SP*/:
+       s->dtsOffset = 0;
+       break;
+     /* ts requires dts/pts of I frame not same when there are B frames in streams */
+     case 3 /*PRESET_IDX_IBBB*/:
+     case 7 /*PRESET_IDX_IBBBB*/:
+     case 4 /*PRESET_IDX_IBPBP*/:
+       s->dtsOffset = 1;
+       break;
+     case 5 /*PRESET_IDX_IBBBP*/:
+       s->dtsOffset = 2;
+       break;
+     case 8 /*PRESET_IDX_RA_IB*/:
+       s->dtsOffset = 3;
+       break;
+     default:
+       // TBD need user to specify offset
+       s->dtsOffset = 7;
+       av_log(avctx, AV_LOG_VERBOSE, "dts offset default to 7, TBD\n");
+       break;
+   }
+   if (1 == pparams->force_frame_type)
+   {
+     s->dtsOffset = 7;
+   }
+ 
+   s->total_frames_received = 0;
+   s->gop_offset_count = 0;
+   av_log(avctx, AV_LOG_INFO, "dts offset: %" PRId64 ", gop_offset_count: %d\n",
+          s->dtsOffset, s->gop_offset_count);
+ 
+   if (0 == strcmp(s->dev_xcoder, LIST_DEVICES_STR))
+   {
+     av_log(avctx, AV_LOG_DEBUG, "XCoder: printing out all xcoder devices and their load, and exit ...\n");
+     ni_rsrc_print_all_devices_capability();
+     return AVERROR_EXIT;
+   }
+   //overwrite the nvme io size here with a custom value if it was provided
+   if (s->nvme_io_size > 0)
+   {
+     s->api_ctx.max_nvme_io_size = s->nvme_io_size;
+     av_log(avctx, AV_LOG_VERBOSE, "Custom NVMe IO Size set to = %d\n", s->api_ctx.max_nvme_io_size);
+   }
+ 
+   //overwrite keep alive timeout value here with a custom value if it was provided
+   s->api_ctx.keep_alive_timeout = s->keep_alive_timeout;
+   av_log(avctx, AV_LOG_VERBOSE, "Custom NVMe Keep Alive Timeout set to = %d\n", s->api_ctx.keep_alive_timeout);
+ 
+   s->encoder_eof = 0;
+   s->roi_side_data_size = s->nb_rois = 0;
+   s->av_rois = NULL;
+   s->avc_roi_map = NULL;
+   s->hevc_sub_ctu_roi_buf = NULL;
+   s->hevc_roi_map = NULL;
+   avctx->bit_rate = pparams->bitrate;
+ 
+   s->api_ctx.src_bit_depth = 8;
+   s->api_ctx.src_endian = NI_FRAME_LITTLE_ENDIAN;
+   s->api_ctx.roi_len = 0;
+   s->api_ctx.roi_avg_qp = 0;
+   s->api_ctx.bit_depth_factor = 1;
+   if (AV_PIX_FMT_YUV420P10BE == avctx->sw_pix_fmt ||
+       AV_PIX_FMT_YUV420P10LE == avctx->sw_pix_fmt)
+   {
+     s->api_ctx.bit_depth_factor = 2;
+     s->api_ctx.src_bit_depth = 10;
+     if (AV_PIX_FMT_YUV420P10BE == avctx->sw_pix_fmt)
+     {
+       s->api_ctx.src_endian = NI_FRAME_BIG_ENDIAN;
+     }
+   }
+ 
+   // DolbyVision, HRD and AUD settings
+   if (AV_CODEC_ID_HEVC == avctx->codec_id)
+   {
+     if (5 == pparams->dolby_vision_profile)
+     {
+       pparams->hrd_enable = pparams->enable_aud = 1;
+       pparams->hevc_enc_params.forced_header_enable = NI_ENC_REPEAT_HEADERS_ALL_I_FRAMES;
+       pparams->hevc_enc_params.decoding_refresh_type = 2;
+     }
+     if (pparams->hrd_enable)
+     {
+       pparams->hevc_enc_params.rc.enable_rate_control = 1;
+     }
+   }
+ 
+   // init HW AVFRAME pool
+   s->freeHead = 0;
+   s->freeTail = 0;
+   for (i = 0; i < MAX_NUM_FRAMEPOOL_HWAVFRAME; i++)
+   {
+     s->sframe_pool[i] = av_frame_alloc();
+     if (!s->sframe_pool[i])
+     {
+       return AVERROR(ENOMEM);
+     }
+     s->aFree_Avframes_list[i] = i;
+     s->freeTail++;
+   }
+   s->aFree_Avframes_list[i] = -1;
+ 
+   // init HDR SEI stuff
+   s->api_ctx.sei_hdr_content_light_level_info_len =
+   s->api_ctx.light_level_data_len =
+   s->api_ctx.sei_hdr_mastering_display_color_vol_len =
+   s->api_ctx.mdcv_max_min_lum_data_len = 0;
+   s->api_ctx.p_master_display_meta_data = NULL;
+ 
+   // init HRD SEI stuff (TBD: value after recovery ?)
+   s->au_cpb_removal_delay_minus1 = 0;
+ 
+   memset( &(s->api_fme), 0, sizeof(ni_session_data_io_t) );
+   memset( &(s->api_pkt), 0, sizeof(ni_session_data_io_t) );
+ 
+   if (avctx->width > 0 && avctx->height > 0)
+   {
+     ni_frame_buffer_alloc(&(s->api_fme.data.frame),
+                           ODD2EVEN(avctx->width),
+                           ODD2EVEN(avctx->height),
+                           0,
+                           0,
+                           s->api_ctx.bit_depth_factor,
+                           (s->buffered_fme.format == AV_PIX_FMT_NI));
+   }
+ 
+   // generate encoded bitstream headers in advance if configured to do so
+   if (pparams->generate_enc_hdrs)
+   {
+     ret = xcoder_encoder_headers(avctx);
+   }
+ 
+   return ret;
+ }
+ 
+ av_cold int xcoder_encode_init(AVCodecContext *avctx)
+ {
+   XCoderH265EncContext *ctx = avctx->priv_data;
+   int ret;
+ 
+   ni_log_set_level(ff_to_ni_log_level(av_log_get_level()));
+ 
+   av_log(avctx, AV_LOG_DEBUG, "XCoder encode init\n");
+ 
+   if (ctx->dev_xcoder == NULL)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Error: XCoder encode options dev_xcoder is null\n");
+     return AVERROR_INVALIDDATA;
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_VERBOSE, "XCoder options: dev_xcoder: %s dev_enc_idx %d\n",
+            ctx->dev_xcoder, ctx->dev_enc_idx);
+   }
+ 
+   if (ctx->api_ctx.session_run_state == SESSION_RUN_STATE_SEQ_CHANGE_DRAINING)
+   {
+     ctx->dev_enc_idx = ctx->orig_dev_enc_idx;
+   }
+   else
+   {
+     ctx->orig_dev_enc_idx = ctx->dev_enc_idx;
+   }
+ 
+ #ifdef NIENC_MULTI_THREAD
+   if (sessionCounter == 0)
+   {
+     threadpool_init(&pool);
+   }
+   sessionCounter++;
+ #endif
+ 
+   if ((ret = xcoder_setup_encoder(avctx)) < 0)
+   {
+     xcoder_encode_close(avctx);
+     return ret;
+   }
+ 
+ #ifdef _WIN32
+   // For windows opening the encoder when init will take less time.
+   // If HW frame detected then open in xcoder_send_frame function.
+   if (avctx->pix_fmt != AV_PIX_FMT_NI)
+   {
+     // NETINT_INTERNAL - currently only for internal testing
+     ni_encoder_params_t *p_param = &ctx->api_param;
+     ret = do_open_encoder_device(avctx, ctx, p_param);
+     if (ret < 0)
+     {
+       xcoder_encode_close(avctx);
+       return ret;
+     }
+   }
+ #endif
+   ctx->vpu_reset = 0;
+ 
+   return 0;
+ }
+ 
+ static int is_input_fifo_empty(XCoderH265EncContext *ctx)
+ {
+   return av_fifo_size(ctx->fme_fifo) < sizeof(AVFrame);
+ }
+ 
+ static int is_input_fifo_full(XCoderH265EncContext *ctx)
+ {
+   return av_fifo_space(ctx->fme_fifo) < sizeof(AVFrame);
+ }
+ 
+ static int xcoder_encode_reset(AVCodecContext *avctx)
+ {
+   XCoderH265EncContext *ctx = avctx->priv_data;
+   av_log(avctx, AV_LOG_WARNING, "XCoder encode reset\n");
+   ctx->vpu_reset = 1;
+   xcoder_encode_close(avctx);
+   return xcoder_encode_init(avctx);
+ }
+ 
+ static int enqueue_frame(AVCodecContext *avctx, const AVFrame *inframe)
+ {
+   int ret;
+   AVFrame *input_fme;
+   XCoderH265EncContext *ctx = avctx->priv_data;
+ 
+   // expand frame buffer fifo if not enough space
+   if (is_input_fifo_full(ctx))
+   {
+     ret = av_fifo_realloc2(ctx->fme_fifo, 2 * av_fifo_size(ctx->fme_fifo));
+     if (ret < 0)
+     {
+       av_log(avctx, AV_LOG_ERROR, "Enc av_fifo_realloc2 NO MEMORY !!!\n");
+       return ret;
+     }
+     if ((av_fifo_size(ctx->fme_fifo) / sizeof(AVFrame) % 100) == 0)
+     {
+       av_log(avctx, AV_LOG_INFO, "Enc fifo being extended to: %" PRIu64 "\n",
+              av_fifo_size(ctx->fme_fifo) / sizeof(AVFrame));
+     }
+     av_assert0(0 == av_fifo_size(ctx->fme_fifo) % sizeof(AVFrame));
+   }
+ 
+   input_fme = av_frame_alloc();
+   ret = av_frame_ref(input_fme, inframe);
+ 
+   if (ret < 0)
+   {
+     av_log(avctx, AV_LOG_ERROR, "Enc av_frame_ref input_fme ERROR !!!\n");
+     return ret;
+   }
+   av_fifo_generic_write(ctx->fme_fifo, input_fme, sizeof(*input_fme), NULL);
+   av_log(avctx, AV_LOG_DEBUG, "fme queued pts:%" PRId64 ", fifo size: %" PRIu64 "\n",
+          input_fme->pts, av_fifo_size(ctx->fme_fifo) / sizeof(AVFrame));
+   return ret;
+ }
+ 
+ #ifdef NIENC_MULTI_THREAD
+ static void* write_frame_thread(void* arg)
+ {
+   write_thread_arg_struct_t *args = (write_thread_arg_struct_t *) arg;
+   XCoderH265EncContext *ctx = args->ctx;
+   int ret;
+   int sent;
+ 
+   pthread_mutex_lock(&args->mutex);
+   args->running = 1;
+   av_log(ctx, AV_LOG_DEBUG, "write_frame_thread: session_id %d, device_handle %d\n",
+          ctx->api_ctx.session_id, ctx->api_ctx.device_handle);
+ 
+   av_log(ctx, AV_LOG_DEBUG, "write_frame_thread: ctx %p\n", ctx);
+ 
+   sent = ni_device_session_write(&ctx->api_ctx, &ctx->api_fme, NI_DEVICE_TYPE_ENCODER);
+ 
+   av_log(ctx, AV_LOG_DEBUG, "write_frame_thread: size %d sent to xcoder\n", sent);
+ 
+   if (NI_RETCODE_ERROR_RESOURCE_UNAVAILABLE == sent)
+   {
+     av_log(ctx, AV_LOG_DEBUG, "write_frame_thread(): Sequence Change in progress, returning EAGAIN\n");
+     ret = AVERROR(EAGAIN);
+   }
+   else if (NI_RETCODE_ERROR_VPU_RECOVERY == sent)
+   {
+     sent = xcoder_encode_reset(ctx);
+   }
+ 
+   if (sent < 0)
+   {
+     ret = AVERROR(EIO);
+   }
+   else
+   {
+     //pushing input pts in circular FIFO
+     ctx->api_ctx.enc_pts_list[ctx->api_ctx.enc_pts_w_idx % NI_FIFO_SZ] = ctx->api_fme.data.frame.pts;
+     ctx->api_ctx.enc_pts_w_idx ++;
+     ret = 0;
+   }
+ 
+   args->ret = ret;
+   av_log(ctx, AV_LOG_DEBUG, "write_frame_thread: ret %d\n", ret);
+   pthread_cond_signal(&args->cond);
+   args->running = 0;
+   pthread_mutex_unlock(&args->mutex);
+   return NULL;
+ }
+ #endif
+ 
+ int xcoder_encode_close(AVCodecContext *avctx)
+ {
+   XCoderH265EncContext *ctx = avctx->priv_data;
+   ni_retcode_t ret = NI_RETCODE_FAILURE;
+   int i;
+ 
+ #ifdef NIENC_MULTI_THREAD
+   sessionCounter--;
+   if (sessionCounter == 0)
+   {
+     threadpool_destroy(&pool);
+   }
+ #endif
+ 
+   for (i = 0; i < MAX_NUM_FRAMEPOOL_HWAVFRAME; i++)
+   {
+     av_frame_free(&(ctx->sframe_pool[i])); //any remaining stored AVframes that have not been unref will die here
+     ctx->sframe_pool[i] = NULL;
+   }
+ 
+   do_close_encoder_device(ctx);
+ 
+   if (ctx->api_ctx.p_master_display_meta_data)
+   {
+     free(ctx->api_ctx.p_master_display_meta_data);
+     ctx->api_ctx.p_master_display_meta_data = NULL;
+   }
+ 
+   av_log(avctx, AV_LOG_DEBUG, "XCoder encode close (status = %d)\n", ret);
+   ni_frame_buffer_free( &(ctx->api_fme.data.frame) );
+   ni_packet_buffer_free( &(ctx->api_pkt.data.packet) );
+ 
+   av_log(avctx, AV_LOG_DEBUG, "fifo size: %" PRIu64 "\n",
+          av_fifo_size(ctx->fme_fifo) / sizeof(AVFrame));
+   if (! ctx->vpu_reset &&
+       ctx->api_ctx.session_run_state != SESSION_RUN_STATE_SEQ_CHANGE_DRAINING)
+   {
+     av_fifo_free(ctx->fme_fifo);
+     av_log(avctx, AV_LOG_DEBUG, " , freed.\n");
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_DEBUG, " , kept.\n");
+   }
+ 
+   ni_rsrc_free_device_context(ctx->rsrc_ctx);
+   ctx->rsrc_ctx = NULL;
+ 
+   free(ctx->g_enc_change_params);
+   ctx->g_enc_change_params = NULL;
+   free(ctx->p_spsPpsHdr);
+   ctx->p_spsPpsHdr = NULL;
+ 
+   free(ctx->av_rois);
+   free(ctx->avc_roi_map);
+   free(ctx->hevc_sub_ctu_roi_buf);
+   free(ctx->hevc_roi_map);
+   ctx->av_rois = NULL;
+   ctx->avc_roi_map = NULL;
+   ctx->hevc_sub_ctu_roi_buf = NULL;
+   ctx->hevc_roi_map = NULL;
+   ctx->roi_side_data_size = ctx->nb_rois = 0;
+   ctx->started = 0;
+ 
+   return 0;
+ }
+ 
+ int xcoder_send_frame(AVCodecContext *avctx, const AVFrame *frame)
+ {
+   XCoderH265EncContext *ctx = avctx->priv_data;
+   int ret = 0;
+   int sent;
+   int orig_avctx_width = avctx->width, orig_avctx_height = avctx->height;
+   AVFrameSideData *side_data;
+   AVHWFramesContext *avhwf_ctx;
+   NIFramesContext *nif_src_ctx;
+   uint8_t *cc_data = NULL;
+   int cc_size = 0;
+   // close caption data and its size after emulation prevention processing
+   uint8_t cc_data_emu_prevent[NI_MAX_SEI_DATA];
+   int cc_size_emu_prevent;
+   uint8_t *udu_sei = NULL;
+   uint8_t udu_sei_type = 0;
+   int udu_sei_size = 0;
+   int ext_udu_sei_size = 0;
+   int is_hwframe;
+   int format_in_use;
+   int frame_width, frame_height;
+ 
+ #ifdef NIENC_MULTI_THREAD
+   av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame start 000 %p, session_id %d, device_handle %d\n",
+          ctx->api_ctx.session_info, ctx->api_ctx.session_id, ctx->api_ctx.device_handle);
+   if ((ctx->api_ctx.session_id != NI_INVALID_SESSION_ID) && (ctx->api_ctx.device_handle != NI_INVALID_DEVICE_HANDLE))
+   {
+     av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame start 000 %p\n", ctx->api_ctx.session_info);
+     if (ctx->api_ctx.session_info != NULL)
+     {
+       write_thread_arg_struct_t *write_thread_args = (write_thread_arg_struct_t *)ctx->api_ctx.session_info;
+       pthread_mutex_lock(&write_thread_args->mutex);
+       av_log(avctx, AV_LOG_DEBUG, "thread start waiting session_id %d\n", ctx->api_ctx.session_id);
+       if (write_thread_args->running == 1)
+       {
+         pthread_cond_wait(&write_thread_args->cond, &write_thread_args->mutex);
+         av_log(avctx, AV_LOG_DEBUG, "thread get waiting session_id %d\n", ctx->api_ctx.session_id);
+       }
+       if (write_thread_args->ret == AVERROR(EAGAIN))
+       {
+         av_log(avctx, AV_LOG_ERROR, "xcoder_send_frame: ret %d\n", write_thread_args->ret);
+         pthread_mutex_unlock(&write_thread_args->mutex);
+         free(write_thread_args);
+         ctx->api_ctx.session_info = NULL;
+         return AVERROR(EAGAIN);
+       }
+       pthread_mutex_unlock(&write_thread_args->mutex);
+       free(write_thread_args);
+       ctx->api_ctx.session_info = NULL;
+       av_log(avctx, AV_LOG_DEBUG, "thread free session_id %d\n", ctx->api_ctx.session_id);
+     }
+   }
+ #endif
+   ni_encoder_params_t *p_param = &ctx->api_param; // NETINT_INTERNAL - currently only for internal testing
+ 
+   av_log(avctx, AV_LOG_DEBUG, "XCoder send frame, pkt_size %d %dx%d  avctx: "
+          "%dx%d\n",
+          frame ? frame->pkt_size : -1, frame ? frame->width : -1,
+          frame ? frame->height : -1, avctx->width, avctx->height);
+ 
+   if (ctx->encoder_flushing)
+   {
+     if (! frame && is_input_fifo_empty(ctx))
+     {
+       av_log(avctx, AV_LOG_DEBUG, "XCoder EOF: null frame && fifo empty\n");
+       return AVERROR_EOF;
+     }
+   }
+ 
+   if (! frame)
+   {
+     if (SESSION_RUN_STATE_QUEUED_FRAME_DRAINING == ctx->api_ctx.session_run_state)
+     {
+       av_log(avctx, AV_LOG_DEBUG, "null frame, send queued frame\n");
+     }
+     else
+     {
+       ctx->eos_fme_received = 1;
+       av_log(avctx, AV_LOG_DEBUG, "null frame, ctx->eos_fme_received = 1\n");
+     }
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_DEBUG, "XCoder send frame #%"PRIu64"\n",
+            ctx->api_ctx.frame_num);
+ 
+     // queue up the frame if fifo is NOT empty, or sequence change ongoing !
+     if (!is_input_fifo_empty(ctx) ||
+         SESSION_RUN_STATE_SEQ_CHANGE_DRAINING == ctx->api_ctx.session_run_state)
+     {
+       enqueue_frame(avctx, frame);
+ 
+       if (SESSION_RUN_STATE_SEQ_CHANGE_DRAINING ==
+           ctx->api_ctx.session_run_state)
+       {
+         av_log(avctx, AV_LOG_TRACE, "XCoder doing sequence change, frame #"
+                "%"PRIu64" queued and return 0 !\n", ctx->api_ctx.frame_num);
+         return 0;
+       }
+     }
+     else
+     {
+       ret = av_frame_ref(&ctx->buffered_fme, frame);
+     }
+   }
+ 
+   if (is_input_fifo_empty(ctx))
+   {
+     av_log(avctx, AV_LOG_DEBUG,
+            "no frame in fifo to send, just send/receive ..\n");
+     if (ctx->eos_fme_received)
+     {
+       av_log(avctx, AV_LOG_DEBUG, "no frame in fifo to send, send eos ..\n");
+       // if received eos but not sent any frame, there is no need to continue the following process
+       if (ctx->started == 0)
+       {
+         av_log(avctx, AV_LOG_DEBUG, "session is not open, send eos, return EOF\n");
+         return AVERROR_EOF;
+       }
+     }
+   }
+   else
+   {
+     av_fifo_generic_peek(ctx->fme_fifo, &ctx->buffered_fme,
+                          sizeof(AVFrame), NULL);
+     ctx->buffered_fme.extended_data = ctx->buffered_fme.data;
+   }
+ 
+   frame_width = ODD2EVEN(ctx->buffered_fme.width);
+   frame_height = ODD2EVEN(ctx->buffered_fme.height);
+   is_hwframe = (ctx->buffered_fme.format == AV_PIX_FMT_NI);
+ 
+   // leave encoder instance open to when the first frame buffer arrives so that
+   // its stride size is known and handled accordingly.
+   if (ctx->started == 0)
+   {
+ #ifdef _WIN32
+     if (ctx->buffered_fme.width != avctx->width ||
+        ctx->buffered_fme.height != avctx->height ||
+        ctx->buffered_fme.color_primaries != avctx->color_primaries ||
+        ctx->buffered_fme.color_trc != avctx->color_trc ||
+        ctx->buffered_fme.colorspace != avctx->colorspace)
+     {
+       av_log(avctx, AV_LOG_INFO, "WARNING reopen device Width: %d-%d, "
+              "Height: %d-%d, color_primaries: %d-%d, color_trc: %d-%d, "
+              "color_space: %d-%d\n",
+              ctx->buffered_fme.width, avctx->width,
+              ctx->buffered_fme.height, avctx->height,
+              ctx->buffered_fme.color_primaries, avctx->color_primaries,
+              ctx->buffered_fme.color_trc, avctx->color_trc,
+              ctx->buffered_fme.colorspace, avctx->colorspace);
+       do_close_encoder_device(ctx);
+       // Errror when set this parameters in ni_encoder_params_set_value !!!!!!
+       p_param->hevc_enc_params.conf_win_right = 0;
+       p_param->hevc_enc_params.conf_win_bottom = 0;
+ 
+       if ((ret = do_open_encoder_device(avctx, ctx, p_param)) < 0)
+       {
+         return ret;
+       }
+     }
+     else if (is_hwframe) // if hw-frame detected for windows then open here.
+ #endif
+     {
+       if ((ret = do_open_encoder_device(avctx, ctx, p_param)) < 0)
+       {
+         return ret;
+       }
+     }
+     ctx->api_fme.data.frame.start_of_stream = 1;
+     ctx->started = 1;
+   }
+   else
+   {
+     ctx->api_fme.data.frame.start_of_stream = 0;
+   }
+ 
+   if ((ctx->buffered_fme.height && ctx->buffered_fme.width) &&
+       (ctx->buffered_fme.height != avctx->height ||
+        ctx->buffered_fme.width != avctx->width))
+   {
+     av_log(avctx, AV_LOG_INFO, "xcoder_send_frame resolution change %dx%d "
+            "-> %dx%d\n", avctx->width, avctx->height,
+            ctx->buffered_fme.width, ctx->buffered_fme.height);
+     ctx->api_ctx.session_run_state = SESSION_RUN_STATE_SEQ_CHANGE_DRAINING;
+     ctx->eos_fme_received = 1;
+ 
+     // have to queue this frame if not done so: an empty queue
+     if (is_input_fifo_empty(ctx))
+     {
+       av_log(avctx, AV_LOG_TRACE, "resolution change when fifo empty, frame "
+              "#%"PRIu64" being queued ..\n", ctx->api_ctx.frame_num);
+       av_frame_unref(&ctx->buffered_fme);
+       enqueue_frame(avctx, frame);
+     }
+   }
+ 
+   ctx->api_fme.data.frame.preferred_characteristics_data_len = 0;
+   ctx->api_fme.data.frame.end_of_stream = 0;
+   ctx->api_fme.data.frame.force_key_frame
+   = ctx->api_fme.data.frame.use_cur_src_as_long_term_pic
+   = ctx->api_fme.data.frame.use_long_term_ref = 0;
+ 
+   ctx->api_fme.data.frame.sei_total_len
+   = ctx->api_fme.data.frame.sei_cc_offset = ctx->api_fme.data.frame.sei_cc_len
+   = ctx->api_fme.data.frame.sei_hdr_mastering_display_color_vol_offset
+   = ctx->api_fme.data.frame.sei_hdr_mastering_display_color_vol_len
+   = ctx->api_fme.data.frame.sei_hdr_content_light_level_info_offset
+   = ctx->api_fme.data.frame.sei_hdr_content_light_level_info_len
+   = ctx->api_fme.data.frame.sei_hdr_plus_offset
+   = ctx->api_fme.data.frame.sei_hdr_plus_len = 0;
+ 
+   ctx->api_fme.data.frame.roi_len = 0;
+   ctx->api_fme.data.frame.reconf_len = 0;
+   ctx->api_fme.data.frame.force_pic_qp = 0;
+ 
+   if (SESSION_RUN_STATE_SEQ_CHANGE_DRAINING == ctx->api_ctx.session_run_state ||
+       (ctx->eos_fme_received && is_input_fifo_empty(ctx)))
+   {
+     av_log(avctx, AV_LOG_DEBUG, "XCoder start flushing\n");
+     ctx->api_fme.data.frame.end_of_stream = 1;
+     ctx->encoder_flushing = 1;
+   }
+   else
+   {
+     // NETINT_INTERNAL - currently only for internal testing
+     // allocate memory for reconf parameters only once and reuse it
+     if (! ctx->g_enc_change_params)
+     {
+       ctx->g_enc_change_params = calloc(1, sizeof(ni_encoder_change_params_t));
+     }
+ 
+     ctx->api_fme.data.frame.extra_data_len = NI_APP_ENC_FRAME_META_DATA_SIZE;
+     ctx->g_enc_change_params->enable_option = 0;
+     ctx->api_fme.data.frame.reconf_len = 0;
+ 
+     switch (p_param->reconf_demo_mode)
+     {
+       case XCODER_TEST_RECONF_BR:
+         if (ctx->api_ctx.frame_num == p_param->reconf_hash[ctx->reconfigCount][0])
+         {
+           ctx->g_enc_change_params->enable_option = NI_SET_CHANGE_PARAM_RC_TARGET_RATE;
+           ctx->g_enc_change_params->bitRate = p_param->reconf_hash[ctx->reconfigCount][1];
+           ctx->api_fme.data.frame.extra_data_len += sizeof(ni_encoder_change_params_t);
+           ctx->api_fme.data.frame.reconf_len = sizeof(ni_encoder_change_params_t);
+           ctx->reconfigCount ++;
+         }
+         break;
+       case XCODER_TEST_RECONF_INTRAPRD:
+         if (ctx->api_ctx.frame_num == p_param->reconf_hash[ctx->reconfigCount][0])
+         {
+           ctx->g_enc_change_params->enable_option = NI_SET_CHANGE_PARAM_INTRA_PARAM;
+           ctx->g_enc_change_params->intraQP =
+           p_param->reconf_hash[ctx->reconfigCount][1];
+           ctx->g_enc_change_params->intraPeriod =
+           p_param->reconf_hash[ctx->reconfigCount][2];
+           ctx->g_enc_change_params->repeatHeaders =
+           p_param->reconf_hash[ctx->reconfigCount][3];
+           av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: frame #%" PRIu64 " "
+                  "reconf intraQP %d intraPeriod %d repeatHeaders %d\n",
+                  ctx->api_ctx.frame_num, ctx->g_enc_change_params->intraQP,
+                  ctx->g_enc_change_params->intraPeriod,
+                  ctx->g_enc_change_params->repeatHeaders);
+ 
+           ctx->api_fme.data.frame.extra_data_len += sizeof(ni_encoder_change_params_t);
+           ctx->api_fme.data.frame.reconf_len = sizeof(ni_encoder_change_params_t);
+           ctx->reconfigCount ++;
+         }
+         break;
+     case XCODER_TEST_RECONF_LONG_TERM_REF:
+       // the reconf file data line format for this is:
+       // <frame-number>:useCurSrcAsLongtermPic,useLongtermRef where
+       // values will stay the same on every frame until changed.
+       if (ctx->api_ctx.frame_num >= p_param->reconf_hash[ctx->reconfigCount][0])
+       {
+         AVFrameSideData *ltr_sd;
+         AVNetintLongTermRef *p_ltr;
+         ltr_sd = av_frame_new_side_data(&ctx->buffered_fme,
+                                         AV_FRAME_DATA_NETINT_LONG_TERM_REF,
+                                         sizeof(AVNetintLongTermRef));
+         if (ltr_sd)
+         {
+           p_ltr = (AVNetintLongTermRef *)ltr_sd->data;
+           p_ltr->use_cur_src_as_long_term_pic
+           = p_param->reconf_hash[ctx->reconfigCount][1];
+           p_ltr->use_long_term_ref
+           = p_param->reconf_hash[ctx->reconfigCount][2];
+         }
+       }
+       if (ctx->api_ctx.frame_num + 1 ==
+           p_param->reconf_hash[ctx->reconfigCount + 1][0])
+       {
+         ctx->reconfigCount ++;
+       }
+       break;
+     case XCODER_TEST_RECONF_VUI_HRD:
+       // the reconf file format for this is:
+       // <frame-number>:<vui-file-name-in-digits>,<number-of-bits-of-vui-rbsp>
+       if (ctx->api_ctx.frame_num == p_param->reconf_hash[ctx->reconfigCount][0])
+       {
+         char file_name[64];
+         FILE *vui_file;
+         snprintf(file_name, 64, "%d",
+                  p_param->reconf_hash[ctx->reconfigCount][1]);
+         vui_file = fopen(file_name, "rb");
+         if (! vui_file)
+         {
+           av_log(avctx, AV_LOG_ERROR, "Error VUI reconf file: %s\n", file_name);
+         }
+         else
+         {
+           int nb_bytes_by_bits =
+           (p_param->reconf_hash[ctx->reconfigCount][2] + 7) / 8;
+           size_t nb_bytes = fread(ctx->g_enc_change_params->vuiRbsp,
+                                   1, NI_MAX_VUI_SIZE, vui_file);
+           if (nb_bytes != nb_bytes_by_bits)
+           {
+             av_log(avctx, AV_LOG_ERROR, "Error VUI file size %d bytes != "
+                    "specified %d bits (%d bytes) !\n", (int)nb_bytes,
+                    p_param->reconf_hash[ctx->reconfigCount][2], nb_bytes_by_bits);
+           }
+           else
+           {
+             ctx->g_enc_change_params->enable_option =
+             NI_SET_CHANGE_PARAM_VUI_HRD_PARAM;
+             ctx->g_enc_change_params->encodeVuiRbsp = 1;
+             ctx->g_enc_change_params->vuiDataSizeBits =
+             p_param->reconf_hash[ctx->reconfigCount][2];
+             ctx->g_enc_change_params->vuiDataSizeBytes = nb_bytes;
+             av_log(avctx, AV_LOG_DEBUG, "Reconf VUI %d bytes (%d bits)\n",
+                    (int)nb_bytes, p_param->reconf_hash[ctx->reconfigCount][2]);
+             ctx->api_fme.data.frame.extra_data_len += sizeof(ni_encoder_change_params_t);
+             ctx->api_fme.data.frame.reconf_len = sizeof(ni_encoder_change_params_t);
+             ctx->reconfigCount++;
+           }
+ 
+           fclose(vui_file);
+         }
+       }
+       break;
+     case XCODER_TEST_RECONF_RC:
+       if (ctx->api_ctx.frame_num == p_param->reconf_hash[ctx->reconfigCount][0])
+       {
+         ctx->g_enc_change_params->enable_option = NI_SET_CHANGE_PARAM_RC;
+         ctx->g_enc_change_params->hvsQPEnable =
+         p_param->reconf_hash[ctx->reconfigCount][1];
+         ctx->g_enc_change_params->hvsQpScale =
+         p_param->reconf_hash[ctx->reconfigCount][2];
+         ctx->g_enc_change_params->vbvBufferSize =
+         p_param->reconf_hash[ctx->reconfigCount][3];
+         ctx->g_enc_change_params->mbLevelRcEnable =
+         p_param->reconf_hash[ctx->reconfigCount][4];
+         ctx->g_enc_change_params->fillerEnable =
+         p_param->reconf_hash[ctx->reconfigCount][5];
+         av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: frame #%" PRIu64 " "
+                "reconf hvsQPEnable %d hvsQpScale %d vbvBufferSize %d "
+                "mbLevelRcEnable %d fillerEnable %d\n",
+                ctx->api_ctx.frame_num, ctx->g_enc_change_params->hvsQPEnable,
+                ctx->g_enc_change_params->hvsQpScale,
+                ctx->g_enc_change_params->vbvBufferSize,
+                ctx->g_enc_change_params->mbLevelRcEnable,
+                ctx->g_enc_change_params->fillerEnable);
+ 
+         ctx->api_fme.data.frame.extra_data_len +=
+         sizeof(ni_encoder_change_params_t);
+         ctx->api_fme.data.frame.reconf_len = sizeof(ni_encoder_change_params_t);
+         ctx->reconfigCount ++;
+       }
+       break;
+     case XCODER_TEST_RECONF_RC_MIN_MAX_QP:
+       if (ctx->api_ctx.frame_num == p_param->reconf_hash[ctx->reconfigCount][0])
+       {
+         ctx->g_enc_change_params->enable_option = NI_SET_CHANGE_PARAM_RC_MIN_MAX_QP;
+         ctx->g_enc_change_params->minQpI =
+         p_param->reconf_hash[ctx->reconfigCount][1];
+         ctx->g_enc_change_params->maxQpI =
+         p_param->reconf_hash[ctx->reconfigCount][2];
+         ctx->g_enc_change_params->maxDeltaQp =
+         p_param->reconf_hash[ctx->reconfigCount][3];
+         ctx->g_enc_change_params->minQpP =
+         p_param->reconf_hash[ctx->reconfigCount][4];
+         ctx->g_enc_change_params->minQpB =
+         p_param->reconf_hash[ctx->reconfigCount][5];
+         ctx->g_enc_change_params->maxQpP =
+         p_param->reconf_hash[ctx->reconfigCount][6];
+         ctx->g_enc_change_params->maxQpB =
+         p_param->reconf_hash[ctx->reconfigCount][7];
+         av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: frame #%" PRIu64 " "
+                "reconf minQpI %d maxQpI %d maxDeltaQp %d minQpP %d minQpB %d "
+                "maxQpP %d maxQpB %d\n",
+                ctx->api_ctx.frame_num, ctx->g_enc_change_params->minQpI,
+                ctx->g_enc_change_params->maxQpI,
+                ctx->g_enc_change_params->maxDeltaQp,
+                ctx->g_enc_change_params->minQpP,
+                ctx->g_enc_change_params->minQpB,
+                ctx->g_enc_change_params->maxQpP,
+                ctx->g_enc_change_params->maxQpB);
+ 
+         ctx->api_fme.data.frame.extra_data_len +=
+         sizeof(ni_encoder_change_params_t);
+         ctx->api_fme.data.frame.reconf_len = sizeof(ni_encoder_change_params_t);
+         ctx->reconfigCount ++;
+       }
+       break;
+       case XCODER_TEST_RECONF_OFF:
+       default:
+         ;
+     }
+ 
+     // NetInt long term reference frame support
+     side_data = av_frame_get_side_data(&ctx->buffered_fme,
+                                        AV_FRAME_DATA_NETINT_LONG_TERM_REF);
+     if (side_data && (side_data->size == sizeof(AVNetintLongTermRef)))
+     {
+       AVNetintLongTermRef *ltr = (AVNetintLongTermRef*)side_data->data;
+ 
+       ctx->api_fme.data.frame.use_cur_src_as_long_term_pic
+       = ltr->use_cur_src_as_long_term_pic;
+       ctx->api_fme.data.frame.use_long_term_ref
+       = ltr->use_long_term_ref;
+     }
+ 
+     // NetInt support VFR by reconfig bitrate and vui
+     if (ctx->api_param.enable_vfr)
+     {
+       int cur_fps = 0, pre_fps = 0, bit_rate = 0;
+ 
+       pre_fps = ctx->api_ctx.prev_fps;
+ 
+       if (ctx->buffered_fme.pts - ctx->api_ctx.prev_pts) {
+         cur_fps = (avctx->time_base.den / avctx->time_base.num) / (ctx->buffered_fme.pts - ctx->api_ctx.prev_pts);
+       }
+ 
+       ctx->api_ctx.fps_change_detect_count = (pre_fps == cur_fps) ? 0: ctx->api_ctx.fps_change_detect_count + 1;
+ 
+       //change the bitrate for VFR
+       //1. Only when the fps change, setting the new bitrate
+       //2. The interval between two bitrate change settings shall be greater than 1 seconds(hardware limiation)
+       //   or at the start the transcoding, we should detect the init frame rate(30) and the actual framerate
+       //3. The PTS exceptions caused by drop frame or repeat frame should be considered
+       if (((ctx->buffered_fme.coded_picture_number != 0) && (pre_fps != cur_fps) && (cur_fps != 0 )) &&
+           ((ctx->buffered_fme.coded_picture_number < pre_fps) ||
+            ((ctx->buffered_fme.coded_picture_number - ctx->api_ctx.last_change_framenum) > pre_fps)) &&
+           (ctx->api_ctx.fps_change_detect_count >= 2))
+       {
+         bit_rate = pre_fps * (ctx->api_ctx.prev_bitrate / cur_fps);
+ 
+         ctx->g_enc_change_params->enable_option |= NI_SET_CHANGE_PARAM_RC_TARGET_RATE;
+         ctx->g_enc_change_params->bitRate = bit_rate;
+ 
+         //reconfig the vui
+         ctx->g_enc_change_params->enable_option |= NI_SET_CHANGE_PARAM_VUI_HRD_PARAM;
+         ctx->g_enc_change_params->encodeVuiRbsp = 1;
+         memcpy(ctx->g_enc_change_params->vuiRbsp, p_param->ui8VuiRbsp, NI_MAX_VUI_SIZE);
+         ni_overwrite_specified_pos(ctx->g_enc_change_params->vuiRbsp, p_param->pos_num_units_in_tick, avctx->time_base.num);
+         if (avctx->codec_id == AV_CODEC_ID_H264)
+         {
+           ni_overwrite_specified_pos(ctx->g_enc_change_params->vuiRbsp, p_param->pos_num_units_in_tick, avctx->time_base.den * 2);
+         }
+         else
+         {
+           ni_overwrite_specified_pos(ctx->g_enc_change_params->vuiRbsp, p_param->pos_time_scale, avctx->time_base.den);
+         }
+         ctx->g_enc_change_params->vuiDataSizeBits  = NI_MAX_VUI_SIZE * 8;
+         ctx->g_enc_change_params->vuiDataSizeBytes = NI_MAX_VUI_SIZE;
+ 
+         if (ctx->api_fme.data.frame.reconf_len == 0)
+         {
+           ctx->api_fme.data.frame.extra_data_len += sizeof(ni_encoder_change_params_t);
+           ctx->api_fme.data.frame.reconf_len      = sizeof(ni_encoder_change_params_t);
+         }
+ 
+         ctx->api_ctx.prev_bitrate = bit_rate;
+         ctx->api_ctx.last_change_framenum = ctx->buffered_fme.coded_picture_number;
+         ctx->api_ctx.fps_change_detect_count = 0;
+         ctx->api_ctx.prev_fps = cur_fps;
+       }
+       ctx->api_ctx.prev_pts = ctx->buffered_fme.pts;
+     }
+ 
+     // NetInt target bitrate reconfiguration support
+     side_data = av_frame_get_side_data(&ctx->buffered_fme,
+                                        AV_FRAME_DATA_NETINT_BITRATE);
+     if (side_data && (side_data->size == sizeof(int32_t)))
+     {
+       int32_t bitrate = *((int32_t *)side_data->data);
+       if (ctx->api_param.enable_vfr)
+       {
+         ctx->api_ctx.prev_bitrate = bitrate;
+       }
+       ctx->g_enc_change_params->enable_option |= NI_SET_CHANGE_PARAM_RC_TARGET_RATE;
+       ctx->g_enc_change_params->bitRate = bitrate;
+       if (ctx->api_fme.data.frame.reconf_len == 0)
+       {
+         ctx->api_fme.data.frame.extra_data_len += sizeof(ni_encoder_change_params_t);
+         ctx->api_fme.data.frame.reconf_len = sizeof(ni_encoder_change_params_t);
+         ctx->reconfigCount++;
+       }
+     }
+ 
+     // force pic qp demo mode: initial QP (200 frames) -> QP value specified by
+     // ForcePicQpDemoMode (100 frames) -> initial QP (remaining frames)
+     if (p_param->force_pic_qp_demo_mode)
+     {
+       if (ctx->api_ctx.frame_num >= 300)
+       {
+         ctx->api_fme.data.frame.force_pic_qp =
+         p_param->hevc_enc_params.rc.intra_qp;
+       }
+       else if (ctx->api_ctx.frame_num >= 200)
+       {
+         ctx->api_fme.data.frame.force_pic_qp = p_param->force_pic_qp_demo_mode;
+       }
+     }
+     // END NETINT_INTERNAL - currently only for internal testing
+ 
+     // SEI (HDR)
+     // content light level info
+     AVFrameSideData *hdr_side_data;
+ 
+     hdr_side_data = av_frame_get_side_data(
+       &ctx->buffered_fme, AV_FRAME_DATA_CONTENT_LIGHT_LEVEL);
+     if (hdr_side_data && hdr_side_data->size == sizeof(AVContentLightMetadata))
+     {
+       // size of: start code + NAL unit header + payload type byte +
+       //          payload size byte + payload + rbsp trailing bits, default HEVC
+       uint16_t max_content_light_level;
+       uint16_t max_pic_average_light_level;
+       ctx->api_ctx.light_level_data_len = 4;
+       ctx->api_ctx.sei_hdr_content_light_level_info_len = 8 + 4 + 1;
+       if (AV_CODEC_ID_H264 == avctx->codec_id)
+       {
+         ctx->api_ctx.sei_hdr_content_light_level_info_len--;
+       }
+ 
+       max_content_light_level =
+       htons(((AVContentLightMetadata *)hdr_side_data->data)->MaxCLL);
+       max_pic_average_light_level =
+       htons(((AVContentLightMetadata *)hdr_side_data->data)->MaxFALL);
+ 
+       av_log(avctx, AV_LOG_TRACE, "content light level info, MaxCLL %u "
+              "MaxFALL %u\n",
+              ((AVContentLightMetadata *)hdr_side_data->data)->MaxCLL,
+              ((AVContentLightMetadata *)hdr_side_data->data)->MaxFALL);
+       memcpy(ctx->api_ctx.ui8_light_level_data,
+              &max_content_light_level, sizeof(uint16_t));
+       memcpy(&ctx->api_ctx.ui8_light_level_data[2],
+              &max_pic_average_light_level,
+              sizeof(uint16_t));
+ 
+       if (AV_RB24(ctx->api_ctx.ui8_light_level_data) == 0 ||
+           AV_RB24(ctx->api_ctx.ui8_light_level_data) == 1 ||
+           AV_RB24(ctx->api_ctx.ui8_light_level_data) == 2 ||
+           (AV_RB24(ctx->api_ctx.ui8_light_level_data) == 3 &&
+            ctx->api_ctx.ui8_light_level_data[3] != 0 &&
+            ctx->api_ctx.ui8_light_level_data[3] != 1 &&
+            ctx->api_ctx.ui8_light_level_data[3] != 2 &&
+            ctx->api_ctx.ui8_light_level_data[3] != 3))
+       {
+         ctx->api_ctx.sei_hdr_content_light_level_info_len++;
+         ctx->api_ctx.light_level_data_len++;
+         memmove(&ctx->api_ctx.ui8_light_level_data[3],
+                 &ctx->api_ctx.ui8_light_level_data[2], 2);
+         ctx->api_ctx.ui8_light_level_data[2] = 0x3;
+       }
+     }
+ 
+     // mastering display color volume
+     hdr_side_data = av_frame_get_side_data(
+       &ctx->buffered_fme, AV_FRAME_DATA_MASTERING_DISPLAY_METADATA);
+     if (hdr_side_data &&
+         hdr_side_data->size == sizeof(AVMasteringDisplayMetadata))
+     {
+       uint8_t *p_temp = NULL;
+       const int luma_den = 10000;
+       uint32_t uint32_t_tmp;
+       AVMasteringDisplayMetadata *p_src;
+       ctx->api_ctx.mdcv_max_min_lum_data_len = 8;
+       ctx->api_ctx.sei_hdr_mastering_display_color_vol_len = 8 + 6*2 + 2*2 + 2*4 + 1;
+       if (AV_CODEC_ID_H264 == avctx->codec_id)
+       {
+         ctx->api_ctx.sei_hdr_mastering_display_color_vol_len--;
+       }
+ 
+       p_src = (AVMasteringDisplayMetadata *) hdr_side_data->data;
+       // save a copy
+       if (ctx->api_ctx.p_master_display_meta_data)
+       {
+         free(ctx->api_ctx.p_master_display_meta_data);
+         ctx->api_ctx.p_master_display_meta_data = NULL;
+       }
+       ctx->api_ctx.p_master_display_meta_data =
+       malloc(sizeof(AVMasteringDisplayMetadata));
+       if (! ctx->api_ctx.p_master_display_meta_data)
+       {
+         return AVERROR(ENOMEM);
+       }
+       memcpy(ctx->api_ctx.p_master_display_meta_data, p_src,
+              sizeof(AVMasteringDisplayMetadata));
+ 
+       uint32_t_tmp = htonl((uint32_t)(lrint(luma_den * av_q2d(p_src->max_luminance))));
+       memcpy(ctx->api_ctx.ui8_mdcv_max_min_lum_data,
+              &uint32_t_tmp, sizeof(uint32_t));
+ 
+       uint32_t_tmp = htonl((uint32_t)(lrint(luma_den * av_q2d(p_src->min_luminance))));
+       memcpy(&ctx->api_ctx.ui8_mdcv_max_min_lum_data[4],
+              &uint32_t_tmp, sizeof(uint32_t));
+ 
+       p_temp = (uint8_t *)&uint32_t_tmp; // cppcheck-suppress objectIndex
+       if (AV_RB24(p_temp) == 0 ||// cppcheck-suppress objectIndex
+           AV_RB24(p_temp) == 1 ||
+           AV_RB24(p_temp) == 2 ||
+           (AV_RB24(p_temp) == 3 &&
+            ctx->api_ctx.ui8_mdcv_max_min_lum_data[7] != 0 &&
+            ctx->api_ctx.ui8_mdcv_max_min_lum_data[7] != 1 &&
+            ctx->api_ctx.ui8_mdcv_max_min_lum_data[7] != 2 &&
+            ctx->api_ctx.ui8_mdcv_max_min_lum_data[7] != 3))
+       {
+         ctx->api_ctx.sei_hdr_mastering_display_color_vol_len++;
+         ctx->api_ctx.mdcv_max_min_lum_data_len++;
+         if (ctx->api_ctx.ui8_mdcv_max_min_lum_data[3] == 0)
+         {
+           memmove(&ctx->api_ctx.ui8_mdcv_max_min_lum_data[5],
+                   &ctx->api_ctx.ui8_mdcv_max_min_lum_data[4],
+                   sizeof(uint32_t));
+           ctx->api_ctx.ui8_mdcv_max_min_lum_data[5] = 0x3;
+         }
+         else
+         {
+           memmove(&ctx->api_ctx.ui8_mdcv_max_min_lum_data[7],
+                   &ctx->api_ctx.ui8_mdcv_max_min_lum_data[6], 2);
+           ctx->api_ctx.ui8_mdcv_max_min_lum_data[6] = 0x3;
+         }
+       }
+     }
+ 
+     // SEI (HDR10+)
+     uint8_t hdr10p_buf[NI_MAX_SEI_DATA];
+     int hdr10p_num_bytes = 0;
+     int hdr10p_num_bytes_nal_payload = 0;
+     AVFrameSideData *s_data = av_frame_get_side_data(
+       &ctx->buffered_fme, AV_FRAME_DATA_DYNAMIC_HDR_PLUS);
+     if (s_data && s_data->size == sizeof(AVDynamicHDRPlus))
+     {
+       AVDynamicHDRPlus *hdrp = (AVDynamicHDRPlus *)s_data->data;
+       int w, i, j;
+       PutBitContext pb;
+       uint32_t ui_tmp;
+       init_put_bits(&pb, hdr10p_buf, NI_MAX_SEI_DATA);
+ 
+       // HDR10+ SEI header bytes
+       // itu_t_t35_provider_code and itu_t_t35_provider_oriented_code are
+       // contained in the first 4 bytes of payload; pb has all the data until
+       // start of trailer
+       put_bits(&pb, 8, 0);
+       put_bits(&pb, 8, 0x3c); // u16 itu_t_t35_provider_code = 0x003c
+       put_bits(&pb, 8, 0);
+       put_bits(&pb, 8, 0x01); // u16 itu_t_t35_provider_oriented_code = 0x0001
+       put_bits(&pb, 8, 4); // u8 application_identifier = 0x04
+       put_bits(&pb, 8, 0); // u8 application version = 0x00
+       put_bits(&pb, 2, hdrp->num_windows);
+       av_log(avctx, AV_LOG_TRACE, "hdr10+ num_windows %u\n", hdrp->num_windows);
+       for (w = 1; w < hdrp->num_windows; w++)
+       {
+         put_bits(&pb, 16, hdrp->params[w - 1].window_upper_left_corner_x.num);
+         put_bits(&pb, 16, hdrp->params[w - 1].window_upper_left_corner_y.num);
+         put_bits(&pb, 16, hdrp->params[w - 1].window_lower_right_corner_x.num);
+         put_bits(&pb, 16, hdrp->params[w - 1].window_lower_right_corner_y.num);
+         put_bits(&pb, 16, hdrp->params[w - 1].center_of_ellipse_x);
+         put_bits(&pb, 16, hdrp->params[w - 1].center_of_ellipse_y);
+         put_bits(&pb, 8, hdrp->params[w - 1].rotation_angle);
+         put_bits(&pb, 16, hdrp->params[w - 1].semimajor_axis_internal_ellipse);
+         put_bits(&pb, 16, hdrp->params[w - 1].semimajor_axis_external_ellipse);
+         put_bits(&pb, 16, hdrp->params[w - 1].semiminor_axis_external_ellipse);
+         put_bits(&pb, 1, hdrp->params[w - 1].overlap_process_option);
+       }
+ 
+       // values are scaled up according to standard spec
+       ui_tmp = lrint(10000 * av_q2d(hdrp->targeted_system_display_maximum_luminance));
+       put_bits(&pb, 27, ui_tmp);
+       put_bits(&pb, 1, hdrp->targeted_system_display_actual_peak_luminance_flag);
+       av_log(avctx, AV_LOG_TRACE, "hdr10+ targeted_system_display_maximum_luminance %d\n", ui_tmp);
+       av_log(avctx, AV_LOG_TRACE, "hdr10+ targeted_system_display_actual_peak_luminance_flag %u\n",
+              hdrp->targeted_system_display_actual_peak_luminance_flag);
+ 
+       if (hdrp->targeted_system_display_actual_peak_luminance_flag)
+       {
+         put_bits(&pb, 5,
+                  hdrp->num_rows_targeted_system_display_actual_peak_luminance);
+         put_bits(&pb, 5,
+                  hdrp->num_cols_targeted_system_display_actual_peak_luminance);
+         av_log(avctx, AV_LOG_TRACE, "hdr10+ num_rows_targeted_system_display_actual_peak_luminance x num_cols_targeted_system_display_actual_peak_luminance %u x %u\n",
+                hdrp->num_rows_targeted_system_display_actual_peak_luminance,
+                hdrp->num_cols_targeted_system_display_actual_peak_luminance);
+ 
+         for (i = 0; i < hdrp->num_rows_targeted_system_display_actual_peak_luminance; i++)
+         {
+           for (j = 0; j < hdrp->num_cols_targeted_system_display_actual_peak_luminance; j++)
+           {
+             ui_tmp = lrint(15 * av_q2d(hdrp->targeted_system_display_actual_peak_luminance[i][j]));
+             put_bits(&pb, 4, ui_tmp);
+             av_log(avctx, AV_LOG_TRACE, "hdr10+ targeted_system_display_actual_peak_luminance[%d][%d] %d\n", i, j, ui_tmp);
+           }
+         }
+       }
+ 
+       for (w = 0; w < hdrp->num_windows; w++)
+       {
+         for (i = 0; i < 3; i++)
+         {
+           ui_tmp = lrint(100000 * av_q2d(hdrp->params[w].maxscl[i]));
+           put_bits(&pb, 17, ui_tmp);
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ maxscl[%d][%d] %d\n", w, i,
+                  ui_tmp);
+         }
+         ui_tmp = lrint(100000 * av_q2d(hdrp->params[w].average_maxrgb));
+         put_bits(&pb, 17, ui_tmp);
+         av_log(avctx, AV_LOG_TRACE, "hdr10+ average_maxrgb[%d] %d\n",
+                w, ui_tmp);
+ 
+         put_bits(&pb, 4, hdrp->params[w].num_distribution_maxrgb_percentiles);
+         av_log(avctx, AV_LOG_TRACE,
+                "hdr10+ num_distribution_maxrgb_percentiles[%d] %d\n",
+                w, hdrp->params[w].num_distribution_maxrgb_percentiles);
+ 
+         for (i = 0; i < hdrp->params[w].num_distribution_maxrgb_percentiles; i++)
+         {
+           put_bits(&pb, 7, hdrp->params[w].distribution_maxrgb[i].percentage);
+           ui_tmp = lrint(100000 * av_q2d(hdrp->params[w].distribution_maxrgb[i].percentile));
+           put_bits(&pb, 17, ui_tmp);
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ distribution_maxrgb_percentage[%d][%d] %u\n",
+                  w, i, hdrp->params[w].distribution_maxrgb[i].percentage);
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ distribution_maxrgb_percentile[%d][%d] %d\n",
+                  w, i, ui_tmp);
+         }
+ 
+         ui_tmp = lrint(1000 * av_q2d(hdrp->params[w].fraction_bright_pixels));
+         put_bits(&pb, 10, ui_tmp);
+         av_log(avctx, AV_LOG_TRACE, "hdr10+ fraction_bright_pixels[%d] %d\n",
+                w, ui_tmp);
+       }
+ 
+       put_bits(&pb, 1, hdrp->mastering_display_actual_peak_luminance_flag);
+       av_log(avctx, AV_LOG_TRACE,
+              "hdr10+ mastering_display_actual_peak_luminance_flag %u\n",
+              hdrp->mastering_display_actual_peak_luminance_flag);
+       if (hdrp->mastering_display_actual_peak_luminance_flag)
+       {
+         put_bits(&pb, 5, hdrp->num_rows_mastering_display_actual_peak_luminance);
+         put_bits(&pb, 5, hdrp->num_cols_mastering_display_actual_peak_luminance);
+         av_log(avctx, AV_LOG_TRACE, "hdr10+ num_rows_mastering_display_actual_peak_luminance x num_cols_mastering_display_actual_peak_luminance %u x %u\n",
+                hdrp->num_rows_mastering_display_actual_peak_luminance,
+                hdrp->num_cols_mastering_display_actual_peak_luminance);
+ 
+         for (i = 0; i < hdrp->num_rows_mastering_display_actual_peak_luminance; i++)
+         {
+           for (j = 0; j < hdrp->num_cols_mastering_display_actual_peak_luminance; j++)
+           {
+             ui_tmp = lrint(15 * av_q2d(hdrp->mastering_display_actual_peak_luminance[i][j]));
+             put_bits(&pb, 4, ui_tmp);
+             av_log(avctx, AV_LOG_TRACE, "hdr10+ mastering_display_actual_peak_luminance[%d][%d] %d\n", i, j, ui_tmp);
+           }
+         }
+       }
+ 
+       for (w = 0; w < hdrp->num_windows; w++)
+       {
+         put_bits(&pb, 1, hdrp->params[w].tone_mapping_flag);
+         av_log(avctx, AV_LOG_TRACE, "hdr10+ tone_mapping_flag[%d] %u\n",
+                w, hdrp->params[w].tone_mapping_flag);
+ 
+         if (hdrp->params[w].tone_mapping_flag)
+         {
+           ui_tmp = lrint(4095 * av_q2d(hdrp->params[w].knee_point_x));
+           put_bits(&pb, 12, ui_tmp);
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ knee_point_x[%d] %u\n",
+                  w, ui_tmp);
+ 
+           ui_tmp = lrint(4095 * av_q2d(hdrp->params[w].knee_point_y));
+           put_bits(&pb, 12, ui_tmp);
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ knee_point_y[%d] %u\n",
+                  w, ui_tmp);
+ 
+           put_bits(&pb, 4, hdrp->params[w].num_bezier_curve_anchors);
+           av_log(avctx, AV_LOG_TRACE,
+                  "hdr10+ num_bezier_curve_anchors[%d] %u\n",
+                  w, hdrp->params[w].num_bezier_curve_anchors);
+           for (i = 0; i < hdrp->params[w].num_bezier_curve_anchors; i++)
+           {
+             ui_tmp = lrint(1023 * av_q2d(hdrp->params[w].bezier_curve_anchors[i]));
+             put_bits(&pb, 10, ui_tmp);
+             av_log(avctx, AV_LOG_TRACE,
+                    "hdr10+ bezier_curve_anchors[%d][%d] %d\n", w, i, ui_tmp);
+           }
+         }
+ 
+         put_bits(&pb, 1, hdrp->params[w].color_saturation_mapping_flag);
+         av_log(avctx, AV_LOG_TRACE,
+                "hdr10+ color_saturation_mapping_flag[%d] %u\n",
+                w, hdrp->params[w].color_saturation_mapping_flag);
+         if (hdrp->params[w].color_saturation_mapping_flag)
+         {
+           ui_tmp = lrint(8 * av_q2d(hdrp->params[w].color_saturation_weight));
+           put_bits(&pb, 6, ui_tmp);
+           av_log(avctx, AV_LOG_TRACE, "hdr10+ color_saturation_weight[%d] %d\n",
+                  w, ui_tmp);
+         }
+       } // num_windows
+ 
+       hdr10p_num_bytes_nal_payload = hdr10p_num_bytes =
+       (put_bits_count(&pb) + 7) / 8;
+       av_log(avctx, AV_LOG_TRACE, "hdr10+ total bits: %d -> bytes %d\n",
+              put_bits_count(&pb), hdr10p_num_bytes);
+       flush_put_bits(&pb);
+ 
+       hdr10p_num_bytes += insert_emulation_prevent_bytes(
+         hdr10p_buf, hdr10p_num_bytes);
+ 
+       // set header info fields and extra size based on codec
+       if (AV_CODEC_ID_HEVC == avctx->codec_id)
+       {
+         ctx->api_fme.data.frame.sei_hdr_plus_len = NI_HDR10P_SEI_HDR_HEVC_LEN +
+         hdr10p_num_bytes + NI_RBSP_TRAILING_BITS_LEN;
+         ctx->api_fme.data.frame.sei_total_len +=
+         ctx->api_fme.data.frame.sei_hdr_plus_len;
+         ctx->api_ctx.itu_t_t35_hdr10p_sei_hdr_hevc[7] =
+         hdr10p_num_bytes_nal_payload + NI_RBSP_TRAILING_BITS_LEN;
+       }
+       else if (AV_CODEC_ID_H264 == avctx->codec_id)
+       {
+         ctx->api_fme.data.frame.sei_hdr_plus_len = NI_HDR10P_SEI_HDR_H264_LEN +
+         hdr10p_num_bytes + NI_RBSP_TRAILING_BITS_LEN;
+         ctx->api_fme.data.frame.sei_total_len +=
+         ctx->api_fme.data.frame.sei_hdr_plus_len;
+         ctx->api_ctx.itu_t_t35_hdr10p_sei_hdr_h264[6] =
+         hdr10p_num_bytes_nal_payload + NI_RBSP_TRAILING_BITS_LEN;
+       }
+       else
+       {
+         av_log(avctx, AV_LOG_ERROR, "xcoder_send_frame: codec %d not "
+                "supported for SEI !\n", avctx->codec_id);
+         ctx->api_fme.data.frame.sei_hdr_plus_len = 0;
+       }
+     } // hdr10+
+ 
+     // SEI (close caption)
+     side_data = av_frame_get_side_data(&ctx->buffered_fme,AV_FRAME_DATA_A53_CC);
+     if (side_data && side_data->size > 0)
+     {
+       cc_data = side_data->data;
+       cc_size = side_data->size;
+ 
+       memcpy(cc_data_emu_prevent, cc_data, cc_size);
+       cc_size_emu_prevent = cc_size + insert_emulation_prevent_bytes(
+         cc_data_emu_prevent, cc_size);
+ 
+       if (cc_size_emu_prevent != cc_size)
+       {
+         av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: close caption "
+                "emulation prevention bytes added: %d\n",
+                cc_size_emu_prevent - cc_size);
+       }
+ 
+       // set header info fields and extra size based on codec
+       if (AV_CODEC_ID_HEVC == avctx->codec_id)
+       {
+         ctx->api_fme.data.frame.sei_cc_len =
+         NI_CC_SEI_HDR_HEVC_LEN + cc_size_emu_prevent + NI_CC_SEI_TRAILER_LEN;
+         ctx->api_fme.data.frame.sei_total_len +=
+         ctx->api_fme.data.frame.sei_cc_len;
+         ctx->api_ctx.itu_t_t35_cc_sei_hdr_hevc[7] = cc_size + 11;
+         ctx->api_ctx.itu_t_t35_cc_sei_hdr_hevc[16] = (cc_size / 3) | 0xc0;
+       }
+       else if (AV_CODEC_ID_H264 == avctx->codec_id)
+       {
+         ctx->api_fme.data.frame.sei_cc_len =
+         NI_CC_SEI_HDR_H264_LEN + cc_size_emu_prevent + NI_CC_SEI_TRAILER_LEN;
+         ctx->api_fme.data.frame.sei_total_len +=
+         ctx->api_fme.data.frame.sei_cc_len;
+         ctx->api_ctx.itu_t_t35_cc_sei_hdr_h264[6] = cc_size + 11;
+         ctx->api_ctx.itu_t_t35_cc_sei_hdr_h264[15] = (cc_size / 3) | 0xc0;
+       }
+       else
+       {
+         av_log(avctx, AV_LOG_ERROR, "xcoder_send_frame: codec %d not "
+                "supported for SEI !\n", avctx->codec_id);
+         cc_data = NULL;
+         cc_size = 0;
+       }
+     }
+ 
+     // supply QP map if ROI enabled and if ROIs passed in
+     const AVFrameSideData *p_sd = av_frame_get_side_data(
+       &ctx->buffered_fme, AV_FRAME_DATA_REGIONS_OF_INTEREST);
+     if (p_param->hevc_enc_params.roi_enable && p_sd)
+     {
+       int is_new_rois = 1;
+       int nb_roi;
+       const AVRegionOfInterest *roi = NULL;
+       uint32_t self_size = 0;
+ 
+       roi = (const AVRegionOfInterest*)p_sd->data;
+       self_size = roi->self_size;
+       if (! self_size || p_sd->size % self_size)
+       {
+         av_log(avctx, AV_LOG_ERROR, "Invalid AVRegionOfInterest.self_size, "
+                "sd size %d self_size %u\n", p_sd->size, self_size);
+         return AVERROR(EINVAL);
+       }
+ 
+       nb_roi = p_sd->size / self_size;
+       // update ROI(s) if new/different from last one
+       if (0 == ctx->nb_rois || 0 == ctx->roi_side_data_size || ! ctx->av_rois ||
+           ctx->nb_rois != nb_roi || ctx->roi_side_data_size != p_sd->size ||
+           memcmp(ctx->av_rois, p_sd->data, p_sd->size))
+       {
+         ctx->roi_side_data_size = p_sd->size;
+         ctx->nb_rois = nb_roi;
+         free(ctx->av_rois);
+         ctx->av_rois = malloc(p_sd->size);
+         if (! ctx->av_rois)
+         {
+           av_log(avctx, AV_LOG_ERROR, "malloc ROI sidedata failed.\n");
+           return AVERROR(ENOMEM);
+         }
+         memcpy(ctx->av_rois, p_sd->data, p_sd->size);
+       }
+       else
+       {
+         is_new_rois = 0;
+       }
+ 
+       if (is_new_rois)
+       {
+         if (set_roi_map(avctx, p_sd, nb_roi, p_param->source_width,
+                         p_param->source_height,
+                         p_param->hevc_enc_params.rc.intra_qp))
+         {
+           av_log(avctx, AV_LOG_ERROR, "set_roi_map failed\n");
+         }
+       }
+       // ROI data in the frame
+       ctx->api_fme.data.frame.extra_data_len += ctx->api_ctx.roi_len;
+       ctx->api_fme.data.frame.roi_len = ctx->api_ctx.roi_len;
+     }
+ 
+     // if ROI cache is enabled, supply cached QP map if no ROI sidedata is
+     // passed in with this frame
+     if (p_param->hevc_enc_params.roi_enable && ! p_sd && p_param->cacheRoi)
+     {
+       ctx->api_fme.data.frame.extra_data_len += ctx->api_ctx.roi_len;
+       ctx->api_fme.data.frame.roi_len = ctx->api_ctx.roi_len;
+ 
+       av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: supply cached QP map.\n");
+     }
+ 
+     ctx->api_fme.data.frame.pts = ctx->buffered_fme.pts;
+     ctx->api_fme.data.frame.dts = ctx->buffered_fme.pkt_dts;
+     ctx->api_fme.data.frame.video_width = ODD2EVEN(avctx->width);
+     ctx->api_fme.data.frame.video_height = ODD2EVEN(avctx->height);
+     ctx->api_fme.data.frame.ni_pict_type = 0;
+ 
+     if (ctx->api_ctx.force_frame_type)
+     {
+       switch (ctx->buffered_fme.pict_type)
+       {
+         case AV_PICTURE_TYPE_I:
+           ctx->api_fme.data.frame.ni_pict_type = PIC_TYPE_FORCE_IDR;
+           break;
+         case AV_PICTURE_TYPE_P:
+           ctx->api_fme.data.frame.ni_pict_type = PIC_TYPE_P;
+           break;
+         default:
+           ;
+       }
+     }
+     else if (AV_PICTURE_TYPE_I == ctx->buffered_fme.pict_type)
+     {
+       ctx->api_fme.data.frame.force_key_frame = 1;
+       ctx->api_fme.data.frame.ni_pict_type = PIC_TYPE_FORCE_IDR;
+     }
+ 
+     av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: #%"PRIu64" ni_pict_type %d"
+            " forced_header_enable %d intraPeriod %d\n", ctx->api_ctx.frame_num,
+            ctx->api_fme.data.frame.ni_pict_type,
+            p_param->hevc_enc_params.forced_header_enable,
+            p_param->hevc_enc_params.intra_period);
+ 
+     // send HDR SEI when:
+     // - repeatHeaders = 0. Insert on first frame only (IDR)
+     // - repeatHeaders = 1. Insert on every I-frame including I-frames
+     //   generated on the intraPeriod interval as well as I-frames that are
+     //   forced.
+     int send_sei_with_idr = 0;
+     if (0 == ctx->api_ctx.frame_num ||
+         PIC_TYPE_FORCE_IDR == ctx->api_fme.data.frame.ni_pict_type ||
+         (p_param->hevc_enc_params.forced_header_enable &&
+          p_param->hevc_enc_params.intra_period &&
+          0 == (ctx->api_ctx.frame_num % p_param->hevc_enc_params.intra_period)))
+     {
+       send_sei_with_idr = 1;
+     }
+ 
+     // DolbyVision (HRD SEI), HEVC only for now
+     uint8_t hrd_buf[NI_MAX_SEI_DATA];
+     uint32_t hrd_sei_len = 0; // HRD SEI size in bytes
+     if (AV_CODEC_ID_HEVC == avctx->codec_id && p_param->hrd_enable)
+     {
+       if (send_sei_with_idr)
+       {
+         hrd_sei_len += encode_buffering_period_sei(p_param, ctx,
+                                                    ctx->api_ctx.frame_num + 1,
+                                                    hrd_buf);
+       }
+       //printf(" ^^^^ frame_num %u  idr %d\n", ctx->api_ctx.frame_num, send_sei_with_idr);
+       // pic_timing SEI will inserted after encoding
+       ctx->api_fme.data.frame.sei_total_len += hrd_sei_len;
+     }
+ 
+     // HDR SEI
+     if (ctx->api_ctx.sei_hdr_content_light_level_info_len && send_sei_with_idr)
+     {
+       ctx->api_fme.data.frame.sei_hdr_content_light_level_info_len =
+       ctx->api_ctx.sei_hdr_content_light_level_info_len;
+       ctx->api_fme.data.frame.sei_total_len +=
+       ctx->api_fme.data.frame.sei_hdr_content_light_level_info_len;
+     }
+ 
+     if (ctx->api_ctx.sei_hdr_mastering_display_color_vol_len &&
+         send_sei_with_idr)
+     {
+       ctx->api_fme.data.frame.sei_hdr_mastering_display_color_vol_len =
+       ctx->api_ctx.sei_hdr_mastering_display_color_vol_len;
+       ctx->api_fme.data.frame.sei_total_len +=
+       ctx->api_fme.data.frame.sei_hdr_mastering_display_color_vol_len;
+     }
+ 
+     if (p_param->hevc_enc_params.preferred_transfer_characteristics >= 0 &&
+         send_sei_with_idr)
+     {
+       if (AV_CODEC_ID_H264 == avctx->codec_id)
+       {
+         ctx->api_fme.data.frame.preferred_characteristics_data_len = 9;
+       }
+       else
+       {
+         ctx->api_fme.data.frame.preferred_characteristics_data_len = 10;
+       }
+       ctx->api_ctx.preferred_characteristics_data = (uint8_t)p_param->hevc_enc_params.preferred_transfer_characteristics;
+       ctx->api_fme.data.frame.sei_total_len += ctx->api_fme.data.frame.preferred_characteristics_data_len;
+     }
+ 
+     side_data = av_frame_get_side_data(&ctx->buffered_fme,
+                                        AV_FRAME_DATA_NETINT_UDU_SEI);
+     if (side_data && side_data->size > 0)
+     {
+       uint8_t *sei_data = (uint8_t *)side_data->data;
+       int i, sei_len = 0;
+       udu_sei_type = 0x05;
+ 
+      /*
+       * worst case:
+       * even size: each 2B plus a escape 1B
+       * odd size: each 2B plus a escape 1B + 1 byte
+       */
+       udu_sei = malloc(side_data->size * 3 / 2);
+       if (udu_sei == NULL)
+       {
+         av_log(avctx, AV_LOG_ERROR, "failed to allocate memory for sei data.\n");
+         ret = AVERROR(ENOMEM);
+         return ret;
+       }
+ 
+       for (i = 0; i < side_data->size; i++)
+       {
+         if ((2 <= i) && !udu_sei[sei_len - 2] && !udu_sei[sei_len - 1] && (sei_data[i] <= 0x03))
+         {
+           /* insert 0x3 as emulation_prevention_three_byte */
+           udu_sei[sei_len++] = 0x03;
+         }
+         udu_sei[sei_len++] = sei_data[i];
+       }
+ 
+       udu_sei_size = side_data->size;
+       ext_udu_sei_size = sei_len;
+ 
+       if (AV_CODEC_ID_H264 == avctx->codec_id)
+       {
+         /* 4B long start code + 1B nal header + 1B SEI type + Bytes of payload length + Bytes of SEI payload + 1B trailing */
+         sei_len = 6 + ((udu_sei_size + 0xFE) / 0xFF) + ext_udu_sei_size + 1;
+       }
+       else
+       {
+         /* 4B long start code + 2B nal header + 1B SEI type + Bytes of payload length + Bytes of SEI payload + 1B trailing */
+         sei_len = 7 + ((udu_sei_size + 0xFE) / 0xFF) + ext_udu_sei_size + 1;
+       }
+ 
+       /* if the total sei data is about to exceed maximum size allowed, discard the user data unregistered SEI data */
+       if ((ctx->api_fme.data.frame.sei_total_len + sei_len) > NI_ENC_MAX_SEI_BUF_SIZE)
+       {
+         av_log(avctx, AV_LOG_WARNING, "xcoder_send_frame: sei total length %u, udu sei_len %u exceeds maximum sei size %u. discard it.\n",
+                ctx->api_fme.data.frame.sei_total_len, sei_len, NI_ENC_MAX_SEI_BUF_SIZE);
+         free(udu_sei);
+         udu_sei = NULL;
+         udu_sei_size = 0;
+       }
+       else
+       {
+         ctx->api_fme.data.frame.sei_total_len += sei_len;
+       }
+     }
+ 
+     side_data = av_frame_get_side_data(&ctx->buffered_fme,
+                                        AV_FRAME_DATA_NETINT_CUSTOM_SEI);
+     if (side_data && side_data->size > 0)
+     {
+       int i = 0;
+       int64_t local_pts = ctx->buffered_fme.pts;
+       ni_all_custom_sei_t *src_all_custom_sei = (ni_all_custom_sei_t *)side_data->data;
+       ni_custom_sei_t *src_custom_sei = NULL;
+       uint8_t *src_sei_data = NULL;
+       int custom_sei_size = 0;
+       int custom_sei_size_trans = 0;
+       uint8_t custom_sei_type;
+       uint8_t sei_idx = 0;
+       int sei_len = 0;
+       ni_all_custom_sei_t *dst_all_custom_sei = NULL;
+       ni_custom_sei_t *dst_custom_sei = NULL;
+       uint8_t *dst_sei_data = NULL;
+ 
+       dst_all_custom_sei = malloc(sizeof(ni_all_custom_sei_t));
+       if (dst_all_custom_sei == NULL)
+       {
+         av_log(avctx, AV_LOG_ERROR, "failed to allocate memory for custom sei "
+                "data, len:%" PRIu64 ".\n", sizeof(ni_all_custom_sei_t));
+         ret = AVERROR(ENOMEM);
+         return ret;
+       }
+       memset(dst_all_custom_sei, 0 ,sizeof(ni_all_custom_sei_t));
+ 
+       for (sei_idx = 0; sei_idx < src_all_custom_sei->custom_sei_cnt; sei_idx++)
+       {
+         src_custom_sei = &src_all_custom_sei->ni_custom_sei[sei_idx];
+ 
+         custom_sei_type = src_custom_sei->custom_sei_type;
+         custom_sei_size = src_custom_sei->custom_sei_size;
+         src_sei_data = src_custom_sei->custom_sei_data;
+ 
+         dst_custom_sei = &dst_all_custom_sei->ni_custom_sei[sei_idx];
+         dst_sei_data = dst_custom_sei->custom_sei_data;
+ 
+         /* fill sei buffer */
+         // long start code
+         dst_sei_data[sei_len++] = 0x00;
+         dst_sei_data[sei_len++] = 0x00;
+         dst_sei_data[sei_len++] = 0x00;
+         dst_sei_data[sei_len++] = 0x01;
+         if (AV_CODEC_ID_H264 == avctx->codec_id)
+         {
+           dst_sei_data[sei_len++] = 0x06;   //nal type: SEI
+         }
+         else
+         {
+           dst_sei_data[sei_len++] = 0x4e;   //nal type: SEI
+           dst_sei_data[sei_len++] = 0x01;
+         }
+ 
+         // SEI type
+         dst_sei_data[sei_len++] = custom_sei_type;
+ 
+         // original payload size
+         custom_sei_size_trans = custom_sei_size;
+         while (custom_sei_size_trans > 0)
+         {
+           dst_sei_data[sei_len++] = (custom_sei_size_trans > 0xFF ? 0xFF : (uint8_t)custom_sei_size_trans);
+           custom_sei_size_trans -= 0xFF;
+         }
+ 
+         // payload data
+         for (i = 0; (i < custom_sei_size) && (sei_len < (NI_MAX_CUSTOM_SEI_SZ - 2)); i++)
+         {
+           if ((2 <= i) && !dst_sei_data[sei_len - 2] && !dst_sei_data[sei_len - 1] && (src_sei_data[i] <= 0x03))
+           {
+             /* insert 0x3 as emulation_prevention_three_byte */
+             dst_sei_data[sei_len++] = 0x03;
+           }
+           dst_sei_data[sei_len++] = src_sei_data[i];
+         }
+ 
+         if (i != custom_sei_size)
+         {
+           av_log(avctx, AV_LOG_WARNING, "xcoder_send_frame: sei RBSP size out of limit(%d), "
+                  "idx=%u, type=%u, size=%d, custom_sei_loc=%d.\n", NI_MAX_CUSTOM_SEI_SZ,
+                  sei_idx, custom_sei_type, custom_sei_size, src_custom_sei->custom_sei_loc);
+           free(dst_all_custom_sei);
+           dst_all_custom_sei = NULL;
+           break;
+         }
+ 
+         // trailing byte
+         dst_sei_data[sei_len++] = 0x80;
+ 
+         dst_custom_sei->custom_sei_size = sei_len;
+         dst_custom_sei->custom_sei_type = custom_sei_type;
+         dst_custom_sei->custom_sei_loc = src_custom_sei->custom_sei_loc;
+         av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: sei idx=%u,type=%u, len=%d, custom_sei_loc=%d\n",
+                sei_idx, custom_sei_type, sei_len, dst_custom_sei->custom_sei_loc);
+       }
+ 
+       if (dst_all_custom_sei)
+       {
+         dst_all_custom_sei->custom_sei_cnt = src_all_custom_sei->custom_sei_cnt;
+         ctx->api_ctx.pkt_custom_sei[local_pts % NI_FIFO_SZ] = dst_all_custom_sei;
+         av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: sei number %d pts %" PRId64 ".\n",
+                dst_all_custom_sei->custom_sei_cnt, local_pts);
+       }
+     }
+ 
+     if (ctx->api_fme.data.frame.sei_total_len > NI_ENC_MAX_SEI_BUF_SIZE)
+     {
+       av_log(avctx, AV_LOG_ERROR, "xcoder_send_frame: sei total length %u exceeds maximum sei size %u.\n",
+              ctx->api_fme.data.frame.sei_total_len, NI_ENC_MAX_SEI_BUF_SIZE);
+       ret = AVERROR(EINVAL);
+       return ret;
+     }
+ 
+     ctx->api_fme.data.frame.extra_data_len += ctx->api_fme.data.frame.sei_total_len;
+     //FW accomodation: whatever add reconfig size to allocation if sei or roi are present
+     if ((ctx->api_fme.data.frame.sei_total_len ||
+          ctx->api_fme.data.frame.roi_len)
+         && !ctx->api_fme.data.frame.reconf_len)
+     {
+       ctx->api_fme.data.frame.extra_data_len += sizeof(ni_encoder_change_params_t);
+     }
+ 
+     if (ctx->api_ctx.auto_dl_handle != NI_INVALID_DEVICE_HANDLE)
+     {
+       is_hwframe = 0;
+       format_in_use = avctx->sw_pix_fmt;
+       av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: Autodownload mode, disable hw frame\n");
+     }
+     else
+     {
+       format_in_use = ctx->buffered_fme.format;
+     }
+ 
+     if (is_hwframe)
+     {
+       ret = sizeof(ni_hwframe_surface_t);
+     }
+     else
+     {
+       ret = av_image_get_buffer_size(format_in_use,
+                                      ctx->buffered_fme.width,
+                                      ctx->buffered_fme.height, 1);
+     }
+ #if FF_API_PKT_PTS
+     av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: pts=%" PRId64 ", "
+            "pkt_dts=%" PRId64 ", pkt_pts=%" PRId64 "\n",
+            ctx->buffered_fme.pts, ctx->buffered_fme.pkt_dts,
+            ctx->buffered_fme.pkt_pts);
+ #endif
+     av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: buffered_fme.format=%d, "
+            "width=%d, height=%d, pict_type=%d, key_frame=%d, size=%d\n",
+            format_in_use, ctx->buffered_fme.width,
+            ctx->buffered_fme.height, ctx->buffered_fme.pict_type,
+            ctx->buffered_fme.key_frame, ret);
+ 
+     if (ret < 0)
+     {
+       return ret;
+     }
+ 
+     if (is_hwframe)
+     {
+       uint8_t *dsthw;
+       const uint8_t *srchw;
+       ni_frame_buffer_alloc_hwenc(&(ctx->api_fme.data.frame),
+                                   ODD2EVEN(ctx->buffered_fme.width),
+                                   ODD2EVEN(ctx->buffered_fme.height),
+                                   ctx->api_fme.data.frame.extra_data_len);
+       if (!ctx->api_fme.data.frame.p_data[3])
+       {
+         return AVERROR(ENOMEM);
+       }
+ 
+       dsthw = ctx->api_fme.data.frame.p_data[3];
+       srchw = (const uint8_t *) ctx->buffered_fme.data[3];
+       av_log(avctx, AV_LOG_TRACE, "dst=%p src=%p, len =%d\n", dsthw, srchw, ctx->api_fme.data.frame.data_len[3]);
+       memcpy(dsthw, srchw, ctx->api_fme.data.frame.data_len[3]);
+       av_log(avctx, AV_LOG_TRACE, "session_id:%u, FrameIdx:%d, %d, W-%u, H-%u, bit_depth:%d, encoding_type:%d\n",
+              ((ni_hwframe_surface_t *)dsthw)->ui16SessionID,
+              ((ni_hwframe_surface_t *)dsthw)->i8FrameIdx,
+              ((ni_hwframe_surface_t *)dsthw)->i8InstID,
+              ((ni_hwframe_surface_t *)dsthw)->ui16width,
+              ((ni_hwframe_surface_t *)dsthw)->ui16height,
+              ((ni_hwframe_surface_t *)dsthw)->bit_depth,
+              ((ni_hwframe_surface_t *)dsthw)->encoding_type);
+     }
+     else
+     {
+       int dst_stride[NI_MAX_NUM_DATA_POINTERS] = {0};
+       int dst_height_aligned[NI_MAX_NUM_DATA_POINTERS] = {0};
+       int src_height[NI_MAX_NUM_DATA_POINTERS] = {0};
+ 
+       src_height[0] = frame_height;
+       src_height[1] = src_height[2] = frame_height / 2;
+ 
+       ni_get_hw_yuv420p_dim(frame_width, frame_height,
+                             ctx->api_ctx.bit_depth_factor,
+                             avctx->codec_id == AV_CODEC_ID_H264,
+                             dst_stride, dst_height_aligned);
+ 
+       // alignment(16) extra padding for H.264 encoding
+       ni_frame_buffer_alloc_v3(&(ctx->api_fme.data.frame),
+                                ODD2EVEN(ctx->buffered_fme.width),
+                                ODD2EVEN(ctx->buffered_fme.height),
+                                dst_stride,
+                                (avctx->codec_id == AV_CODEC_ID_H264),
+                                ctx->api_fme.data.frame.extra_data_len,
+                                ctx->api_ctx.bit_depth_factor);
+       if (!ctx->api_fme.data.frame.p_data[0])
+       {
+         return AVERROR(ENOMEM);
+       }
+ 
+       if (ctx->api_ctx.auto_dl_handle == NI_INVALID_DEVICE_HANDLE)
+       {
+         av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: api_fme.data_len[0]=%d,"
+                "buffered_fme.linesize=%d/%d/%d, dst alloc linesize = %d/%d/%d, "
+                "src height = %d/%d%d, dst height aligned = %d/%d/%d, "
+                "ctx->api_fme.force_key_frame=%d, extra_data_len=%d "
+                "sei_size=%u (hdr_content_light_level %u "
+                "hdr_mastering_display_color_vol %u hdr10+ %u hrd %u) "
+                "reconf_size=%u roi_size=%u force_pic_qp=%u udu_sei_size=%u "
+                "use_cur_src_as_long_term_pic %u use_long_term_ref %u\n",
+                ctx->api_fme.data.frame.data_len[0],
+                ctx->buffered_fme.linesize[0],
+                ctx->buffered_fme.linesize[1],
+                ctx->buffered_fme.linesize[2],
+                dst_stride[0], dst_stride[1], dst_stride[2],
+                src_height[0], src_height[1], src_height[2],
+                dst_height_aligned[0], dst_height_aligned[1], dst_height_aligned[2],
+                ctx->api_fme.data.frame.force_key_frame,
+                ctx->api_fme.data.frame.extra_data_len,
+                ctx->api_fme.data.frame.sei_total_len,
+                ctx->api_fme.data.frame.sei_hdr_content_light_level_info_len,
+                ctx->api_fme.data.frame.sei_hdr_mastering_display_color_vol_len,
+                ctx->api_fme.data.frame.sei_hdr_plus_len,
+                hrd_sei_len,
+                ctx->api_fme.data.frame.reconf_len,
+                ctx->api_fme.data.frame.roi_len,
+                ctx->api_fme.data.frame.force_pic_qp,
+                udu_sei_size,
+                ctx->api_fme.data.frame.use_cur_src_as_long_term_pic,
+                ctx->api_fme.data.frame.use_long_term_ref);
+ 
+         ni_copy_hw_yuv420p((uint8_t **) ctx->api_fme.data.frame.p_data,
+                            ctx->buffered_fme.data, ctx->buffered_fme.width,
+                            ctx->buffered_fme.height,
+                            ctx->api_ctx.bit_depth_factor,
+                            dst_stride, dst_height_aligned,
+                            ctx->buffered_fme.linesize, src_height);
+ 
+         av_log(avctx, AV_LOG_TRACE, "After memcpy p_data 0:0x%p, 1:0x%p, 2:0x%p"
+                " len:0:%d 1:%d 2:%d\n",
+                ctx->api_fme.data.frame.p_data[0],
+                ctx->api_fme.data.frame.p_data[1],
+                ctx->api_fme.data.frame.p_data[2],
+                ctx->api_fme.data.frame.data_len[0],
+                ctx->api_fme.data.frame.data_len[1],
+                ctx->api_fme.data.frame.data_len[2]);
+       }
+       else
+       {
+         ni_hwframe_surface_t *src_surf;
+         ni_session_data_io_t *p_session_data;
+         av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame:Autodownload to be run\n");
+         avhwf_ctx = (AVHWFramesContext*)ctx->buffered_fme.hw_frames_ctx->data;
+         nif_src_ctx = avhwf_ctx->internal->priv;
+         src_surf = (ni_hwframe_surface_t*)ctx->buffered_fme.data[3];
+         p_session_data = &ctx->api_fme;
+ 
+         ret = ni_device_session_hwdl(&nif_src_ctx->api_ctx, p_session_data, src_surf);
+         if (ret <= 0)
+         {
+           av_log(avctx, AV_LOG_ERROR, "nienc.c:ni_hwdl_frame() failed to retrieve frame\n");
+           return AVERROR_EXTERNAL;
+         }
+       }
+     }
+     // fill in extra data (excluding meta data hdr)
+     uint8_t *dst = (uint8_t *)ctx->api_fme.data.frame.p_data[3] +
+                    ctx->api_fme.data.frame.data_len[3] +
+                    NI_APP_ENC_FRAME_META_DATA_SIZE;
+ 
+     // fill in reconfig data, if enabled
+     // FW accomodation: whatever add reconfig size to dst if sei or roi or reconfig are present
+     if ((ctx->api_fme.data.frame.reconf_len || ctx->api_fme.data.frame.roi_len
+          || ctx->api_fme.data.frame.sei_total_len) && ctx->g_enc_change_params)
+     {
+       memcpy(dst, ctx->g_enc_change_params, sizeof(ni_encoder_change_params_t));
+       dst += sizeof(ni_encoder_change_params_t);
+     }
+ 
+     // fill in ROI map, if enabled
+     if (ctx->api_fme.data.frame.roi_len)
+     {
+       if (AV_CODEC_ID_H264 == avctx->codec_id && ctx->avc_roi_map)
+       {
+         memcpy(dst, ctx->avc_roi_map, ctx->api_fme.data.frame.roi_len);
+         dst += ctx->api_fme.data.frame.roi_len;
+       }
+       else if (AV_CODEC_ID_HEVC == avctx->codec_id && ctx->hevc_roi_map)
+       {
+         memcpy(dst, ctx->hevc_roi_map, ctx->api_fme.data.frame.roi_len);
+         dst += ctx->api_fme.data.frame.roi_len;
+       }
+     }
+ 
+     // HDR mastering display color volume
+     if (ctx->api_fme.data.frame.sei_hdr_mastering_display_color_vol_len)
+     {
+       const int chroma_den = 50000;
+       const int luma_den = 10000;
+       uint16_t dp00 = 0, dp01 = 0, dp10 = 0, dp11 = 0, dp20 = 0, dp21 = 0,
+       wpx = 0, wpy = 0;
+       AVMasteringDisplayMetadata *p_src;
+       ni_enc_mastering_display_colour_volume_t *p_mdcv;
+ 
+       dst[0] = dst[1] = dst[2] = 0;
+       dst[3] = 1;
+       if (AV_CODEC_ID_HEVC == avctx->codec_id)
+       {
+         dst[4] = 0x4e;
+         dst[5] = 1;
+         dst[6] = 0x89;  // payload type=137
+         dst[7] = 0x18;  // payload size=24
+         dst += 8;
+       }
+       else
+       {
+         dst[4] = 0x6;
+         dst[5] = 0x89;  // payload type=137
+         dst[6] = 0x18;  // payload size=24
+         dst += 7;
+       }
+ 
+       p_mdcv = (ni_enc_mastering_display_colour_volume_t*) dst;
+       p_src = (AVMasteringDisplayMetadata*)ctx->api_ctx.p_master_display_meta_data;
+       if (p_src->has_primaries)
+       {
+         // this is stored in r,g,b order and needs to be in g.b,r order
+         // when sent to encoder
+         dp00 = lrint(chroma_den * av_q2d(p_src->display_primaries[1][0]));
+         p_mdcv->display_primaries[0][0] = htons((uint16_t)dp00);
+         dp01 = lrint(chroma_den * av_q2d(p_src->display_primaries[1][1]));
+         p_mdcv->display_primaries[0][1] = htons((uint16_t)dp01);
+         dp10 = lrint(chroma_den * av_q2d(p_src->display_primaries[2][0]));
+         p_mdcv->display_primaries[1][0] = htons((uint16_t)dp10);
+         dp11 = lrint(chroma_den * av_q2d(p_src->display_primaries[2][1]));
+         p_mdcv->display_primaries[1][1] = htons((uint16_t)dp11);
+         dp20 = lrint(chroma_den * av_q2d(p_src->display_primaries[0][0]));
+         p_mdcv->display_primaries[2][0] = htons((uint16_t)dp20);
+         dp21 = lrint(chroma_den * av_q2d(p_src->display_primaries[0][1]));
+         p_mdcv->display_primaries[2][1] = htons((uint16_t)dp21);
+ 
+         wpx = lrint(chroma_den * av_q2d(p_src->white_point[0]));
+         p_mdcv->white_point_x = htons((uint16_t)wpx);
+         wpy = lrint(chroma_den * av_q2d(p_src->white_point[1]));
+         p_mdcv->white_point_y = htons((uint16_t)wpy);
+       }
+ 
+       av_log(avctx, AV_LOG_TRACE, "mastering display color volume, primaries "
+              "%u/%u/%u/%u/%u/%u white_point_x/y %u/%u max/min_lumi %u/%u\n",
+              (uint16_t)dp00, (uint16_t)dp01, (uint16_t)dp10,
+              (uint16_t)dp11, (uint16_t)dp20, (uint16_t)dp21,
+              (uint16_t)wpx,  (uint16_t)wpy,
+              (uint32_t)(luma_den * av_q2d(p_src->max_luminance)),
+              (uint32_t)(luma_den * av_q2d(p_src->min_luminance)));
+ 
+       dst += 6 * 2 + 2 * 2;
+       if (p_src->has_luminance)
+       {
+         memcpy(dst, ctx->api_ctx.ui8_mdcv_max_min_lum_data,
+                ctx->api_ctx.mdcv_max_min_lum_data_len);
+         dst += ctx->api_ctx.mdcv_max_min_lum_data_len;
+       }
+       *dst = 0x80;
+       dst++;
+     }
+ 
+     // HDR content light level info
+     if (ctx->api_fme.data.frame.sei_hdr_content_light_level_info_len)
+     {
+       dst[0] = dst[1] = dst[2] = 0;
+       dst[3] = 1;
+       if (AV_CODEC_ID_HEVC == avctx->codec_id)
+       {
+         dst[4] = 0x4e;
+         dst[5] = 1;
+         dst[6] = 0x90;  // payload type=144
+         dst[7] = 4;     // payload size=4
+         dst += 8;
+       }
+       else
+       {
+         dst[4] = 0x6;
+         dst[5] = 0x90;  // payload type=144
+         dst[6] = 4;     // payload size=4
+         dst += 7;
+       }
+ 
+       memcpy(dst, ctx->api_ctx.ui8_light_level_data,
+              ctx->api_ctx.light_level_data_len);
+       dst += ctx->api_ctx.light_level_data_len;
+       *dst = 0x80;
+       dst++;
+     }
+ 
+     //HLG preferred characteristics SEI
+     if (ctx->api_fme.data.frame.preferred_characteristics_data_len)
+     {
+       dst[0] = dst[1] = dst[2] = 0;
+       dst[3] = 1;
+       if (AV_CODEC_ID_HEVC == avctx->codec_id)
+       {
+         dst[4] = 0x4e;
+         dst[5] = 1;
+         dst[6] = 0x93;  // payload type=147
+         dst[7] = 1;     // payload size=1
+         dst += 8;
+       }
+       else
+       {
+         dst[4] = 0x6;
+         dst[5] = 0x93;  // payload type=147
+         dst[6] = 1;     // payload size=1
+         dst += 7;
+       }
+       *dst = ctx->api_ctx.preferred_characteristics_data;
+       dst++;
+       *dst = 0x80;
+       dst++;
+     }
+     ctx->sentFrame = 1;
+     // close caption
+     if (ctx->api_fme.data.frame.sei_cc_len && cc_data && cc_size)
+     {
+       if (AV_CODEC_ID_HEVC == avctx->codec_id)
+       {
+         memcpy(dst, ctx->api_ctx.itu_t_t35_cc_sei_hdr_hevc,
+                NI_CC_SEI_HDR_HEVC_LEN);
+         dst += NI_CC_SEI_HDR_HEVC_LEN;
+         memcpy(dst, cc_data_emu_prevent, cc_size_emu_prevent);
+         dst += cc_size_emu_prevent;
+         memcpy(dst, ctx->api_ctx.sei_trailer, NI_CC_SEI_TRAILER_LEN);
+         dst += NI_CC_SEI_TRAILER_LEN;
+       }
+       else if (AV_CODEC_ID_H264 == avctx->codec_id)
+       {
+         memcpy(dst, ctx->api_ctx.itu_t_t35_cc_sei_hdr_h264,
+                NI_CC_SEI_HDR_H264_LEN);
+         dst += NI_CC_SEI_HDR_H264_LEN;
+         memcpy(dst, cc_data_emu_prevent, cc_size_emu_prevent);
+         dst += cc_size_emu_prevent;
+         memcpy(dst, ctx->api_ctx.sei_trailer, NI_CC_SEI_TRAILER_LEN);
+         dst += NI_CC_SEI_TRAILER_LEN;
+       }
+     }
+ 
+     // HDR10+
+     if (ctx->api_fme.data.frame.sei_hdr_plus_len)
+     {
+       if (AV_CODEC_ID_HEVC == avctx->codec_id)
+       {
+         memcpy(dst, ctx->api_ctx.itu_t_t35_hdr10p_sei_hdr_hevc,
+                NI_HDR10P_SEI_HDR_HEVC_LEN);
+         dst += NI_HDR10P_SEI_HDR_HEVC_LEN;
+         memcpy(dst, hdr10p_buf, hdr10p_num_bytes);
+         dst += hdr10p_num_bytes;
+         *dst = ctx->api_ctx.sei_trailer[1];
+         dst += NI_RBSP_TRAILING_BITS_LEN;
+       }
+       else if (AV_CODEC_ID_H264 == avctx->codec_id)
+       {
+         memcpy(dst, ctx->api_ctx.itu_t_t35_hdr10p_sei_hdr_h264,
+                NI_HDR10P_SEI_HDR_H264_LEN);
+         dst += NI_HDR10P_SEI_HDR_H264_LEN;
+         memcpy(dst, hdr10p_buf, hdr10p_num_bytes);
+         dst += hdr10p_num_bytes;
+         *dst = ctx->api_ctx.sei_trailer[1];
+         dst += NI_RBSP_TRAILING_BITS_LEN;
+       }
+     }
+ 
+     // HRD SEI
+     if (hrd_sei_len)
+     {
+       memcpy(dst, hrd_buf, hrd_sei_len);
+       dst += hrd_sei_len;
+     }
+ 
+     if (udu_sei && udu_sei_size)
+     {
+       int payload_size = udu_sei_size;
+       *dst++ = 0x00;   //long start code
+       *dst++ = 0x00;
+       *dst++ = 0x00;
+       *dst++ = 0x01;
+       if (AV_CODEC_ID_H264 == avctx->codec_id)
+       {
+         *dst++ = 0x06;   //nal type: SEI
+       }
+       else
+       {
+         *dst++ = 0x4e;   //nal type: SEI
+         *dst++ = 0x01;
+       }
+       *dst++ = udu_sei_type;   //SEI type: user data unregistered or user customization
+ 
+       /* original payload size */
+       while (payload_size > 0)
+       {
+         *dst++ = (payload_size > 0xFF ? 0xFF : (uint8_t)payload_size);
+         payload_size -= 0xFF;
+       }
+ 
+       /* extended payload data */
+       memcpy(dst, udu_sei, ext_udu_sei_size);
+       dst += ext_udu_sei_size;
+ 
+       /* trailing byte */
+       *dst = 0x80;
+       dst++;
+ 
+       free(udu_sei);
+       udu_sei = NULL;
+       udu_sei_size = 0;
+     }
+   }
+ #ifdef NIENC_MULTI_THREAD
+   if (ctx->encoder_flushing)
+   {
+     sent = ni_device_session_write(&ctx->api_ctx, &ctx->api_fme, NI_DEVICE_TYPE_ENCODER);
+ 
+     av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame encoder_flushing: size %d sent to xcoder\n", sent);
+ 
+     if (NI_RETCODE_ERROR_RESOURCE_UNAVAILABLE == sent)
+     {
+       av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame(): Sequence Change in progress, returning EAGAIN\n");
+       ret = AVERROR(EAGAIN);
+       return ret;
+     }
+     else if (NI_RETCODE_ERROR_VPU_RECOVERY == sent)
+     {
+       sent = xcoder_encode_reset(avctx);
+     }
+ 
+     if (sent < 0)
+     {
+       ret = AVERROR(EIO);
+     }
+     else
+     {
+       if (frame && is_hwframe)
+       {
+         av_frame_ref(ctx->sframe_pool[ctx->aFree_Avframes_list[ctx->freeHead]], frame);
+         av_log(avctx, AV_LOG_DEBUG, "AVframe_index = %d popped from head %d\n", ctx->aFree_Avframes_list[ctx->freeHead], ctx->freeHead);
+         if (deq_free_frames(ctx)!= 0)
+         {
+           ret = AVERROR_EXTERNAL;
+           return ret;
+         }
+       }
+       //pushing input pts in circular FIFO
+       ctx->api_ctx.enc_pts_list[ctx->api_ctx.enc_pts_w_idx % NI_FIFO_SZ] = ctx->api_fme.data.frame.pts;
+       ctx->api_ctx.enc_pts_w_idx ++;
+       ret = 0;
+     }
+   }
+   else if (is_hwframe)
+   {
+     sent = ni_device_session_write(&ctx->api_ctx, &ctx->api_fme, NI_DEVICE_TYPE_ENCODER);
+     //ctx->sframe_pool[((niFrameSurface1_t*)((uint8_t*)frame->data[3]))->i8FrameIdx] = av_buffer_ref(frame);
+     av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame: size %d sent to xcoder\n", sent);
+ 
+     if (NI_RETCODE_ERROR_RESOURCE_UNAVAILABLE == sent)
+     {
+       av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame(): Sequence Change in progress, returning EAGAIN\n");
+       ret = AVERROR(EAGAIN);
+       return ret;
+     }
+ 
+     if (sent == -1)
+     {
+       ret = AVERROR(EAGAIN);
+     }
+     else
+     {
+       av_frame_ref(ctx->sframe_pool[((niFrameSurface1_t*)((uint8_t*)frame->data[3]))->i8FrameIdx], frame);
+       av_log(avctx, AV_LOG_DEBUG, "AVframe_index = %d popped from head %d\n", ctx->aFree_Avframes_list[ctx->freeHead], ctx->freeHead);
+       if (deq_free_frames(ctx) != 0)
+       {
+         ret = AVERROR_EXTERNAL;
+         return ret;
+       }
+       //av_frame_ref(ctx->sframe_pool[((ni_hwframe_surface_t*)((uint8_t*)frame->data[3]))->ui16FrameIdx], frame);
+       ret = 0;
+     }
+   }
+   else
+   {
+     av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame start 111 %p, session_info %d, device_handle %d\n",
+            ctx->api_ctx.session_info, ctx->api_ctx.session_id, ctx->api_ctx.device_handle);
+     if ((ctx->api_ctx.session_id != NI_INVALID_SESSION_ID) && (ctx->api_ctx.device_handle != NI_INVALID_DEVICE_HANDLE))
+     {
+       av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame start 111 %p\n", ctx->api_ctx.session_info);
+       write_thread_arg_struct_t *write_thread_args = (write_thread_arg_struct_t *)malloc(sizeof(write_thread_arg_struct_t));
+       pthread_mutex_init(&write_thread_args->mutex, NULL);
+       pthread_cond_init(&write_thread_args->cond, NULL);
+       write_thread_args->running = 0;
+       write_thread_args->ctx = ctx;
+       av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame: session_id %d, device_handle %d\n", ctx->api_ctx.session_id, ctx->api_ctx.device_handle);
+       av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame: ctx %p\n", write_thread_args->ctx);
+       ctx->api_ctx.session_info = (void *)write_thread_args;
+       write_thread_args->running = 1;
+       ret = threadpool_auto_add_task_thread(&pool, write_frame_thread, write_thread_args, 1);
+       if (ret < 0)
+       {
+         av_log(avctx, AV_LOG_ERROR, "failed to add_task_thread to threadpool\n");
+         return ret;
+       }
+     }
+   }
+ #else
+   sent = ni_device_session_write(&ctx->api_ctx, &ctx->api_fme, NI_DEVICE_TYPE_ENCODER);
+   av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame: pts %lld dts %lld size %d sent to xcoder\n",
+          ctx->api_fme.data.frame.pts, ctx->api_fme.data.frame.dts, sent);
+ 
+   // return EIO at error
+   if (NI_RETCODE_ERROR_VPU_RECOVERY == sent)
+   {
+     ret = xcoder_encode_reset(avctx);
+     if (ret < 0)
+     {
+       av_log(avctx, AV_LOG_ERROR, "xcoder_send_frame(): VPU recovery failed:%d, "
+              "returning EIO\n", sent);
+       ret = AVERROR(EIO);
+     }
+     return ret;
+   }
+   else if (sent < 0)
+   {
+     av_log(avctx, AV_LOG_ERROR, "xcoder_send_frame(): failure sent (%d) , "
+            "returning EIO\n", sent);
+     ret = AVERROR(EIO);
+ 
+     // if rejected due to sequence change in progress, revert resolution
+     // setting and will do it again next time.
+     if (ctx->api_fme.data.frame.start_of_stream &&
+         (avctx->width != orig_avctx_width ||
+          avctx->height != orig_avctx_height))
+     {
+       avctx->width = orig_avctx_width;
+       avctx->height = orig_avctx_height;
+     }
+     return ret;
+   }
+   else if (sent == 0)
+   {
+     // case of sequence change in progress
+     if (ctx->api_fme.data.frame.start_of_stream &&
+         (avctx->width != orig_avctx_width ||
+          avctx->height != orig_avctx_height))
+     {
+       avctx->width = orig_avctx_width;
+       avctx->height = orig_avctx_height;
+     }
+ 
+     // when buffer_full, drop the frame and return EAGAIN if in strict timeout
+     // mode, otherwise buffer the frame and it is to be sent out using encode2
+     // API: queue the frame only if not done so yet, i.e. queue is empty
+     // *and* it's a valid frame. ToWatch: what are other rc cases ?
+     if (ctx->api_ctx.status == NI_RETCODE_NVME_SC_WRITE_BUFFER_FULL)
+     {
+       if (ctx->api_param.strict_timeout_mode)
+       {
+         av_log(avctx, AV_LOG_ERROR, "xcoder_send_frame(): Error Strict timeout period exceeded, returning EAGAIN\n");
+         ret = AVERROR(EAGAIN);
+       }
+       else
+       {
+         av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame(): Write buffer full, returning 1\n");
+         ret = 1;
+         if (frame && is_input_fifo_empty(ctx))
+         {
+           enqueue_frame(avctx, frame);
+         }
+       }
+     }
+   }
+   else
+   {
+     if (!ctx->eos_fme_received && is_hwframe)
+     {
+       av_frame_ref(ctx->sframe_pool[ctx->aFree_Avframes_list[ctx->freeHead]], &ctx->buffered_fme);
+       av_log(avctx, AV_LOG_DEBUG, "AVframe_index = %d popped from free head %d\n", ctx->aFree_Avframes_list[ctx->freeHead], ctx->freeHead);
+       av_log(avctx, AV_LOG_TRACE, "ctx->buffered_fme->data[3] %p sframe_pool[%d]->data[3] %p\n",
+              ctx->buffered_fme.data[3], ctx->aFree_Avframes_list[ctx->freeHead],
+              ctx->sframe_pool[ctx->aFree_Avframes_list[ctx->freeHead]]->data[3]);
+       if (ctx->sframe_pool[ctx->aFree_Avframes_list[ctx->freeHead]]->data[3])
+       {
+         av_log(avctx, AV_LOG_DEBUG, "sframe_pool[%d] ui16FrameIdx %u, device_handle %" PRId64 ".\n",
+                ctx->aFree_Avframes_list[ctx->freeHead],
+                ((ni_hwframe_surface_t*)((uint8_t*)ctx->sframe_pool[ctx->aFree_Avframes_list[ctx->freeHead]]->data[3]))->i8FrameIdx,
+                ((ni_hwframe_surface_t*)((uint8_t*)ctx->sframe_pool[ctx->aFree_Avframes_list[ctx->freeHead]]->data[3]))->device_handle);
+         av_log(avctx, AV_LOG_TRACE, "xcoder_send_frame: after ref sframe_pool, hw frame av_buffer_get_ref_count=%d, data[3]=%p\n",
+                av_buffer_get_ref_count(ctx->sframe_pool[ctx->aFree_Avframes_list[ctx->freeHead]]->buf[0]),
+                ctx->sframe_pool[ctx->aFree_Avframes_list[ctx->freeHead]]->data[3]);
+       }
+       if (deq_free_frames(ctx) != 0)
+       {
+         av_log(avctx, AV_LOG_ERROR, "free frames is empty\n");
+         ret = AVERROR_EXTERNAL;
+         return ret;
+       }
+     }
+ 
+     // only if it's NOT sequence change flushing (in which case only the eos
+     // was sent and not the first sc pkt) AND
+     // only after successful sending will it be removed from fifo
+     if (SESSION_RUN_STATE_SEQ_CHANGE_DRAINING != ctx->api_ctx.session_run_state)
+     {
+       if (! is_input_fifo_empty(ctx))
+       {
+         av_fifo_drain(ctx->fme_fifo, sizeof(AVFrame));
+         av_log(avctx, AV_LOG_DEBUG, "fme popped pts:%" PRId64 ", "
+                "fifo size: %" PRIu64 "\n",  ctx->buffered_fme.pts,
+                av_fifo_size(ctx->fme_fifo) / sizeof(AVFrame));
+       }
+       av_frame_unref(&ctx->buffered_fme);
+     }
+     else
+     {
+       av_log(avctx, AV_LOG_TRACE, "XCoder frame(eos) sent, sequence changing! NO fifo pop !\n");
+     }
+ 
+     //pushing input pts in circular FIFO
+     ctx->api_ctx.enc_pts_list[ctx->api_ctx.enc_pts_w_idx % NI_FIFO_SZ] = ctx->api_fme.data.frame.pts;
+     ctx->api_ctx.enc_pts_w_idx++;
+     ret = 0;
+ 
+     // have another check before return: if no more frames in fifo to send and
+     // we've got eos (NULL) frame from upper stream, flag for flushing
+     if (ctx->eos_fme_received && is_input_fifo_empty(ctx))
+     {
+       av_log(avctx, AV_LOG_DEBUG, "Upper stream EOS frame received, fifo empty, start flushing ..\n");
+       ctx->encoder_flushing = 1;
+     }
+   }
+ #endif
+   if (ctx->encoder_flushing)
+   {
+     av_log(avctx, AV_LOG_DEBUG, "xcoder_send_frame flushing ..\n");
+     ret = ni_device_session_flush(&ctx->api_ctx, NI_DEVICE_TYPE_ENCODER);
+   }
+ 
+   return ret;
+ }
+ 
+ static int xcoder_encode_reinit(AVCodecContext *avctx)
+ {
+   int ret = 0;
+   AVFrame tmp_fme;
+   XCoderH265EncContext *ctx = avctx->priv_data;
+ 
+   ctx->eos_fme_received = 0;
+   ctx->encoder_eof = 0;
+   ctx->encoder_flushing = 0;
+ 
+   if (ctx->api_ctx.pts_table && ctx->api_ctx.dts_queue)
+   {
+     xcoder_encode_close(avctx);
+   }
+   ctx->started = 0;
+   ctx->firstPktArrived = 0;
+   ctx->spsPpsArrived = 0;
+   ctx->spsPpsHdrLen = 0;
+   ctx->p_spsPpsHdr = NULL;
+ 
+   // and re-init avctx's resolution to the changed one that is
+   // stored in the first frame of the fifo
+   av_fifo_generic_peek(ctx->fme_fifo, &tmp_fme, sizeof(AVFrame), NULL);
+   av_log(avctx, AV_LOG_INFO, "xcoder_receive_packet resolution "
+          "changing %dx%d -> %dx%d\n", avctx->width, avctx->height,
+          tmp_fme.width, tmp_fme.height);
+   avctx->width = tmp_fme.width;
+   avctx->height = tmp_fme.height;
+ 
+   ret = xcoder_encode_init(avctx);
+   ctx->api_ctx.session_run_state = SESSION_RUN_STATE_NORMAL;
+ 
+   while ((ret >= 0) && !is_input_fifo_empty(ctx))
+   {
+     ctx->api_ctx.session_run_state = SESSION_RUN_STATE_QUEUED_FRAME_DRAINING;
+     ret = xcoder_send_frame(avctx, NULL);
+ 
+     // new resolution changes or buffer full should break flush.
+     // if needed, add new cases here
+     if (SESSION_RUN_STATE_SEQ_CHANGE_DRAINING == ctx->api_ctx.session_run_state)
+     {
+       av_log(avctx, AV_LOG_DEBUG, "xcoder_encode_reinit(): break flush queued frames, "
+              "resolution changes again, session_run_state=%d, status=%d\n",
+              ctx->api_ctx.session_run_state, ctx->api_ctx.status);
+       break;
+     }
+     else if (NI_RETCODE_NVME_SC_WRITE_BUFFER_FULL == ctx->api_ctx.status)
+     {
+       ctx->api_ctx.session_run_state = SESSION_RUN_STATE_NORMAL;
+       av_log(avctx, AV_LOG_DEBUG, "xcoder_encode_reinit(): break flush queued frames, "
+             "because of buffer full, session_run_state=%d, status=%d\n",
+             ctx->api_ctx.session_run_state, ctx->api_ctx.status);
+       break;
+     }
+     else
+     {
+       ctx->api_ctx.session_run_state = SESSION_RUN_STATE_NORMAL;
+       av_log(avctx, AV_LOG_DEBUG, "xcoder_encode_reinit(): continue to flush queued frames, "
+              "ret=%d\n", ret);
+     }
+   }
+ 
+   return ret;
+ }
+ 
+ int xcoder_receive_packet(AVCodecContext *avctx, AVPacket *pkt)
+ {
+   XCoderH265EncContext *ctx = avctx->priv_data;
+   ni_encoder_params_t *p_param = &ctx->api_param;
+   int ret = 0;
+   int recv;
+   ni_packet_t *xpkt = &ctx->api_pkt.data.packet;
+ 
+   av_log(avctx, AV_LOG_DEBUG, "XCoder receive packet\n");
+ 
+   if (ctx->encoder_eof)
+   {
+     av_log(avctx, AV_LOG_TRACE, "xcoder_receive_packet: EOS\n");
+     return AVERROR_EOF;
+   }
+ 
+   ni_packet_buffer_alloc(xpkt, NI_MAX_TX_SZ);
+   while (1)
+   {
+     xpkt->recycle_index = -1;
+     recv = ni_device_session_read(&ctx->api_ctx, &ctx->api_pkt, NI_DEVICE_TYPE_ENCODER);
+ 
+     av_log(avctx, AV_LOG_TRACE, "XCoder receive packet: xpkt.end_of_stream=%d, xpkt.data_len=%d, recv=%d, encoder_flushing=%d, encoder_eof=%d\n",
+            xpkt->end_of_stream, xpkt->data_len, recv, ctx->encoder_flushing, ctx->encoder_eof);
+ 
+     if (recv <= 0)
+     {
+       ctx->encoder_eof = xpkt->end_of_stream;
+       /* not ready ?? */
+       if (ctx->encoder_eof || xpkt->end_of_stream)
+       {
+         if (SESSION_RUN_STATE_SEQ_CHANGE_DRAINING ==
+             ctx->api_ctx.session_run_state)
+         {
+           // after sequence change completes, reset codec state
+           av_log(avctx, AV_LOG_INFO, "xcoder_receive_packet 1: sequence "
+                  "change completed, return AVERROR(EAGAIN) and will reopen "
+                  "codec!\n");
+ 
+           ret = xcoder_encode_reinit(avctx);
+           if (ret >= 0)
+           {
+             ret = AVERROR(EAGAIN);
+           }
+           break;
+         }
+ 
+         ret = AVERROR_EOF;
+         av_log(avctx, AV_LOG_TRACE, "xcoder_receive_packet: got encoder_eof, "
+                "return AVERROR_EOF\n");
+         break;
+       }
+       else
+       {
+         if (NI_RETCODE_ERROR_VPU_RECOVERY == recv)
+         {
+           ret = xcoder_encode_reset(avctx);
+           if (ret < 0)
+           {
+             av_log(avctx, AV_LOG_ERROR, "xcoder_receive_packet(): VPU recovery failed:%d, returning EIO\n", recv);
+             ret = AVERROR(EIO);
+           }
+           return ret;
+         }
+ 
+         if (recv < 0)
+         {
+           if ((NI_RETCODE_ERROR_INVALID_SESSION == recv) && !ctx->started)  // session may be in recovery state, return EAGAIN
+           {
+             av_log(avctx, AV_LOG_ERROR, "XCoder receive packet: VPU might be reset, invalid session id\n");
+             ret = AVERROR(EAGAIN);
+           }
+           else
+           {
+             av_log(avctx, AV_LOG_ERROR, "XCoder receive packet: Persistent failure, returning EIO,ret=%d\n", recv);
+             ret = AVERROR(EIO);
+           }
+           ctx->gotPacket = 0;
+           ctx->sentFrame = 0;
+           break;
+         }
+ 
+         if (ctx->api_param.low_delay_mode && ctx->sentFrame && !ctx->gotPacket)
+         {
+           av_log(avctx, AV_LOG_TRACE, "XCoder receive packet: low delay mode,"
+                  " keep reading until pkt arrives\n");
+           continue;
+         }
+ 
+         ctx->gotPacket = 0;
+         ctx->sentFrame = 0;
+         if (!is_input_fifo_empty(ctx) &&
+             (SESSION_RUN_STATE_NORMAL == ctx->api_ctx.session_run_state) &&
+             (NI_RETCODE_NVME_SC_WRITE_BUFFER_FULL != ctx->api_ctx.status))
+         {
+           ctx->api_ctx.session_run_state = SESSION_RUN_STATE_QUEUED_FRAME_DRAINING;
+           ret = xcoder_send_frame(avctx, NULL);
+ 
+           // if session_run_state is changed in xcoder_send_frame, keep it
+           if (SESSION_RUN_STATE_QUEUED_FRAME_DRAINING == ctx->api_ctx.session_run_state)
+           {
+             ctx->api_ctx.session_run_state = SESSION_RUN_STATE_NORMAL;
+           }
+           if (ret < 0)
+           {
+             av_log(avctx, AV_LOG_ERROR, "xcoder_receive_packet(): xcoder_send_frame 1 error, ret=%d\n",
+                    ret);
+             return ret;
+           }
+           continue;
+         }
+         ret = AVERROR(EAGAIN);
+         if (! ctx->encoder_flushing && ! ctx->eos_fme_received)
+         {
+           av_log(avctx, AV_LOG_TRACE, "xcoder_receive_packet: NOT encoder_"
+                  "flushing, NOT eos_fme_received, return AVERROR(EAGAIN)\n");
+           break;
+         }
+       }
+     }
+     else
+     {
+       /* got encoded data back */
+       int meta_size = NI_FW_ENC_BITSTREAM_META_DATA_SIZE;
+       if (avctx->pix_fmt == AV_PIX_FMT_NI && xpkt->recycle_index >= 0 && xpkt->recycle_index < 1056)
+       {
+         int avframe_index;
+         av_log(avctx, AV_LOG_VERBOSE, "UNREF index %d.\n", xpkt->recycle_index);
+         avframe_index = recycle_index_2_avframe_index(ctx, xpkt->recycle_index);
+         if (avframe_index >=0 && ctx->sframe_pool[avframe_index])
+         {
+           AVFrame *frame = ctx->sframe_pool[avframe_index];
+           void *opaque = av_buffer_get_opaque(frame->buf[0]);
+           // This opaque would carry the valid event handle to help release the
+           // hwframe surface descriptor for windows target.
+           opaque = (void *) ctx->api_ctx.event_handle;
+           av_log(avctx, AV_LOG_TRACE, "xcoder_receive_packet: after ref "
+                  "sframe_pool, hw frame av_buffer_get_ref_count=%d, data[3]=%p "
+                  "event handle:%p\n", av_buffer_get_ref_count(frame->buf[0]),
+                  frame->data[3], opaque);
+           av_frame_unref(frame);
+           av_log(avctx, AV_LOG_DEBUG, "AVframe_index = %d pushed to free tail "
+                  "%d\n", avframe_index, ctx->freeTail);
+           if (enq_free_frames(ctx, avframe_index) != 0)
+           {
+             av_log(avctx, AV_LOG_ERROR, "free frames is full\n");
+           }
+           av_log(avctx, AV_LOG_DEBUG, "enq head %d, tail %d\n",ctx->freeHead, ctx->freeTail);
+           //enqueue the index back to free
+           xpkt->recycle_index = -1;
+         }
+         else
+         {
+           av_log(avctx, AV_LOG_DEBUG, "can't push to tail - avframe_index %d sframe_pool %p\n",
+                  avframe_index, ctx->sframe_pool[avframe_index]);
+         }
+       }
+ 
+       if (! ctx->spsPpsArrived)
+       {
+         ret = AVERROR(EAGAIN);
+         ctx->spsPpsArrived = 1;
+         ctx->spsPpsHdrLen = recv - meta_size;
+         ctx->p_spsPpsHdr = malloc(ctx->spsPpsHdrLen);
+         if (! ctx->p_spsPpsHdr)
+         {
+           ret = AVERROR(ENOMEM);
+           break;
+         }
+ 
+         memcpy(ctx->p_spsPpsHdr, (uint8_t*)xpkt->p_data + meta_size, xpkt->data_len - meta_size);
+ 
+         // start pkt_num counter from 1 to get the real first frame
+         ctx->api_ctx.pkt_num = 1;
+         // for low-latency mode, keep reading until the first frame is back
+         if (ctx->api_param.low_delay_mode)
+         {
+           av_log(avctx, AV_LOG_TRACE, "XCoder receive packet: low delay mode,"
+                  " keep reading until 1st pkt arrives\n");
+           continue;
+         }
+         break;
+       }
+       ctx->gotPacket = 1;
+       ctx->sentFrame = 0;
+ 
+       uint8_t pic_timing_buf[NI_MAX_SEI_DATA];
+       uint32_t pic_timing_sei_len = 0;
+       int nalu_type = 0;
+       const uint8_t *p_start_code;
+       uint32_t stc = -1;
+       uint32_t copy_len = 0;
+       uint8_t *p_src = (uint8_t*)xpkt->p_data + meta_size;
+       uint8_t *p_end = p_src + (xpkt->data_len - meta_size);
+       int is_idr = 0;
+       int64_t local_pts = xpkt->pts;
+       int custom_sei_cnt = 0;
+       int total_custom_sei_len = 0;
+       int sei_idx = 0;
+       ni_all_custom_sei_t *ni_all_custom_sei;
+       ni_custom_sei_t *ni_custom_sei;
+       if (ctx->api_ctx.pkt_custom_sei[local_pts % NI_FIFO_SZ])
+       {
+         ni_all_custom_sei = ctx->api_ctx.pkt_custom_sei[local_pts % NI_FIFO_SZ];
+         custom_sei_cnt = ni_all_custom_sei->custom_sei_cnt;
+         for (sei_idx = 0; sei_idx < custom_sei_cnt; sei_idx ++)
+         {
+           total_custom_sei_len += ni_all_custom_sei->ni_custom_sei[sei_idx].custom_sei_size;
+         }
+       }
+ 
+       if (p_param->hrd_enable || custom_sei_cnt)
+       {
+         // if HRD or custom sei enabled, search for pic_timing or custom SEI insertion point by
+         // skipping non-VCL until video data is found.
+         p_start_code = p_src;
+         if(AV_CODEC_ID_HEVC == avctx->codec_id)
+         {
+           do
+           {
+             stc = -1;
+             p_start_code = avpriv_find_start_code(p_start_code, p_end, &stc);
+             nalu_type = (stc >> 1) & 0x3F;
+           } while (nalu_type > HEVC_NAL_RSV_VCL31);
+ 
+           // calc. length to copy
+           copy_len = p_start_code - 5 - p_src;
+         }
+         else if(AV_CODEC_ID_H264 == avctx->codec_id)
+         {
+           do
+           {
+             stc = -1;
+             p_start_code = avpriv_find_start_code(p_start_code, p_end, &stc);
+             nalu_type = stc & 0x1F;
+           } while (nalu_type > H264_NAL_IDR_SLICE);
+ 
+           // calc. length to copy
+           copy_len = p_start_code - 5 - p_src;
+         }
+         else
+         {
+           av_log(avctx, AV_LOG_ERROR, "xcoder_receive packet: codec %d not "
+                  "supported for SEI !\n", avctx->codec_id);
+         }
+ 
+         if (p_param->hrd_enable)
+         {
+           int is_i_or_idr;
+           if (HEVC_NAL_IDR_W_RADL == nalu_type || HEVC_NAL_IDR_N_LP == nalu_type)
+           {
+             is_idr = 1;
+           }
+           is_i_or_idr = (PIC_TYPE_I   == xpkt->frame_type ||
+                          PIC_TYPE_IDR == xpkt->frame_type ||
+                          PIC_TYPE_CRA == xpkt->frame_type);
+           pic_timing_sei_len = encode_pic_timing_sei2(p_param, ctx,
+                                pic_timing_buf, is_i_or_idr, is_idr, xpkt->pts);
+           // returned pts is display number
+         }
+       }
+ 
+       if (! ctx->firstPktArrived)
+       {
+         int sizeof_spspps_attached_to_idr = ctx->spsPpsHdrLen;
+ 
+         // if not enable forced repeat header, check AV_CODEC_FLAG_GLOBAL_HEADER flag
+         // to determine whether to add a SPS/PPS header in the first packat
+         if ((avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) &&
+             (p_param->hevc_enc_params.forced_header_enable != NI_ENC_REPEAT_HEADERS_ALL_I_FRAMES))
+         {
+           sizeof_spspps_attached_to_idr = 0;
+         }
+         ctx->firstPktArrived = 1;
+         ctx->first_frame_pts = xpkt->pts;
+         ret = ff_alloc_packet2(avctx, pkt,
+                                xpkt->data_len - meta_size + sizeof_spspps_attached_to_idr + total_custom_sei_len + pic_timing_sei_len,
+                                xpkt->data_len - meta_size + sizeof_spspps_attached_to_idr + total_custom_sei_len + pic_timing_sei_len);
+ 
+         if (! ret)
+         {
+           uint8_t *p_side_data, *p_dst;
+           // fill in AVC/HEVC sidedata
+           if ((avctx->flags & AV_CODEC_FLAG_GLOBAL_HEADER) &&
+               (avctx->extradata_size != ctx->spsPpsHdrLen ||
+                memcmp(avctx->extradata, ctx->p_spsPpsHdr, ctx->spsPpsHdrLen)))
+           {
+             avctx->extradata_size = ctx->spsPpsHdrLen;
+             free(avctx->extradata);
+             avctx->extradata = av_mallocz(avctx->extradata_size +
+                                           AV_INPUT_BUFFER_PADDING_SIZE);
+             if (! avctx->extradata)
+             {
+               av_log(avctx, AV_LOG_ERROR,
+                      "Cannot allocate AVC/HEVC header of size %d.\n",
+                      avctx->extradata_size);
+               return AVERROR(ENOMEM);
+             }
+             memcpy(avctx->extradata, ctx->p_spsPpsHdr, avctx->extradata_size);
+           }
+ 
+           p_side_data = av_packet_new_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA,
+                                                 ctx->spsPpsHdrLen);
+           if (p_side_data)
+           {
+             memcpy(p_side_data, ctx->p_spsPpsHdr, ctx->spsPpsHdrLen);
+           }
+ 
+           p_dst = pkt->data;
+           if (sizeof_spspps_attached_to_idr)
+           {
+             memcpy(p_dst, ctx->p_spsPpsHdr, ctx->spsPpsHdrLen);
+             p_dst += ctx->spsPpsHdrLen;
+           }
+ 
+           // 1st pkt, skip buffering_period SEI and insert pic_timing SEI
+           if (pic_timing_sei_len || custom_sei_cnt)
+           {
+             // copy buf_period
+             memcpy(p_dst, p_src, copy_len);
+             p_dst += copy_len;
+ 
+             // copy custom sei before slice
+             sei_idx = 0;
+             while (sei_idx < custom_sei_cnt)
+             {
+               ni_custom_sei = &ni_all_custom_sei->ni_custom_sei[sei_idx];
+               if (ni_custom_sei->custom_sei_loc == NI_CUSTOM_SEI_LOC_AFTER_VCL)
+               {
+                 break;
+               }
+               memcpy(p_dst, ni_custom_sei->custom_sei_data, ni_custom_sei->custom_sei_size);
+               p_dst += ni_custom_sei->custom_sei_size;
+               sei_idx ++;
+             }
+ 
+             // copy pic_timing
+             if (pic_timing_sei_len)
+             {
+               memcpy(p_dst, pic_timing_buf, pic_timing_sei_len);
+               p_dst += pic_timing_sei_len;
+             }
+ 
+             // copy the IDR data
+             memcpy(p_dst, p_src + copy_len,
+                    xpkt->data_len - meta_size - copy_len);
+             p_dst += (xpkt->data_len - meta_size - copy_len);
+ 
+             // copy custom sei after slice
+             while (sei_idx < custom_sei_cnt)
+             {
+               ni_custom_sei = &ni_all_custom_sei->ni_custom_sei[sei_idx];
+               memcpy(p_dst, ni_custom_sei->custom_sei_data, ni_custom_sei->custom_sei_size);
+               p_dst += ni_custom_sei->custom_sei_size;
+               sei_idx ++;
+             }
+           }
+           else
+           {
+             memcpy(p_dst, (uint8_t*)xpkt->p_data + meta_size,
+                    xpkt->data_len - meta_size);
+           }
+         }
+ 
+         // free buffer
+         if (custom_sei_cnt)
+         {
+           free(ctx->api_ctx.pkt_custom_sei[local_pts % NI_FIFO_SZ]);
+           ctx->api_ctx.pkt_custom_sei[local_pts % NI_FIFO_SZ] = NULL;
+         }
+       }
+       else
+       {
+         // insert header when intraRefresh is enabled for every
+         // intraRefreshMinPeriod frames, pkt counting starts from 1, e.g. for
+         // cycle of 100, the header is forced on frame 102, 202, ...;
+         // note that api_ctx.pkt_num returned is the actual index + 1
+         int intra_refresh_hdr_sz = 0;
+         if (ctx->p_spsPpsHdr && ctx->spsPpsHdrLen &&
+             p_param->hevc_enc_params.forced_header_enable &&
+             (1 == p_param->hevc_enc_params.intra_mb_refresh_mode ||
+              2 == p_param->hevc_enc_params.intra_mb_refresh_mode ||
+              3 == p_param->hevc_enc_params.intra_mb_refresh_mode) &&
+             p_param->ui32minIntraRefreshCycle > 0 &&
+             ctx->api_ctx.pkt_num > 3 &&
+             0 == ((ctx->api_ctx.pkt_num - 3) % p_param->ui32minIntraRefreshCycle))
+         {
+           intra_refresh_hdr_sz = ctx->spsPpsHdrLen;
+           av_log(avctx, AV_LOG_TRACE, "xcoder_receive_packet pkt %" PRId64 " "
+                  " force header on intraRefreshMinPeriod %u\n",
+                  ctx->api_ctx.pkt_num - 1, p_param->ui32minIntraRefreshCycle);
+         }
+ 
+         ret = ff_alloc_packet2(avctx, pkt, xpkt->data_len - meta_size + total_custom_sei_len + pic_timing_sei_len + intra_refresh_hdr_sz,
+                                xpkt->data_len - meta_size + total_custom_sei_len + pic_timing_sei_len + intra_refresh_hdr_sz);
+ 
+         if (! ret)
+         {
+           uint8_t *p_dst = pkt->data;
+           if (intra_refresh_hdr_sz)
+           {
+             memcpy(p_dst, ctx->p_spsPpsHdr, intra_refresh_hdr_sz);
+             p_dst += intra_refresh_hdr_sz;
+           }
+           // insert pic_timing if required
+           if (pic_timing_sei_len || custom_sei_cnt)
+           {
+             // for non-IDR, skip AUD and insert
+             // for IDR, skip AUD VPS SPS PPS buf_period and insert
+             memcpy(p_dst, p_src, copy_len);
+             p_dst += copy_len;
+ 
+             // copy custom sei before slice
+             sei_idx = 0;
+             while (sei_idx < custom_sei_cnt)
+             {
+               ni_custom_sei = &ni_all_custom_sei->ni_custom_sei[sei_idx];
+               if (ni_custom_sei->custom_sei_loc == NI_CUSTOM_SEI_LOC_AFTER_VCL)
+               {
+                 break;
+               }
+               memcpy(p_dst, ni_custom_sei->custom_sei_data, ni_custom_sei->custom_sei_size);
+               p_dst += ni_custom_sei->custom_sei_size;
+               sei_idx ++;
+             }
+ 
+             // copy pic_timing
+             if (pic_timing_sei_len)
+             {
+               memcpy(p_dst, pic_timing_buf, pic_timing_sei_len);
+               p_dst += pic_timing_sei_len;
+             }
+ 
+             // copy the video data
+             memcpy(p_dst, p_src + copy_len,
+                    xpkt->data_len - meta_size - copy_len);
+             p_dst += (xpkt->data_len - meta_size - copy_len);
+ 
+             // copy custom sei after slice
+             while (sei_idx < custom_sei_cnt)
+             {
+               ni_custom_sei = &ni_all_custom_sei->ni_custom_sei[sei_idx];
+               memcpy(p_dst, ni_custom_sei->custom_sei_data, ni_custom_sei->custom_sei_size);
+               p_dst += ni_custom_sei->custom_sei_size;
+               sei_idx ++;
+             }
+           }
+           else
+           {
+             memcpy(p_dst, (uint8_t*)xpkt->p_data + meta_size,
+                    xpkt->data_len - meta_size);
+           }
+         }
+ 
+         // free buffer
+         if (custom_sei_cnt)
+         {
+           free(ctx->api_ctx.pkt_custom_sei[local_pts % NI_FIFO_SZ]);
+           ctx->api_ctx.pkt_custom_sei[local_pts % NI_FIFO_SZ] = NULL;
+         }
+       }
+       if (!ret)
+       {
+         if (PIC_TYPE_IDR == xpkt->frame_type ||
+             PIC_TYPE_CRA == xpkt->frame_type)
+         {
+           pkt->flags |= AV_PKT_FLAG_KEY;
+         }
+         pkt->pts = xpkt->pts;
+         /* to ensure pts>dts for all frames, we assign a guess pts for the first 'dtsOffset' frames and then the pts from input stream
+          * is extracted from input pts FIFO.
+          * if GOP = IBBBP and PTSs = 0 1 2 3 4 5 .. then out DTSs = -3 -2 -1 0 1 ... and -3 -2 -1 are the guessed values
+          * if GOP = IBPBP and PTSs = 0 1 2 3 4 5 .. then out DTSs = -1 0 1 2 3 ... and -1 is the guessed value
+          * the number of guessed values is equal to dtsOffset
+          */
+         if (ctx->total_frames_received < ctx->dtsOffset)
+         {
+           // guess dts
+           pkt->dts = ctx->first_frame_pts + ((ctx->gop_offset_count - ctx->dtsOffset) * avctx->ticks_per_frame);
+           ctx->gop_offset_count++;
+         }
+         else
+         {
+           // get dts from pts FIFO
+           pkt->dts = ctx->api_ctx.enc_pts_list[ctx->api_ctx.enc_pts_r_idx % NI_FIFO_SZ];
+           ctx->api_ctx.enc_pts_r_idx++;
+         }
+ 
+         if (ctx->total_frames_received >= 1)
+         {
+           if (pkt->dts < ctx->latest_dts)
+           {
+             av_log(avctx, AV_LOG_WARNING, "dts: %" PRId64 ". < latest_dts: "
+                    "%" PRId64 ".\n", pkt->dts, ctx->latest_dts);
+           }
+         }
+ 
+         if (pkt->dts > pkt->pts)
+         {
+           av_log(avctx, AV_LOG_WARNING, "dts: %" PRId64 ", pts: %" PRId64 ". "
+                  "Forcing dts = pts\n", pkt->dts, pkt->pts);
+           pkt->dts = pkt->pts;
+         }
+ 
+         ctx->total_frames_received++;
+         ctx->latest_dts = pkt->dts;
+         av_log(avctx, AV_LOG_DEBUG, "xcoder_receive_packet pkt %" PRId64 ""
+                " pts %" PRId64 "  dts %" PRId64 "  size %d  st_index %d \n",
+                ctx->api_ctx.pkt_num - 1, pkt->pts, pkt->dts, pkt->size,
+                pkt->stream_index);
+       }
+       ctx->encoder_eof = xpkt->end_of_stream;
+ 
+       if (ctx->encoder_eof &&
+           SESSION_RUN_STATE_SEQ_CHANGE_DRAINING ==
+           ctx->api_ctx.session_run_state)
+       {
+         // after sequence change completes, reset codec state
+         av_log(avctx, AV_LOG_TRACE, "xcoder_receive_packet 2: sequence change "
+                "completed, return 0 and will reopen codec !\n");
+         ret = xcoder_encode_reinit(avctx);
+       }
+       else if(!is_input_fifo_empty(ctx) &&
+               (SESSION_RUN_STATE_NORMAL == ctx->api_ctx.session_run_state) &&
+               (NI_RETCODE_NVME_SC_WRITE_BUFFER_FULL != ctx->api_ctx.status))
+       {
+         ctx->api_ctx.session_run_state = SESSION_RUN_STATE_QUEUED_FRAME_DRAINING;
+         ret = xcoder_send_frame(avctx, NULL);
+ 
+         // if session_run_state is changed in xcoder_send_frame, keep it
+         if (SESSION_RUN_STATE_QUEUED_FRAME_DRAINING == ctx->api_ctx.session_run_state)
+         {
+           ctx->api_ctx.session_run_state = SESSION_RUN_STATE_NORMAL;
+         }
+         if (ret < 0)
+         {
+           av_log(avctx, AV_LOG_ERROR, "xcoder_receive_packet(): xcoder_send_frame 2 error, ret=%d\n",
+                  ret);
+           return ret;
+         }
+       }
+       break;
+     }
+   }
+ 
+   return ret;
+ }
+ 
+ int xcoder_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
+                         const AVFrame *frame, int *got_packet)
+ {
+   XCoderH265EncContext *ctx = avctx->priv_data;
+   int ret;
+ 
+   av_log(avctx, AV_LOG_DEBUG, "XCoder encode frame\n");
+ 
+   ret = xcoder_send_frame(avctx, frame);
+   // return immediately for critical errors
+   if (AVERROR(ENOMEM) == ret || AVERROR_EXTERNAL == ret ||
+       (ret < 0 && ctx->encoder_eof))
+   {
+     return ret;
+   }
+ 
+   ret = xcoder_receive_packet(avctx, pkt);
+   if (ret == AVERROR(EAGAIN) || ret == AVERROR_EOF)
+   {
+     *got_packet = 0;
+   }
+   else if (ret < 0)
+   {
+     return ret;
+   }
+   else
+   {
+     *got_packet = 1;
+   }
+ 
+   return 0;
+ }
+ 
+ bool free_frames_isempty(XCoderH265EncContext *ctx)
+ {
+   return  (ctx->freeHead == ctx->freeTail);
+ }
+ 
+ bool free_frames_isfull(XCoderH265EncContext *ctx)
+ {
+   return  (ctx->freeHead == ((ctx->freeTail == MAX_NUM_FRAMEPOOL_HWAVFRAME) ? 0 : ctx->freeTail + 1));
+ }
+ 
+ int deq_free_frames(XCoderH265EncContext *ctx)
+ {
+   if (free_frames_isempty(ctx))
+   {
+     return -1;
+   }
+   ctx->aFree_Avframes_list[ctx->freeHead] = -1;
+   ctx->freeHead = (ctx->freeHead == MAX_NUM_FRAMEPOOL_HWAVFRAME) ? 0 : ctx->freeHead + 1;
+   return 0;
+ }
+ 
+ int enq_free_frames(XCoderH265EncContext *ctx, int idx)
+ {
+   if (free_frames_isfull(ctx))
+   {
+     return -1;
+   }
+   ctx->aFree_Avframes_list[ctx->freeTail] = idx;
+   ctx->freeTail = (ctx->freeTail == MAX_NUM_FRAMEPOOL_HWAVFRAME) ? 0 : ctx->freeTail + 1;
+   return 0;
+ }
+ 
+ int recycle_index_2_avframe_index(XCoderH265EncContext *ctx, uint32_t recycleIndex)
+ {
+   int i;
+   for (i = 0; i < MAX_NUM_FRAMEPOOL_HWAVFRAME; i++)
+   {
+     if (ctx->sframe_pool[i]->data[3])
+     {
+       if (((ni_hwframe_surface_t*)((uint8_t*)ctx->sframe_pool[i]->data[3]))->i8FrameIdx == recycleIndex)
+       {
+         return i;
+       }
+       else
+       {
+         //av_log(NULL, AV_LOG_TRACE, "sframe_pool[%d] ui16FrameIdx %u != recycleIndex %u\n", i, ((niFrameSurface1_t*)((uint8_t*)ctx->sframe_pool[i]->data[3]))->ui16FrameIdx, recycleIndex);
+       }
+     }
+     else
+     {
+       //av_log(NULL, AV_LOG_TRACE, "sframe_pool[%d] data[3] NULL\n", i);
+     }
+   }
+   return -1;
+ }
+ 
+ // Needed for yuvbypass on FFmpeg-n4.3+
+ #if ((LIBAVCODEC_VERSION_MAJOR >= 58) && (LIBAVCODEC_VERSION_MINOR >= 82))
+ const AVCodecHWConfigInternal *ff_ni_enc_hw_configs[] = {
+   HW_CONFIG_ENCODER_FRAMES(NI,  NI),
+   HW_CONFIG_ENCODER_DEVICE(YUV420P, NI),
+   HW_CONFIG_ENCODER_DEVICE(YUV420P10, NI),
+   NULL,
+ };
+ #endif
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/nienc.h FFmpeg-n4.3.1/libavcodec/nienc.h
*** base_ffmpeg_n4.3.1/libavcodec/nienc.h	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/nienc.h	2021-11-04 21:55:58.347593967 -0700
***************
*** 0 ****
--- 1,68 ----
+ /*
+  * NetInt XCoder H.264/HEVC Encoder common code header
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ #ifndef AVCODEC_NIENC_H
+ #define AVCODEC_NIENC_H
+ 
+ #include <ni_rsrc_api.h>
+ #include <ni_util.h>
+ #include <ni_device_api.h>
+ 
+ #include "libavutil/internal.h"
+ 
+ #include "avcodec.h"
+ #include "internal.h"
+ #include "libavutil/opt.h"
+ #include "libavutil/imgutils.h"
+ // Needed for yuvbypass on FFmpeg-n4.3+
+ #if ((LIBAVCODEC_VERSION_MAJOR >= 58) && (LIBAVCODEC_VERSION_MINOR >= 82))
+ #include "hwconfig.h"
+ #endif
+ 
+ #include "nicodec.h"
+ 
+ int xcoder_encode_init(AVCodecContext *avctx);
+   
+ int xcoder_encode_close(AVCodecContext *avctx);
+ 
+ int xcoder_send_frame(AVCodecContext *avctx, const AVFrame *frame);
+ 
+ int xcoder_receive_packet(AVCodecContext *avctx, AVPacket *pkt);
+ 
+ int xcoder_encode_frame(AVCodecContext *avctx, AVPacket *pkt,
+ const AVFrame *frame, int *got_packet);
+ 
+ bool free_frames_isempty(XCoderH265EncContext *ctx);
+ 
+ bool free_frames_isfull(XCoderH265EncContext *ctx);
+ 
+ int deq_free_frames(XCoderH265EncContext *ctx);
+ 
+ int enq_free_frames(XCoderH265EncContext *ctx, int idx);
+ 
+ int recycle_index_2_avframe_index(XCoderH265EncContext *ctx, uint32_t recycleIndex);
+ 
+ // Needed for yuvbypass on FFmpeg-n4.3+
+ #if ((LIBAVCODEC_VERSION_MAJOR >= 58) && (LIBAVCODEC_VERSION_MINOR >= 82))
+ extern const AVCodecHWConfigInternal *ff_ni_enc_hw_configs[];
+ #endif
+ 
+ #endif /* AVCODEC_NIENC_H */
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/nienc_h264.c FFmpeg-n4.3.1/libavcodec/nienc_h264.c
*** base_ffmpeg_n4.3.1/libavcodec/nienc_h264.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/nienc_h264.c	2021-12-21 15:39:35.010154336 -0800
***************
*** 0 ****
--- 1,88 ----
+ /*
+  * NetInt XCoder H.264 Encoder
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ #include "nienc.h"
+ 
+ 
+ #define OFFSETENC(x) offsetof(XCoderH265EncContext, x)
+ #define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+ static const AVOption enc_options[] = {
+   { "xcoder",    "Select which XCoder card to use.",  OFFSETENC(dev_xcoder),
+     AV_OPT_TYPE_STRING, { .str = "bestload" }, CHAR_MIN, CHAR_MAX, VE, "xcoder" },
+   { "bestload",      "Pick the least loaded XCoder/encoder available.", 0, AV_OPT_TYPE_CONST,
+     { .str = "bestload" }, 0, 0, VE, "xcoder" },
+ 
+   { "bestinst",      "Pick the XCoder/encoder with the least number of running encoding instances.", 0, AV_OPT_TYPE_CONST,
+     { .str = "bestinst" }, 0, 0, VE, "xcoder" },
+ 
+   { "list",      "List the available XCoder cards.", 0, AV_OPT_TYPE_CONST,
+     { .str = "list" }, 0, 0, VE, "xcoder" },
+ 
+   { "enc",       "Select which encoder to use by index. First is 0, second is 1, and so on.", OFFSETENC(dev_enc_idx),
+     AV_OPT_TYPE_INT, { .i64 = BEST_DEVICE_LOAD }, -1, INT_MAX, VE, "enc" },
+     
+   { "iosize",       "Specify a custom NVMe IO transfer size (multiples of 4096 only).", OFFSETENC(nvme_io_size),
+     AV_OPT_TYPE_INT, { .i64 = BEST_DEVICE_LOAD }, -1, INT_MAX, VE, "iosize" },
+     
+   { "keep_alive_timeout",       "Specify a custom session keep alive timeout in seconds.", OFFSETENC(keep_alive_timeout),
+     AV_OPT_TYPE_INT, { .i64 = NI_DEFAULT_KEEP_ALIVE_TIMEOUT }, NI_MIN_KEEP_ALIVE_TIMEOUT, NI_MAX_KEEP_ALIVE_TIMEOUT, VE, "keep_alive_timeout" },
+ 
+   { "xcoder-params", "Set the XCoder configuration using a :-separated list of key=value parameters", OFFSETENC(xcoder_opts), 
+     AV_OPT_TYPE_STRING, { 0 }, 0, 0, VE },
+ 
+   { "xcoder-gop", "Set the XCoder custom gop using a :-separated list of key=value parameters", OFFSETENC(xcoder_gop), 
+   AV_OPT_TYPE_STRING, { 0 }, 0, 0, VE },
+ 
+ 
+ 
+   { NULL }
+ };
+ 
+ static const AVClass h264_xcoderenc_class = {
+   .class_name = "h264_ni_enc",
+   .item_name = av_default_item_name,
+   .option = enc_options,
+   .version = LIBAVUTIL_VERSION_INT,
+ };
+ 
+ AVCodec ff_h264_ni_encoder = {
+   .name           = "h264_ni_enc",
+   .long_name      = NULL_IF_CONFIG_SMALL("H.264 NetInt encoder v" NI_XCODER_REVISION),
+   .type           = AVMEDIA_TYPE_VIDEO,
+   .id             = AV_CODEC_ID_H264,
+   .init           = xcoder_encode_init,
+   .send_frame     = xcoder_send_frame,
+   .receive_packet = xcoder_receive_packet,
+   .encode2        = xcoder_encode_frame,
+   .close          = xcoder_encode_close,
+   .priv_data_size = sizeof(XCoderH265EncContext),
+   .priv_class     = &h264_xcoderenc_class,
+   .capabilities   = AV_CODEC_CAP_DELAY,
+   .pix_fmts = (const enum AVPixelFormat[]) {
+                                             AV_PIX_FMT_YUV420P,
+                                             AV_PIX_FMT_YUV420P10BE,
+                                             AV_PIX_FMT_YUV420P10LE,
+                                             AV_PIX_FMT_YUVJ420P,
+                                             AV_PIX_FMT_NI,
+                                             AV_PIX_FMT_NONE},
+ // Needed for yuvbypass on FFmpeg-n4.3+
+ #if ((LIBAVCODEC_VERSION_MAJOR >= 58) && (LIBAVCODEC_VERSION_MINOR >= 82))
+   .hw_configs     = ff_ni_enc_hw_configs,
+ #endif
+ };
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/nienc_hevc.c FFmpeg-n4.3.1/libavcodec/nienc_hevc.c
*** base_ffmpeg_n4.3.1/libavcodec/nienc_hevc.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/nienc_hevc.c	2021-12-21 15:39:35.010154336 -0800
***************
*** 0 ****
--- 1,88 ----
+ /*
+  * NetInt XCoder HEVC Encoder
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ #include "nienc.h"
+ 
+ 
+ #define OFFSETENC(x) offsetof(XCoderH265EncContext, x)
+ #define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+ static const AVOption enc_options[] = {
+   { "xcoder",    "Select which XCoder card to use.",  OFFSETENC(dev_xcoder),
+     AV_OPT_TYPE_STRING, { .str = "bestload" }, CHAR_MIN, CHAR_MAX, VE, "xcoder" },
+   { "bestload",      "Pick the least loaded XCoder/encoder available.", 0, AV_OPT_TYPE_CONST,
+     { .str = "bestload" }, 0, 0, VE, "xcoder" },
+ 
+   { "bestinst",      "Pick the XCoder/encoder with the least number of running encoding instances.", 0, AV_OPT_TYPE_CONST,
+     { .str = "bestinst" }, 0, 0, VE, "xcoder" },
+ 
+   { "list",      "List the available XCoder cards.", 0, AV_OPT_TYPE_CONST,
+     { .str = "list" }, 0, 0, VE, "xcoder" },
+ 
+   { "enc",       "Select which encoder to use by index. First is 0, second is 1, and so on.", OFFSETENC(dev_enc_idx),
+     AV_OPT_TYPE_INT, { .i64 = BEST_DEVICE_LOAD }, -1, INT_MAX, VE, "enc" },
+   
+   { "iosize",       "Specify a custom NVMe IO transfer size (multiples of 4096 only).", OFFSETENC(nvme_io_size),
+     AV_OPT_TYPE_INT, { .i64 = BEST_DEVICE_LOAD }, -1, INT_MAX, VE, "iosize" },
+     
+   { "keep_alive_timeout",       "Specify a custom session keep alive timeout in seconds.", OFFSETENC(keep_alive_timeout),
+     AV_OPT_TYPE_INT, { .i64 = NI_DEFAULT_KEEP_ALIVE_TIMEOUT }, NI_MIN_KEEP_ALIVE_TIMEOUT, NI_MAX_KEEP_ALIVE_TIMEOUT, VE, "keep_alive_timeout" },
+ 
+   { "xcoder-params", "Set the XCoder configuration using a :-separated list of key=value parameters", OFFSETENC(xcoder_opts), 
+     AV_OPT_TYPE_STRING, { 0 }, 0, 0, VE },
+ 
+   { "xcoder-gop", "Set the XCoder custom gop using a :-separated list of key=value parameters", OFFSETENC(xcoder_gop), 
+   AV_OPT_TYPE_STRING, { 0 }, 0, 0, VE },
+ 
+ 
+ 
+   { NULL }
+ };
+ 
+ static const AVClass h265_xcoderenc_class = {
+   .class_name = "h265_ni_enc",
+   .item_name = av_default_item_name,
+   .option = enc_options,
+   .version = LIBAVUTIL_VERSION_INT,
+ };
+ 
+ AVCodec ff_h265_ni_encoder = {
+   .name           = "h265_ni_enc",
+   .long_name      = NULL_IF_CONFIG_SMALL("H.265 NetInt encoder v" NI_XCODER_REVISION),
+   .type           = AVMEDIA_TYPE_VIDEO,
+   .id             = AV_CODEC_ID_H265,
+   .init           = xcoder_encode_init,
+   .send_frame     = xcoder_send_frame,
+   .receive_packet = xcoder_receive_packet,
+   .encode2        = xcoder_encode_frame,
+   .close          = xcoder_encode_close,
+   .priv_data_size = sizeof(XCoderH265EncContext),
+   .priv_class     = &h265_xcoderenc_class,
+   .capabilities   = AV_CODEC_CAP_DELAY,
+   .pix_fmts = (const enum AVPixelFormat[]) {
+                                             AV_PIX_FMT_YUV420P,
+                                             AV_PIX_FMT_YUV420P10BE,
+                                             AV_PIX_FMT_YUV420P10LE,
+                                             AV_PIX_FMT_YUVJ420P,
+                                             AV_PIX_FMT_NI,
+                                             AV_PIX_FMT_NONE},
+ // Needed for yuvbypass on FFmpeg-n4.3+
+ #if ((LIBAVCODEC_VERSION_MAJOR >= 58) && (LIBAVCODEC_VERSION_MINOR >= 82))
+   .hw_configs     = ff_ni_enc_hw_configs,
+ #endif
+ };
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/ni_hevc_extradata.c FFmpeg-n4.3.1/libavcodec/ni_hevc_extradata.c
*** base_ffmpeg_n4.3.1/libavcodec/ni_hevc_extradata.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/ni_hevc_extradata.c	2021-09-13 14:19:52.152858778 -0700
***************
*** 0 ****
--- 1,100 ----
+ /*
+  * NetInt HEVC tile bitstream filter common source code
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ /**
+  * @file
+  *
+  * Extract tile rows and columns number from HEVC AVPacket extra-data using
+  * FFmpeg coded bitstream APIs.
+  */
+ 
+ #include "config.h"
+ 
+ #include "libavutil/avassert.h"
+ 
+ #include "avcodec.h"
+ #include "bsf.h"
+ #include "cbs.h"
+ #include "cbs_h265.h"
+ 
+ #include "ni_hevc_extradata.h"
+ 
+ #if CONFIG_HEVC_FRAME_SPLIT_BSF
+ 
+ int av_hevc_extract_tiles_from_extradata(uint8_t *extradata, size_t extradata_size,
+                                          int *tile_row, int *tile_col)
+ {
+     int i, ret;
+     AVCodecParameters par_in;
+     CodedBitstreamContext *cbc;
+     CodedBitstreamFragment td;
+     CodedBitstreamUnit *unit;
+     H265RawPPS *pps;
+ 
+     if (!extradata || !tile_row || !tile_col) {
+         ret = AVERROR(EINVAL);
+         av_log(NULL, AV_LOG_ERROR, "invalid arguments\n");
+         return ret;
+     }
+ 
+     ret = ff_cbs_init(&cbc, AV_CODEC_ID_HEVC, NULL);
+     if (ret < 0) {
+         av_log(NULL, AV_LOG_ERROR, "failed to initialize cbc\n");
+         return ret;
+     }
+ 
+     memset(&par_in, 0, sizeof(AVCodecParameters));
+     par_in.extradata = extradata;
+     par_in.extradata_size = extradata_size;
+ 
+     memset(&td, 0, sizeof(CodedBitstreamFragment));
+ 
+     ret = ff_cbs_read_extradata(cbc, &td, &par_in);
+     if (ret < 0) {
+         av_log(NULL, AV_LOG_ERROR, "failed to read extradata\n");
+         goto out;
+     }
+ 
+     for (i = 0; i < td.nb_units; i++) {
+         unit = &td.units[i];
+         if (unit->type == HEVC_NAL_PPS) {
+             pps = (H265RawPPS *)unit->content;
+             *tile_row = pps->tiles_enabled_flag ? pps->num_tile_rows_minus1 + 1 : 1;
+             *tile_col = pps->tiles_enabled_flag ? pps->num_tile_columns_minus1 + 1 : 1;
+             break;
+         }
+     }
+ 
+ out:
+     ff_cbs_fragment_free(cbc, &td);
+     ff_cbs_close(&cbc);
+     return ret;
+ }
+ 
+ #else
+ 
+ int av_hevc_extract_tiles_from_extradata(uint8_t *extradata, size_t extradata_size,
+                                          int *tile_row, int *tile_col)
+ {
+     return AVERROR(ENOSYS);
+ }
+ 
+ #endif
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/ni_hevc_extradata.h FFmpeg-n4.3.1/libavcodec/ni_hevc_extradata.h
*** base_ffmpeg_n4.3.1/libavcodec/ni_hevc_extradata.h	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/ni_hevc_extradata.h	2021-09-13 14:19:52.148858760 -0700
***************
*** 0 ****
--- 1,31 ----
+ /*
+  * NetInt HEVC tile bitstream filter common code header
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ #ifndef AVCODEC_HEVC_EXTRADATA_H
+ #define AVCODEC_HEVC_EXTRADATA_H
+ 
+ #include <stddef.h>
+ #include <stdint.h>
+ 
+ int av_hevc_extract_tiles_from_extradata(uint8_t *extradata, size_t extradata_size,
+                                          int *tile_row, int *tile_col);
+ 
+ #endif
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/ni_hevc_frame_split_bsf.c FFmpeg-n4.3.1/libavcodec/ni_hevc_frame_split_bsf.c
*** base_ffmpeg_n4.3.1/libavcodec/ni_hevc_frame_split_bsf.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/ni_hevc_frame_split_bsf.c	2021-09-13 14:19:52.152858778 -0700
***************
*** 0 ****
--- 1,691 ----
+ /*
+  * NetInt HEVC frame split BSF common source code
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ /**
+  * @file
+  *
+  * This bitstream filter splits HEVC stream into packets containing just one
+  * frame and re-encoding them with tile flags so that the splited packets can
+  * be decoded independently.
+  */
+ 
+ #include "libavutil/avassert.h"
+ 
+ #include "avcodec.h"
+ #include "bsf.h"
+ #include "bsf_internal.h"
+ #include "cbs.h"
+ #include "cbs_h265.h"
+ #include "ni_hevc_extradata.h"
+ #include "ni_hevc_rbsp.h"
+ 
+ 
+ struct tile_format {
+     int log2_ctb_size;
+     int num_tile_columns;
+     int num_tile_rows;
+     int ctb_width;
+     int ctb_height;
+     int width;
+     int height;
+ 
+     int *column_width;
+     int *row_height;
+     int *col_idx;
+     int *row_idx;
+ };
+ 
+ typedef struct HEVCFSplitContext {
+     AVPacket *buffer_pkt;
+     CodedBitstreamContext *cbc;
+     CodedBitstreamFragment temporal_unit;
+ 
+     struct tile_format *tiles[HEVC_MAX_PPS_COUNT];
+     struct tile_format **this_tile;
+     ni_bitstream_t *streams;
+ 
+     int tile_enabled;
+     int num_tiles;
+     int unit_offset;
+     int nb_slices;
+ } HEVCFSplitContext;
+ 
+ static int slice_addr_to_idx(HEVCFSplitContext *s, AVBSFContext *ctx,
+                              int slice_addr, int hid)
+ {
+     int x, y;
+     struct tile_format *format = s->tiles[hid];
+ 
+     av_assert0(format);
+ 
+     x = slice_addr % format->ctb_width;
+     y = slice_addr / format->ctb_width;
+ 
+     return format->col_idx[x] + format->num_tile_columns * format->row_idx[y];
+ }
+ 
+ static void slice_geo(HEVCFSplitContext *s, AVBSFContext *ctx, int slice_idx,
+                       int *width, int *height, int hid)
+ {
+     int x, y;
+     struct tile_format *format = s->tiles[hid];
+ 
+     av_assert0(format);
+ 
+     x = slice_idx % format->num_tile_columns;
+     y = slice_idx / format->num_tile_columns;
+ 
+     *width = format->column_width[x];
+     *height = format->row_height[y];
+ }
+ 
+ static int hevc_frame_resolve_tiles(HEVCFSplitContext *s, AVBSFContext *ctx,
+                                     const H265RawSPS *sps, const H265RawPPS *pps)
+ {
+     int i, j;
+     int log2_ctb_size;
+     int limit;
+     struct tile_format *format;
+     int *index_buffer;
+     int index_len;
+ 
+     if (pps->pps_pic_parameter_set_id >= HEVC_MAX_PPS_COUNT) {
+         av_log(ctx, AV_LOG_ERROR, "pps id %d exceeds maximus\n", pps->pps_pic_parameter_set_id);
+         return AVERROR(EINVAL);
+     }
+ 
+     if (!s->tiles[pps->pps_pic_parameter_set_id]) {
+         format = av_mallocz(sizeof(struct tile_format));
+         if (!format) {
+             av_log(ctx, AV_LOG_ERROR, "failed to allocate tile format\n");
+             return AVERROR(ENOMEM);
+         }
+         s->tiles[pps->pps_pic_parameter_set_id] = format;
+     } else {
+         format = s->tiles[pps->pps_pic_parameter_set_id];
+     }
+ 
+     if (!pps->tiles_enabled_flag) {
+         av_log(ctx, AV_LOG_ERROR, "tile enabled flags invalid\n");
+         return AVERROR(ENODEV);
+     }
+ 
+     log2_ctb_size = (sps->log2_min_luma_coding_block_size_minus3 + 3) +
+                      sps->log2_diff_max_min_luma_coding_block_size;
+     format->ctb_width = (sps->pic_width_in_luma_samples + (1 << log2_ctb_size) - 1) >> log2_ctb_size;
+     format->ctb_height = (sps->pic_height_in_luma_samples + (1 << log2_ctb_size) - 1) >> log2_ctb_size;
+     format->num_tile_columns = pps->num_tile_columns_minus1 + 1;
+     format->num_tile_rows = pps->num_tile_rows_minus1 + 1;
+     format->log2_ctb_size = log2_ctb_size;
+     format->width = sps->pic_width_in_luma_samples;
+     format->height = sps->pic_height_in_luma_samples;
+ 
+     av_log(ctx, AV_LOG_DEBUG, "ctb_size %d, ctb_width %d, ctb_height %d, uniform_spacing_flag %d\n",
+            log2_ctb_size, format->ctb_width, format->ctb_height, pps->uniform_spacing_flag);
+ 
+     index_len = sizeof(int) * ((pps->num_tile_columns_minus1 + 1) +
+                 (pps->num_tile_rows_minus1 + 1) + format->ctb_width +
+                 format->ctb_height);
+ 
+     index_buffer = av_mallocz(index_len);
+     if (!index_buffer) {
+         av_log(ctx, AV_LOG_ERROR, "failed to allocate index buffer\n");
+         return AVERROR(ENOMEM);
+     }
+ 
+     format->column_width = index_buffer;
+     format->row_height = format->column_width + (pps->num_tile_columns_minus1 + 1);
+     format->col_idx = format->row_height + (pps->num_tile_rows_minus1 + 1);
+     format->row_idx = format->col_idx + format->ctb_width;
+ 
+     if (pps->uniform_spacing_flag) {
+         for (i = 0, limit = 0; i < pps->num_tile_columns_minus1; i++) {
+             format->column_width[i] = (((i + 1) * format->ctb_width) / (pps->num_tile_columns_minus1 + 1) -
+                     (i * format->ctb_width) / (pps->num_tile_columns_minus1 + 1)) << log2_ctb_size;
+             limit += format->column_width[i];
+         }
+         format->column_width[i] = sps->pic_width_in_luma_samples - limit;
+ 
+         for (i = 0, limit = 0; i < pps->num_tile_rows_minus1; i++) {
+             format->row_height[i] = (((i + 1) * format->ctb_height) / (pps->num_tile_rows_minus1 + 1) -
+                     (i * format->ctb_height) / (pps->num_tile_rows_minus1 + 1)) << log2_ctb_size;
+             limit += format->row_height[i];
+         }
+         format->row_height[i] = sps->pic_height_in_luma_samples - limit;
+     } else {
+         for (i = 0, limit = 0; i < pps->num_tile_columns_minus1; i++) {
+             format->column_width[i] = (pps->column_width_minus1[i] + 1) << log2_ctb_size;
+             limit += format->column_width[i];
+         }
+         format->column_width[i] = sps->pic_width_in_luma_samples - limit;
+ 
+         for (i = 0, limit = 0; i < pps->num_tile_rows_minus1; i++) {
+             format->row_height[i] = (pps->row_height_minus1[i] + 1) << log2_ctb_size;
+             limit += format->row_height[i];
+         }
+         format->row_height[i] = sps->pic_height_in_luma_samples - limit;
+     }
+ 
+     limit = (format->column_width[0] + (1 << log2_ctb_size) - 1) >> log2_ctb_size;
+     for (i = j = 0; i < format->ctb_width; i++) {
+         if (i >= limit) {
+             j++;
+             limit += ((format->column_width[j] + (1 << log2_ctb_size) - 1) >> log2_ctb_size);
+         }
+         format->col_idx[i] = j;
+     }
+ 
+     limit = (format->row_height[0] + (1 << log2_ctb_size) - 1) >> log2_ctb_size;
+     for (i = j = 0; i < format->ctb_height; i++) {
+         if (i >= limit) {
+             j++;
+             limit += ((format->row_height[j] + (1 << log2_ctb_size) - 1) >> log2_ctb_size);
+         }
+         format->row_idx[i] = j;
+     }
+ 
+     /* dump index buffer */
+     for (i = 0; i < pps->num_tile_columns_minus1 + 1; i++) {
+         av_log(ctx, AV_LOG_DEBUG, "column_width: %d %d\n", i, format->column_width[i]);
+     }
+ 
+     for (i = 0; i < pps->num_tile_rows_minus1 + 1; i++) {
+         av_log(ctx, AV_LOG_DEBUG, "row_width: %d %d\n", i, format->row_height[i]);
+     }
+ 
+     for (i = 0; i < format->ctb_width; i++) {
+         av_log(ctx, AV_LOG_DEBUG, "column_idx: %d %d\n", i, format->col_idx[i]);
+     }
+ 
+     for (i = 0; i < format->ctb_height; i++) {
+         av_log(ctx, AV_LOG_DEBUG, "row_idx: %d %d\n", i, format->row_idx[i]);
+     }
+ 
+     return 0;
+ }
+ 
+ static int hevc_frame_init_tiles(HEVCFSplitContext *s, AVBSFContext *ctx)
+ {
+     CodedBitstreamH265Context *priv = s->cbc->priv_data;
+     const H265RawSPS *sps;
+     const H265RawPPS *pps;
+     int i, ret;
+ 
+     for (i = 0; i < s->temporal_unit.nb_units; i++) {
+         CodedBitstreamUnit *unit = &s->temporal_unit.units[i];
+         if (unit->type == HEVC_NAL_PPS) {
+             pps = (H265RawPPS *)unit->content;
+             break;
+         }
+     }
+ 
+     if (i >= s->temporal_unit.nb_units) {
+         av_log(ctx, AV_LOG_ERROR, "cannot find valid header\n");
+         return AVERROR(ENODEV);
+     }
+ 
+     sps = priv->sps[pps->pps_seq_parameter_set_id];
+     if (!sps) {
+         av_log(ctx, AV_LOG_ERROR, "invalid pps data\n");
+         return AVERROR(EINVAL);
+     }
+ 
+     if (!pps->tiles_enabled_flag) {
+         av_log(ctx, AV_LOG_ERROR, "tile is disabled\n");
+         return AVERROR(ENODEV);
+     }
+ 
+     s->tile_enabled = !!pps->tiles_enabled_flag;
+     s->num_tiles = (pps->num_tile_columns_minus1 + 1) * (pps->num_tile_rows_minus1 + 1);
+ 
+     ret = hevc_frame_resolve_tiles(s, ctx, sps, pps);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_ERROR, "failed to resolve tiles\n");
+         return ret;
+     }
+ 
+     s->this_tile = &s->tiles[pps->pps_pic_parameter_set_id];
+     if (!s->this_tile) {
+         av_log(ctx, AV_LOG_ERROR, "invalid tile format\n");
+         return AVERROR(EINVAL);
+     }
+ 
+     return 0;
+ }
+ 
+ static int hevc_frame_encode_vps(HEVCFSplitContext *s, AVBSFContext *ctx,
+                                  CodedBitstreamUnit *unit, int tile_idx)
+ {
+     ni_bitstream_t *stream = &s->streams[tile_idx];
+     H265RawVPS *vps = unit->content;
+     int ret;
+ 
+     ff_ni_write_nal_header(stream, HEVC_NAL_VPS, 0, 1);
+     ret = ff_ni_hevc_encode_nal_vps(stream, ctx, vps);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_ERROR, "failed to encode vps for tile %d\n", tile_idx);
+         return ret;
+     }
+ 
+     return 0;
+ }
+ 
+ static int hevc_frame_tiles_encode_vps(HEVCFSplitContext *s, AVBSFContext *ctx,
+                                        CodedBitstreamUnit *unit)
+ {
+     int i, ret;
+ 
+     for (i = 0; i < s->num_tiles; i++) {
+         ret = hevc_frame_encode_vps(s, ctx, unit, i);
+         if (ret)
+             break;
+     }
+ 
+     return ret;
+ }
+ 
+ static int hevc_frame_encode_sps(HEVCFSplitContext *s, AVBSFContext *ctx,
+                                  CodedBitstreamUnit *unit, int tile_idx, int hid)
+ {
+     int ret, width, height;
+     ni_bitstream_t *stream = &s->streams[tile_idx];
+     H265RawSPS *sps = unit->content;
+ 
+     slice_geo(s, ctx, tile_idx, &width, &height, hid);
+ 
+     av_log(ctx, AV_LOG_DEBUG, "tile_idx %d, pixel %dx%d\n", tile_idx, width, height);
+ 
+     ff_ni_write_nal_header(stream, HEVC_NAL_SPS, 0, 1);
+     ret = ff_ni_hevc_encode_nal_sps(stream, ctx, sps, width, height);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_ERROR, "failed to encode sps for tile %d\n", tile_idx);
+         return ret;
+     }
+ 
+     return 0;
+ }
+ 
+ static int hevc_frame_tiles_encode_sps(HEVCFSplitContext *s, AVBSFContext *ctx,
+                                        CodedBitstreamUnit *unit, int hid)
+ {
+     int i, ret;
+ 
+     for (i = 0; i < s->num_tiles; i++) {
+         ret = hevc_frame_encode_sps(s, ctx, unit, i, hid);
+         if (ret)
+             break;
+     }
+ 
+     return ret;
+ }
+ 
+ static int hevc_frame_encode_pps(HEVCFSplitContext *s, AVBSFContext *ctx,
+                                  CodedBitstreamUnit *unit, int tile_idx)
+ {
+     ni_bitstream_t *stream = &s->streams[tile_idx];
+     H265RawPPS *pps = unit->content;
+     int ret;
+ 
+     ff_ni_write_nal_header(stream, HEVC_NAL_PPS, 0, 1);
+     ret = ff_ni_hevc_encode_nal_pps(stream, ctx, pps, 1, 1, 1);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_ERROR, "failed to encode pps for tile %d\n", tile_idx);
+         return ret;
+     }
+ 
+     return 0;
+ }
+ 
+ static int hevc_frame_tiles_encode_pps(HEVCFSplitContext *s, AVBSFContext *ctx,
+                                        CodedBitstreamUnit *unit)
+ {
+     int i, ret;
+ 
+     for (i = 0; i < s->num_tiles; i++) {
+         ret = hevc_frame_encode_pps(s, ctx, unit, i);
+         if (ret)
+             break;
+     }
+ 
+     return ret;
+ }
+ 
+ static int hevc_frame_encode_slice_header(HEVCFSplitContext *s, AVBSFContext *ctx,
+                                           CodedBitstreamUnit *unit, int tile_idx, int hid)
+ {
+     H265RawSlice *slice = unit->content;
+     ni_bitstream_t *stream = &s->streams[tile_idx];
+     CodedBitstreamH265Context *priv = s->cbc->priv_data;
+     H265RawPPS *pps = priv->pps[hid];
+     H265RawSPS *sps = priv->sps[pps->pps_seq_parameter_set_id];
+     int i, ret;
+ 
+     ff_ni_write_nal_header(stream, slice->header.nal_unit_header.nal_unit_type, 0, 1);
+ 
+     ret = ff_ni_hevc_encode_nal_slice_header(stream, ctx, &slice->header,
+             sps, pps, -1, -1 , 1 /* disable tile */, 0, 0, 1 /* independent */);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_ERROR, "failed to encode slice header for tile %d\n", tile_idx);
+         return ret;
+     }
+ 
+     av_assert0((slice->data_bit_start % 8) == 0);
+ 
+     for (i = 0; i < slice->data_size; i++) {
+         ni_put_bits(stream, 8, slice->data[i]);
+     }
+ 
+     return 0;
+ }
+ 
+ static int hevc_frame_init_bitstream(HEVCFSplitContext *s)
+ {
+     int i;
+ 
+     s->streams = av_mallocz(s->num_tiles * sizeof(ni_bitstream_t));
+     if (!s->streams) {
+         return AVERROR(ENOMEM);
+     }
+ 
+     for (i = 0; i < s->num_tiles; i++) {
+         ni_bitstream_init(&s->streams[i]);
+     }
+ 
+     return 0;
+ }
+ 
+ static int hevc_frame_parse_tiles(HEVCFSplitContext *s, AVBSFContext *ctx,
+                                   H265RawSPS *sps, H265RawPPS *pps)
+ {
+     struct tile_format *format = *s->this_tile;
+     int log2_ctb_size;
+ 
+     if (!pps->tiles_enabled_flag) {
+         av_log(ctx, AV_LOG_ERROR, "tile_enabled_flag unset\n");
+         return AVERROR(ENODEV);
+     }
+ 
+     if (sps->pic_width_in_luma_samples != format->width ||
+             sps->pic_height_in_luma_samples != format->height) {
+         av_log(ctx, AV_LOG_ERROR, "pixel size not match\n");
+         return AVERROR(ENODEV);
+     }
+ 
+     if (pps->num_tile_columns_minus1 + 1 != format->num_tile_columns ||
+             pps->num_tile_rows_minus1 + 1 != format->num_tile_rows) {
+         av_log(ctx, AV_LOG_ERROR, "tiles partition not match\n");
+         return AVERROR(ENODEV);
+     }
+ 
+     log2_ctb_size = (sps->log2_min_luma_coding_block_size_minus3 + 3) +
+             sps->log2_diff_max_min_luma_coding_block_size;
+     if (log2_ctb_size != format->log2_ctb_size) {
+         av_log(ctx, AV_LOG_ERROR, "ctb size not match\n");
+         return AVERROR(ENODEV);
+     }
+ 
+     return 0;
+ }
+ 
+ static int hevc_frame_split_filter(AVBSFContext *ctx, AVPacket *out)
+ {
+     HEVCFSplitContext *s = ctx->priv_data;
+     CodedBitstreamFragment *td = &s->temporal_unit;
+     int i, ret, tile_idx, new_size, *slice_addr;
+     H265RawSlice *slice;
+     ni_bitstream_t *stream = &s->streams[0];
+ 
+     if (!s->tile_enabled) {
+         av_assert0(s->tile_enabled);
+         goto passthrough;
+     }
+ 
+     if (s->buffer_pkt->data) {
+         av_assert0(s->nb_slices > 0);
+         goto slice_split;
+     }
+ 
+     ret = ff_bsf_get_packet_ref(ctx, s->buffer_pkt);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_DEBUG, "failed to get packet ref: 0x%x\n", ret);
+         return ret;
+     }
+ 
+     ret = ff_cbs_read_packet(s->cbc, td, s->buffer_pkt);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_WARNING, "Failed to parse temporal unit.\n");
+         goto passthrough;
+     }
+ 
+     s->nb_slices = 0;
+     s->unit_offset = 0;
+     for (i = 0; i < td->nb_units; i++) {
+         CodedBitstreamUnit *unit = &td->units[i];
+         av_log(ctx, AV_LOG_DEBUG, "query index %d, unit type %d\n", i, unit->type);
+ 
+         if (unit->type == HEVC_NAL_VPS) {
+             ret = hevc_frame_tiles_encode_vps(s, ctx, unit);
+             if (ret < 0) {
+                 av_log(ctx, AV_LOG_ERROR, "failed to re-encode vps\n");
+                 return ret;
+             }
+         } else if (unit->type == HEVC_NAL_SPS) {
+             if (i < td->nb_units - 1 && td->units[i + 1].type == HEVC_NAL_PPS) {
+                 H265RawPPS *pps = td->units[i + 1].content;
+                 H265RawSPS *sps = unit->content;
+                 if (pps->pps_seq_parameter_set_id == sps->sps_seq_parameter_set_id) {
+                     ret = hevc_frame_parse_tiles(s, ctx, sps, pps);
+                     if (ret < 0) {
+                         av_log(ctx, AV_LOG_ERROR, "failed to parse tiles\n");
+                         return ret;
+                     }
+ 
+                     ret = hevc_frame_tiles_encode_sps(s, ctx, unit, pps->pps_pic_parameter_set_id);
+                     if (ret < 0) {
+                         av_log(ctx, AV_LOG_ERROR, "failed to re-encode sps\n");
+                         return ret;
+                     }
+                 } else {
+                     av_log(ctx, AV_LOG_ERROR, "seq_parameter_set_id mismatch: %d, %d\n",
+                            pps->pps_seq_parameter_set_id, sps->sps_seq_parameter_set_id);
+                     return AVERROR(EINVAL);
+                 }
+             } else {
+                 av_log(ctx, AV_LOG_ERROR, "failed to find PPS after SPS\n");
+                 return AVERROR(EINVAL);
+             }
+         } else if (unit->type == HEVC_NAL_PPS) {
+             ret = hevc_frame_tiles_encode_pps(s, ctx, unit);
+             if (ret < 0) {
+                 av_log(ctx, AV_LOG_ERROR, "failed to re-encode pps\n");
+                 return ret;
+             }
+         } else if (unit->type >= HEVC_NAL_TRAIL_N && unit->type <= HEVC_NAL_RSV_VCL31) {
+             if (s->nb_slices == 0) {
+                 s->unit_offset = i;
+             }
+             s->nb_slices++;
+         }
+     }
+ 
+     if (s->nb_slices == 0) {
+         ret = AVERROR(EAGAIN);
+         goto end;
+     }
+ 
+ slice_split:
+     for (i = s->unit_offset; i < td->nb_units; i++) {
+         CodedBitstreamUnit *unit = &td->units[i];
+         if ((int) unit->type >= HEVC_NAL_TRAIL_N && unit->type <= HEVC_NAL_RSV_VCL31) {
+             slice = unit->content;
+             tile_idx = slice_addr_to_idx(s, ctx, slice->header.slice_segment_address,
+                     slice->header.slice_pic_parameter_set_id);
+             av_assert0(tile_idx >= 0 && tile_idx < s->num_tiles);
+             av_log(ctx, AV_LOG_DEBUG, "slice_seg_addr %d, tile_idx %d\n",
+                    slice->header.slice_segment_address, tile_idx);
+ 
+             ret = hevc_frame_encode_slice_header(s, ctx, unit, tile_idx,
+                     slice->header.slice_pic_parameter_set_id);
+             if (ret) {
+                 av_log(ctx, AV_LOG_ERROR, "failed to re-encode slice header\n");
+                 av_assert0(0);
+             }
+ 
+             stream = &s->streams[tile_idx];
+             break;
+         }
+     }
+ 
+     new_size = (int) (ni_bitstream_count(stream) / 8);
+     ret = av_new_packet(out, new_size);
+     if (ret < 0) {
+         return ret;
+     }
+ 
+     av_packet_copy_props(out, s->buffer_pkt);
+ 
+     slice_addr = (int *)av_packet_new_side_data(out, AV_PKT_DATA_SLICE_ADDR, sizeof(*slice_addr));
+     av_assert0(slice_addr);
+     *slice_addr = tile_idx;
+ 
+     ni_bitstream_fetch(stream, out->data, new_size);
+     ni_bitstream_reset(stream);
+ 
+     s->unit_offset++;
+     if (s->unit_offset < td->nb_units) {
+         // To be continued...
+         return ret;
+     }
+ 
+ end:
+     av_packet_unref(s->buffer_pkt);
+     ff_cbs_fragment_reset(s->cbc, td);
+     return ret;
+ 
+ passthrough:
+     av_packet_move_ref(out, s->buffer_pkt);
+     ff_cbs_fragment_reset(s->cbc, td);
+ 
+     return ret;
+ }
+ 
+ static int hevc_frame_split_init(AVBSFContext *ctx)
+ {
+     HEVCFSplitContext *s = ctx->priv_data;
+     CodedBitstreamFragment *td = &s->temporal_unit;
+     int ret;
+ 
+     s->buffer_pkt = av_packet_alloc();
+     if (!s->buffer_pkt)
+         return AVERROR(ENOMEM);
+ 
+     ret = ff_cbs_init(&s->cbc, AV_CODEC_ID_HEVC, ctx);
+     if (ret < 0)
+         return ret;
+ 
+     s->cbc->decompose_unit_types    = NULL;
+     s->cbc->nb_decompose_unit_types = 0;
+ //    s->cbc->decompose_unit_types    = (CodedBitstreamUnitType*)decompose_unit_types;
+ //    s->cbc->nb_decompose_unit_types = FF_ARRAY_ELEMS(decompose_unit_types);
+ 
+     /* extradata is a must */
+ //    if (!ctx->par_in->extradata_size)
+ //        return AVERROR(ENODEV);
+     if (!ctx->par_in->extradata_size)
+         return 0;
+ 
+     ret = ff_cbs_read_extradata(s->cbc, td, ctx->par_in);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_ERROR, "Failed to parse extradata.\n");
+         goto fail_out;
+     }
+ 
+     ret = hevc_frame_init_tiles(s, ctx);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_ERROR, "Failed to initialize tiles\n");
+         goto fail_out;
+     }
+ 
+     ret = hevc_frame_init_bitstream(s);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_ERROR, "failed to initialize bitstream\n");
+         goto fail_out;
+     }
+ 
+     ff_cbs_fragment_reset(s->cbc, td);
+     return 0;
+ 
+ fail_out:
+     ff_cbs_fragment_free(s->cbc, &s->temporal_unit);
+     ff_cbs_close(&s->cbc);
+     return ret;
+ }
+ 
+ static void hevc_frame_split_flush(AVBSFContext *ctx)
+ {
+     int i;
+     HEVCFSplitContext *s = ctx->priv_data;
+ 
+     for (i = 0; i < s->num_tiles; i++) {
+         ni_bitstream_reset(&s->streams[i]);
+     }
+ 
+     av_packet_unref(s->buffer_pkt);
+     ff_cbs_fragment_reset(s->cbc, &s->temporal_unit);
+ }
+ 
+ static void hevc_frame_split_close(AVBSFContext *ctx)
+ {
+     HEVCFSplitContext *s = ctx->priv_data;
+     int i;
+ 
+     for (i = 0; i < s->num_tiles; i++) {
+         ni_bitstream_deinit(&s->streams[i]);
+     }
+ 
+     for (i = 0; i < HEVC_MAX_PPS_COUNT; i++) {
+         if (s->tiles[i]) {
+             if (s->tiles[i]->column_width) {
+                 av_freep(&s->tiles[i]->column_width);
+             }
+             av_freep(&s->tiles[i]);
+         }
+     }
+ 
+     av_freep(&s->streams);
+     av_packet_free(&s->buffer_pkt);
+     ff_cbs_fragment_free(s->cbc, &s->temporal_unit);
+     ff_cbs_close(&s->cbc);
+ }
+ 
+ static const enum AVCodecID hevc_frame_split_codec_ids[] = {
+     AV_CODEC_ID_HEVC, AV_CODEC_ID_NONE,
+ };
+ 
+ const AVBitStreamFilter ff_hevc_frame_split_bsf = {
+     .name           = "hevc_frame_split",
+     .priv_data_size = sizeof(HEVCFSplitContext),
+     .init           = hevc_frame_split_init,
+     .flush          = hevc_frame_split_flush,
+     .close          = hevc_frame_split_close,
+     .filter         = hevc_frame_split_filter,
+     .codec_ids      = hevc_frame_split_codec_ids,
+ };
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/ni_hevc_rawtotile_bsf.c FFmpeg-n4.3.1/libavcodec/ni_hevc_rawtotile_bsf.c
*** base_ffmpeg_n4.3.1/libavcodec/ni_hevc_rawtotile_bsf.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/ni_hevc_rawtotile_bsf.c	2021-09-13 14:19:52.152858778 -0700
***************
*** 0 ****
--- 1,282 ----
+ /*
+  * NetInt HEVC raw-to-tile BSF common source code
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ /**
+  * @file
+  *
+  * This bitstream filter re-encode HEVC NALUs (i.e. VPS, SPS, PPS and slice
+  * header) with tile flags. The slice segment address will be assigned in the
+  * slices or tiles respectively so as to repack them later.
+  */
+ 
+ #include <libavutil/opt.h>
+ #include <libavutil/internal.h>
+ #include <math.h>
+ 
+ #include "avcodec.h"
+ #include "bsf.h"
+ #include "bsf_internal.h"
+ #include "hevc.h"
+ #include "cbs.h"
+ #include "cbs_h265.h"
+ #include "ni_hevc_rbsp.h"
+ 
+ 
+ typedef struct HEVCFtoTileContext {
+     AVPacket *buffer_pkt;
+     CodedBitstreamContext *cbc;
+     CodedBitstreamFragment temporal_unit;
+ 
+     int width;
+     int height;
+     int column; //total tile number in column
+     int row;    //total tile number in row
+     int x;
+     int y;
+ 
+     ni_bitstream_t stream;
+ } HEVCFtoTileContext;
+ 
+ 
+ static int hevc_rawtotile_encode_vps(HEVCFtoTileContext *s, AVBSFContext *ctx, CodedBitstreamUnit *unit)
+ {
+     CodedBitstreamH265Context *priv = s->cbc->priv_data;
+ 
+     ff_ni_write_nal_header(&s->stream, HEVC_NAL_VPS, 0, 1);
+ 
+     return ff_ni_hevc_encode_nal_vps(&s->stream, ctx, priv->active_vps);
+ }
+ 
+ static int hevc_rawtotile_encode_sps(HEVCFtoTileContext *s, AVBSFContext *ctx, CodedBitstreamUnit *unit)
+ {
+     CodedBitstreamH265Context *priv = s->cbc->priv_data;
+ 
+     ff_ni_write_nal_header(&s->stream, HEVC_NAL_SPS, 0, 1);
+ 
+     return ff_ni_hevc_encode_nal_sps(&s->stream, ctx, priv->active_sps, s->width, s->height);
+ }
+ 
+ static int hevc_rawtotile_encode_pps(HEVCFtoTileContext *s, AVBSFContext *ctx, CodedBitstreamUnit *unit)
+ {
+     CodedBitstreamH265Context *priv = s->cbc->priv_data;
+ 
+     ff_ni_write_nal_header(&s->stream, HEVC_NAL_PPS, 0, 1);
+ 
+     return ff_ni_hevc_encode_nal_pps(&s->stream, ctx, priv->active_pps, 2, s->column, s->row);
+ }
+ 
+ //TODO(tyroun): one extra memcpy for slice data, try to eliminate it
+ static int hevc_rawtotile_slice(HEVCFtoTileContext *s, AVBSFContext *ctx, CodedBitstreamUnit *unit)
+ {
+     int i;
+     H265RawSlice *slice = unit->content;
+     CodedBitstreamH265Context *priv = s->cbc->priv_data;
+ 
+     ff_ni_write_nal_header(&s->stream, slice->header.nal_unit_header.nal_unit_type, 0, 1);
+ 
+     ff_ni_hevc_encode_nal_slice_header(&s->stream, ctx,&slice->header, priv->active_sps, priv->active_pps,
+                                        s->width /* width */, s->height /* height  */, 2 /* enable tile */,
+                                        s->x, s->y, 1 /* independent */);
+ 
+     for (i = 0; i < slice->data_size; i++) {
+         ni_put_bits(&s->stream, 8, slice->data[i]);
+     }
+ 
+     return 0;
+ }
+ 
+ static int hevc_rawtotile_filter(AVBSFContext *ctx, AVPacket *out)
+ {
+     HEVCFtoTileContext *s = ctx->priv_data;
+     CodedBitstreamFragment *td = &s->temporal_unit;
+     int i, ret, new_size, nb_slices, unit_offset;
+ 
+     ret = ff_bsf_get_packet_ref(ctx, s->buffer_pkt);
+     if (ret < 0) {
+         // EOF
+         return ret;
+     }
+ 
+     ret = ff_cbs_read_packet(s->cbc, td, s->buffer_pkt);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_WARNING, "Failed to parse temporal unit.\n");
+         goto passthrough;
+     }
+ 
+     nb_slices = 0;
+     unit_offset = 0;
+     for (i = 0; i < td->nb_units; i++) {
+         CodedBitstreamUnit *unit = &td->units[i];
+ 
+         if (unit->type == HEVC_NAL_VPS) {
+             ret = hevc_rawtotile_encode_vps(s, ctx, unit);
+             if (ret < 0) {
+                 av_log(ctx, AV_LOG_ERROR, "failed to re-encode vps\n");
+                 av_assert0(0);
+             }
+         } else if (unit->type == HEVC_NAL_SPS) {
+             ret = hevc_rawtotile_encode_sps(s, ctx, unit);
+             if (ret < 0) {
+                 av_log(ctx, AV_LOG_ERROR, "failed to re-encode sps\n");
+                 av_assert0(0);
+             }
+         } else if (unit->type == HEVC_NAL_PPS) {
+             ret = hevc_rawtotile_encode_pps(s, ctx, unit);
+             if (ret < 0) {
+                 av_log(ctx, AV_LOG_ERROR, "failed to re-encode pps\n");
+                 av_assert0(0);
+             }
+         } else if (unit->type >= HEVC_NAL_TRAIL_N && unit->type <= HEVC_NAL_RSV_VCL31) {
+             if (nb_slices == 0) {
+                 unit_offset = i;
+             }
+             nb_slices++;
+         }
+     }
+ 
+     if (nb_slices == 0) {
+         ret = AVERROR(EAGAIN);
+         goto end;
+     }
+ 
+     for (i = 0; i < nb_slices; i++) {
+         CodedBitstreamUnit *unit = &td->units[i + unit_offset];
+         if ((int) unit->type >= HEVC_NAL_TRAIL_N && unit->type <= HEVC_NAL_RSV_VCL31) {
+             ret = hevc_rawtotile_slice(s, ctx, unit);
+             if (ret < 0) {
+                 av_log(ctx, AV_LOG_ERROR, "failed to re-encode slice header\n");
+                 av_assert0(0);
+             }
+             break;
+         }
+     }
+ 
+     new_size = ni_bitstream_count(&s->stream) / 8;
+     ret = av_new_packet(out, new_size);
+     if (ret < 0) {
+         return ret;
+     }
+ 
+     av_packet_copy_props(out, s->buffer_pkt);
+ 
+     ni_bitstream_fetch(&s->stream, out->data, new_size);
+     ni_bitstream_reset(&s->stream);
+ 
+ end:
+     av_packet_unref(s->buffer_pkt);
+     ff_cbs_fragment_reset(s->cbc, td);
+     return ret;
+ 
+ passthrough:
+     av_packet_move_ref(out, s->buffer_pkt);
+     ff_cbs_fragment_reset(s->cbc, td);
+     return 0;
+ }
+ 
+ static int hevc_rawtotile_init(AVBSFContext *ctx)
+ {
+     HEVCFtoTileContext *s = ctx->priv_data;
+     CodedBitstreamFragment *td = &s->temporal_unit;
+     int ret;
+ 
+     s->buffer_pkt = av_packet_alloc();
+     if (!s->buffer_pkt)
+         return AVERROR(ENOMEM);
+ 
+     ret = ff_cbs_init(&s->cbc, AV_CODEC_ID_HEVC, ctx);
+     if (ret < 0)
+         return ret;
+ 
+     s->cbc->decompose_unit_types    = NULL;
+     s->cbc->nb_decompose_unit_types = 0;
+ 
+ //    s->cbc->decompose_unit_types    = (CodedBitstreamUnitType*)decompose_unit_types;
+ //    s->cbc->nb_decompose_unit_types = FF_ARRAY_ELEMS(decompose_unit_types);
+ 
+     /* extradata is a must */
+ //    if (!ctx->par_in->extradata_size)
+ //        return AVERROR(ENODEV);
+ 
+ //    ret = ff_cbs_read_extradata(s->cbc, td, ctx->par_in);
+ //    if (ret < 0) {
+ //        av_log(ctx, AV_LOG_ERROR, "Failed to parse extradata.\n");
+ //        return ret;
+ //    }
+ 
+     ff_cbs_fragment_reset(s->cbc, td);
+ 
+     ni_bitstream_init(&s->stream);
+ 
+     return 0;
+ }
+ 
+ static void hevc_rawtotile_flush(AVBSFContext *ctx)
+ {
+     HEVCFtoTileContext *s = ctx->priv_data;
+ 
+     ni_bitstream_reset(&s->stream);
+     av_packet_unref(s->buffer_pkt);
+     ff_cbs_fragment_reset(s->cbc, &s->temporal_unit);
+ }
+ 
+ static void hevc_rawtotile_close(AVBSFContext *ctx)
+ {
+     HEVCFtoTileContext *s = ctx->priv_data;
+ 
+     ni_bitstream_deinit(&s->stream);
+     av_packet_free(&s->buffer_pkt);
+     ff_cbs_fragment_free(s->cbc, &s->temporal_unit);
+     ff_cbs_close(&s->cbc);
+ }
+ 
+ static const enum AVCodecID hevc_rawtotile_codec_ids[] = {
+         AV_CODEC_ID_HEVC, AV_CODEC_ID_NONE,
+ };
+ 
+ #define OFFSET(x) offsetof(HEVCFtoTileContext, x)
+ 
+ static const AVOption options[] = {
+         {"width", NULL, OFFSET(width), AV_OPT_TYPE_INT, {.i64 = 1280}, 0, 8192, 0, 0},
+         {"height", NULL, OFFSET(height), AV_OPT_TYPE_INT, {.i64 = 720}, 0, 8192, 0, 0},
+         {"column", NULL, OFFSET(column), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 128, 0, 0},  //support 128 columns max
+         {"row", NULL, OFFSET(row), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 128, 0, 0},  //support 128 rows max
+         {"x", NULL, OFFSET(x), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 8192, 0, 0},  //support 8192 columns max
+         {"y", NULL, OFFSET(y), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 8192, 0, 0},  //support 8192 rows max
+         { NULL },
+ };
+ 
+ static const AVClass hevc_rawtotile_class = {
+         .class_name = "hevc_rawtotile",
+         .item_name  = av_default_item_name,
+         .option     = options,
+         .version    = LIBAVUTIL_VERSION_INT,
+ };
+ 
+ const AVBitStreamFilter ff_hevc_rawtotile_bsf = {
+         .name           = "hevc_rawtotile",
+         .priv_data_size = sizeof(HEVCFtoTileContext),
+         .priv_class     = &hevc_rawtotile_class,
+         .init           = hevc_rawtotile_init,
+         .flush          = hevc_rawtotile_flush,
+         .close          = hevc_rawtotile_close,
+         .filter         = hevc_rawtotile_filter,
+         .codec_ids      = hevc_rawtotile_codec_ids,
+ };
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/ni_hevc_rbsp.c FFmpeg-n4.3.1/libavcodec/ni_hevc_rbsp.c
*** base_ffmpeg_n4.3.1/libavcodec/ni_hevc_rbsp.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/ni_hevc_rbsp.c	2021-09-13 14:19:52.148858760 -0700
***************
*** 0 ****
--- 1,913 ----
+ /*
+  * NetInt HEVC RBSP parser common source code
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ /**
+  * @file
+  *
+  * An RBSP parser according to the HEVC syntax template. Using FFmpeg put_bits
+  * module for the bit write operations.
+  */
+ 
+ #include <stdio.h>
+ #include <stdlib.h>
+ #include <string.h>
+ #include <stdbool.h>
+ 
+ #include "libavcodec/hevc.h"
+ 
+ #include <ni_rsrc_api.h>
+ 
+ #include <libavcodec/cbs_h265.h>
+ #include <libavcodec/avcodec.h>
+ #include <libavcodec/h2645_parse.h>
+ #include <libavcodec/hevc_ps.h>
+ #include <libavcodec/hevc_sei.h>
+ #include <libavcodec/hevcdec.h>
+ 
+ #include "ni_hevc_rbsp.h"
+ 
+ static const uint32_t ni_bit_set_mask[] =
+ {
+     0x00000001,0x00000002,0x00000004,0x00000008,
+     0x00000010,0x00000020,0x00000040,0x00000080,
+     0x00000100,0x00000200,0x00000400,0x00000800,
+     0x00001000,0x00002000,0x00004000,0x00008000,
+     0x00010000,0x00020000,0x00040000,0x00080000,
+     0x00100000,0x00200000,0x00400000,0x00800000,
+     0x01000000,0x02000000,0x04000000,0x08000000,
+     0x10000000,0x20000000,0x40000000,0x80000000
+ };
+ 
+ int ni_bitstream_init(ni_bitstream_t *stream)
+ {
+     memset(stream, 0, sizeof(ni_bitstream_t));
+     stream->pb_buf = av_mallocz(MAX_PUT_BUF_SIZE);
+     if (!stream->pb_buf) {
+         return AVERROR(ENOMEM);
+     }
+     init_put_bits(&stream->pbc, stream->pb_buf, MAX_PUT_BUF_SIZE);
+     return 0;
+ }
+ 
+ void ni_bitstream_deinit(ni_bitstream_t *stream)
+ {
+     av_freep(&stream->pb_buf);
+ }
+ 
+ void ni_bitstream_reset(ni_bitstream_t *stream)
+ {
+     init_put_bits(&stream->pbc, stream->pb_buf, MAX_PUT_BUF_SIZE);
+ }
+ 
+ void ni_bitstream_fetch(const ni_bitstream_t *stream, uint8_t *buf, size_t size)
+ {
+     memcpy(buf, stream->pb_buf, size);
+ }
+ 
+ int ni_bitstream_count(ni_bitstream_t *stream)
+ {
+     return put_bits_count(&stream->pbc);
+ }
+ 
+ /**
+  * \brief Write a byte to a byte aligned bitstream
+  * \param stream  stream the data is to be appended to
+  * \param data  input data
+  */
+ static void ni_put_byte(ni_bitstream_t *stream, uint8_t data)
+ {
+     const uint8_t emulation_prevention_three_byte = 0x03;
+     av_assert0(stream->cur_bits == 0);
+ 
+     if (stream->zero_cnt == 2 && data < 4) {
+         put_bits(&stream->pbc, 8, emulation_prevention_three_byte);
+         stream->zero_cnt = 0;
+     }
+     stream->zero_cnt = data == 0 ? stream->zero_cnt + 1 : 0;
+     put_bits(&stream->pbc, 8, data);
+     flush_put_bits(&stream->pbc);
+ }
+ 
+ /**
+  * \brief Write bits to bitstream
+  *        Buffers individual bits untill they make a full byte.
+  * \param stream  stream the data is to be appended to
+  * \param data  input data
+  * \param bits  number of bits to write from data to stream
+  */
+ void ni_put_bits(ni_bitstream_t *stream, uint8_t bits, const uint32_t data)
+ {
+     while (bits--) {
+         stream->cache <<= 1;
+ 
+         if (data & ni_bit_set_mask[bits]) {
+             stream->cache |= 1;
+         }
+         stream->cur_bits++;
+ 
+         // write byte to output
+         if (stream->cur_bits == 8) {
+             stream->cur_bits = 0;
+             ni_put_byte(stream, stream->cache);
+         }
+     }
+ }
+ 
+ static unsigned ni_math_floor_log2(unsigned value)
+ {
+     unsigned result = 0;
+     av_assert0(value > 0);
+ 
+     for (int i = 4; i >= 0; --i) {
+         unsigned bits = 1ull << i;
+         unsigned shift = value >= (1 << bits) ? bits : 0;
+         result += shift;
+         value >>= shift;
+     }
+ 
+     return result;
+ }
+ 
+ /**
+  * \brief Write unsigned Exp-Golomb bit string
+  */
+ static void ni_set_ue_golomb(ni_bitstream_t *stream, uint32_t code_num)
+ {
+     unsigned code_num_log2 = ni_math_floor_log2(code_num + 1);
+     unsigned prefix = 1 << code_num_log2;
+     unsigned suffix = code_num + 1 - prefix;
+     unsigned num_bits = code_num_log2 * 2 + 1;
+     unsigned value = prefix | suffix;
+ 
+     ni_put_bits(stream, num_bits, value);
+ }
+ 
+ /**
+  * \brief Write signed Exp-Golomb bit string
+  */
+ static void ni_set_se_golomb(ni_bitstream_t *stream, int32_t data)
+ {
+     // Map positive values to even and negative to odd values.
+     uint32_t code_num = data <= 0 ? (-data) << 1 : (data << 1) - 1;
+     ni_set_ue_golomb(stream, code_num);
+ }
+ 
+ /**
+  * \brief Add rbsp_trailing_bits syntax element, which aligns the bitstream.
+  */
+ static void ni_rbsp_trailing_bits(ni_bitstream_t *stream)
+ {
+     ni_put_bits(stream, 1, 1);
+     if ((stream->cur_bits & 7) != 0) {
+         ni_put_bits(stream, 8 - (stream->cur_bits & 7), 0);
+     }
+ }
+ 
+ /**
+  * \brief Add rbsp_trailing_bits syntax element, which aligns the bitstream.
+  */
+ void ff_ni_write_nal_header(ni_bitstream_t *bitstream, const uint8_t nal_type,
+                             const uint8_t temporal_id, const int long_start_code)
+ {
+     uint8_t byte;
+ 
+     // Some useful constants
+     const uint8_t start_code_prefix_one_3bytes = 0x01;
+     const uint8_t zero = 0x00;
+ 
+     // zero_byte (0x00) shall be present in the byte stream NALU of VPS, SPS
+     // and PPS, or the first NALU of an access unit
+     if (long_start_code) {
+         put_bits(&bitstream->pbc, 8, zero);
+      }
+ 
+     // start_code_prefix_one_3bytes
+     put_bits(&bitstream->pbc, 8, zero);
+     put_bits(&bitstream->pbc, 8, zero);
+     ni_put_bits(bitstream, 8, start_code_prefix_one_3bytes);
+ 
+     // Handle header bits with full bytes instead of using bitstream
+     // forbidden_zero_flag(1) + nal_unit_type(6) + 1bit of nuh_layer_id
+     byte = nal_type << 1;
+     ni_put_bits(bitstream, 8, byte);
+ 
+     // 5bits of nuh_layer_id + nuh_temporal_id_plus1(3)
+     byte = (temporal_id + 1) & 7;
+     ni_put_bits(bitstream, 8, byte);
+ }
+ 
+ static void write_raw_ptl(ni_bitstream_t *pb, const H265RawProfileTierLevel *ptl, int max_sub_layers_minus1)
+ {
+     int i;
+ 
+     ni_put_bits(pb, 2, ptl->general_profile_space);
+     ni_put_bits(pb, 1, ptl->general_tier_flag);
+     ni_put_bits(pb, 5, ptl->general_profile_idc);
+ 
+     // ni_put_bits(pb, 32, 3 << 29); only general_profile_compatibility_flag [1] and [2]
+     for (i = 0; i < 32; i++) {
+         ni_put_bits(pb, 1, ptl->general_profile_compatibility_flag[i]);
+     }
+ 
+     ni_put_bits(pb, 1, ptl->general_progressive_source_flag);//general_progressive_source_flag
+     ni_put_bits(pb, 1, ptl->general_interlaced_source_flag);//general_interlaced_source_flag
+     ni_put_bits(pb, 1, ptl->general_non_packed_constraint_flag);//general_non_packed_constraint_flag
+     ni_put_bits(pb, 1, ptl->general_frame_only_constraint_flag);//general_frame_only_constraint_flag
+ 
+     av_assert0(!ptl->general_one_picture_only_constraint_flag);
+     av_assert0(!ptl->general_inbld_flag);
+     ni_put_bits(pb, 7, 0);
+     ni_put_bits(pb, 1, ptl->general_one_picture_only_constraint_flag);
+     ni_put_bits(pb, 24, 0);
+     ni_put_bits(pb, 11, 0);
+     ni_put_bits(pb, 1, ptl->general_inbld_flag);
+ 
+     // end Profile Tier
+ 
+     ni_put_bits(pb, 8, ptl->general_level_idc);//general_level_idc
+ 
+     if (max_sub_layers_minus1 > 1) {
+         printf("not support sub layers yet\n");//TODO(tyroun) sub layers support
+         av_assert0(0);
+         return;
+     }
+ 
+     for (i = 0; i < max_sub_layers_minus1; i++) {
+         av_assert0(!ptl->sub_layer_profile_present_flag[i]);
+         av_assert0(!ptl->sub_layer_level_present_flag[i]);
+         ni_put_bits(pb, 1, ptl->sub_layer_profile_present_flag[i]);
+         ni_put_bits(pb, 1, ptl->sub_layer_level_present_flag[i]);
+     }
+ 
+     if (max_sub_layers_minus1 > 0) {
+         for (i = max_sub_layers_minus1; i < 8; i++) {
+             ni_put_bits(pb, 2, 0); //reserved_zero_2bits
+         }
+     }
+ }
+ 
+ int ff_ni_hevc_encode_nal_vps(ni_bitstream_t *pb, void *ctx, const H265RawVPS *vps)
+ {
+     int i;
+ 
+     ni_put_bits(pb,  4, vps->vps_video_parameter_set_id);
+     ni_put_bits(pb,  2, 3);
+     ni_put_bits(pb,  6, vps->vps_max_layers_minus1);
+     ni_put_bits(pb,  3, vps->vps_max_sub_layers_minus1);
+     ni_put_bits(pb,  1, vps->vps_temporal_id_nesting_flag);
+     ni_put_bits(pb, 16, 0xffff);
+ 
+     write_raw_ptl(pb, &vps->profile_tier_level, vps->vps_max_sub_layers_minus1);
+ 
+     ni_put_bits(pb, 1, vps->vps_sub_layer_ordering_info_present_flag);
+     for (i = vps->vps_sub_layer_ordering_info_present_flag ? 0 : vps->vps_max_sub_layers_minus1;
+          i <= vps->vps_max_sub_layers_minus1; i++) {
+         ni_set_ue_golomb(pb, vps->vps_max_dec_pic_buffering_minus1[i]);
+         ni_set_ue_golomb(pb, vps->vps_max_num_reorder_pics[i]);
+         ni_set_ue_golomb(pb, vps->vps_max_latency_increase_plus1[i]);
+     }
+ 
+     ni_put_bits(pb, 6, vps->vps_max_layer_id);
+     ni_set_ue_golomb(pb, vps->vps_num_layer_sets_minus1);
+ 
+     if (vps->vps_num_layer_sets_minus1 > 0) {
+         avpriv_report_missing_feature(NULL, "Writing layer_id_included_flag");
+         return AVERROR_PATCHWELCOME;
+     }
+ 
+     ni_put_bits(pb, 1, vps->vps_timing_info_present_flag);
+     if (vps->vps_timing_info_present_flag) {
+         ni_put_bits(pb, 32, vps->vps_num_units_in_tick);
+         ni_put_bits(pb, 32, vps->vps_time_scale);
+         ni_put_bits(pb, 1, vps->vps_poc_proportional_to_timing_flag);
+         if (vps->vps_poc_proportional_to_timing_flag)
+             ni_set_ue_golomb(pb, vps->vps_num_ticks_poc_diff_one_minus1);
+ 
+         ni_set_ue_golomb(pb, vps->vps_num_hrd_parameters);
+         if (vps->vps_num_hrd_parameters) {
+             avpriv_report_missing_feature(NULL, "Writing HRD parameters");
+             return AVERROR_PATCHWELCOME;
+         }
+     }
+ 
+     ni_put_bits(pb, 1, 0);    // extension flag
+ 
+     ni_rbsp_trailing_bits(pb);
+ 
+     return 0;
+ }
+ 
+ static void write_raw_scaling_list(ni_bitstream_t *pb, const H265RawScalingList *sl)
+ {
+     unsigned int size_id, matrix_id;
+     int i, coef_num;
+ 
+     for (size_id = 0; size_id < 4; size_id++) {
+         for (matrix_id = 0; matrix_id < 6; matrix_id += ((size_id == 3) ? 3 : 1)) {
+             ni_put_bits(pb, 1, sl->scaling_list_pred_mode_flag[size_id][matrix_id]);
+ 
+             if (!sl->scaling_list_pred_mode_flag[size_id][matrix_id]) {
+                 ni_set_ue_golomb(pb, sl->scaling_list_pred_matrix_id_delta[size_id][matrix_id]);
+             } else {
+                 coef_num = FFMIN(64, 1 << (4 + (size_id << 1)));
+                 if (size_id > 1) {
+                     ni_set_se_golomb(pb, sl->scaling_list_dc_coef_minus8[size_id][matrix_id]);
+                 }
+                 for (i = 0; i < coef_num; i++) {
+                     ni_set_se_golomb(pb, sl->scaling_list_delta_coeff[size_id][matrix_id][i]);
+                 }
+             }
+         }
+     }
+ }
+ 
+ static void write_raw_VUI(ni_bitstream_t *pb, const H265RawSPS *sps)
+ {
+     const H265RawVUI *vui = &sps->vui;
+ 
+     if (vui->aspect_ratio_info_present_flag) {
+         ni_put_bits(pb, 1, vui->aspect_ratio_info_present_flag);
+         ni_put_bits(pb, 8, vui->aspect_ratio_idc);
+         if (vui->aspect_ratio_idc == 255) {
+             ni_put_bits(pb, 16, vui->sar_width);
+             ni_put_bits(pb, 16, vui->sar_height);
+         }
+     } else
+         ni_put_bits(pb, 1, vui->aspect_ratio_info_present_flag);
+ 
+     //IF aspect ratio info
+     //ENDIF
+ 
+     if (vui->overscan_info_present_flag) {
+         ni_put_bits(pb, 1, vui->overscan_info_present_flag);
+         ni_put_bits(pb, 1, vui->overscan_appropriate_flag);
+     } else
+         ni_put_bits(pb, 1, vui->overscan_info_present_flag);
+ 
+     //IF overscan info
+     //ENDIF
+ 
+     if (vui->video_signal_type_present_flag) {
+         ni_put_bits(pb, 1, vui->video_signal_type_present_flag);
+         ni_put_bits(pb, 3, vui->video_format);
+         ni_put_bits(pb, 1, vui->video_full_range_flag);
+ 
+         if (vui->colour_description_present_flag) {
+             ni_put_bits(pb, 1, vui->colour_description_present_flag);
+             ni_put_bits(pb, 8, vui->colour_primaries);
+             ni_put_bits(pb, 8, vui->transfer_characteristics);
+             ni_put_bits(pb, 8, vui->matrix_coefficients);
+         } else
+             ni_put_bits(pb, 1, vui->colour_description_present_flag);
+     } else
+         ni_put_bits(pb, 1, vui->video_signal_type_present_flag);
+ 
+     //IF video type
+     //ENDIF
+ 
+     if (vui->chroma_loc_info_present_flag) {
+         ni_put_bits(pb, 1, vui->chroma_loc_info_present_flag);
+         ni_set_ue_golomb(pb, vui->chroma_sample_loc_type_top_field);
+         ni_set_ue_golomb(pb, vui->chroma_sample_loc_type_bottom_field);
+     } else
+         ni_put_bits(pb, 1, vui->chroma_loc_info_present_flag);
+ 
+     //IF chroma loc info
+     //ENDIF
+ 
+     ni_put_bits(pb, 1, vui->neutral_chroma_indication_flag);
+     ni_put_bits(pb, 1, vui->field_seq_flag); // 0: frames, 1: fields
+     ni_put_bits(pb, 1, vui->frame_field_info_present_flag);
+     ni_put_bits(pb, 1, vui->default_display_window_flag);
+ 
+     //IF default display window
+     //ENDIF
+ 
+     ni_put_bits(pb, 1, vui->vui_timing_info_present_flag);
+     if (vui->vui_timing_info_present_flag) {
+         ni_put_bits(pb, 32, vui->vui_num_units_in_tick);
+         ni_put_bits(pb, 32, vui->vui_time_scale);
+ 
+         ni_put_bits(pb, 1, vui->vui_poc_proportional_to_timing_flag);
+         ni_put_bits(pb, 1, vui->vui_hrd_parameters_present_flag);
+     }
+ 
+     ni_put_bits(pb, 1, vui->bitstream_restriction_flag);
+ 
+     //IF bitstream restriction
+     //ENDIF
+ }
+ 
+ static void short_term_ref_pic_set(ni_bitstream_t *pb, const H265RawSTRefPicSet *p_st_rps,
+                                    int st_rps_idx, const H265RawSPS *sps)
+ {
+     int i, ref_rps_idx, num_delta_pocs;
+     const H265RawSTRefPicSet *ref;
+ 
+     if (st_rps_idx > 0) {
+         ni_put_bits(pb, 1, p_st_rps->inter_ref_pic_set_prediction_flag);
+     }
+ 
+     if (p_st_rps->inter_ref_pic_set_prediction_flag) {
+         if (st_rps_idx == sps->num_short_term_ref_pic_sets) {
+             ni_set_ue_golomb(pb, p_st_rps->delta_idx_minus1);
+         }
+ 
+         ref_rps_idx = st_rps_idx - (p_st_rps->delta_idx_minus1 + 1);
+         ref = &sps->st_ref_pic_set[ref_rps_idx];
+         num_delta_pocs = ref->num_negative_pics + ref->num_positive_pics;
+ 
+         ni_put_bits(pb, 1, p_st_rps->delta_rps_sign);
+         ni_set_ue_golomb(pb, p_st_rps->abs_delta_rps_minus1);
+ 
+         for (i = 0; i <= num_delta_pocs; i++) {
+             ni_put_bits(pb, 1, p_st_rps->used_by_curr_pic_flag[i]);
+             if (!p_st_rps->used_by_curr_pic_flag[i]) {
+                 ni_put_bits(pb, 1, p_st_rps->use_delta_flag[i]);
+             }
+         }
+     } else {
+         ni_set_ue_golomb(pb, p_st_rps->num_negative_pics);
+         ni_set_ue_golomb(pb, p_st_rps->num_positive_pics);
+ 
+         for (i = 0; i < p_st_rps->num_negative_pics; i++) {
+             ni_set_ue_golomb(pb, p_st_rps->delta_poc_s0_minus1[i]);
+             ni_put_bits(pb, 1, p_st_rps->used_by_curr_pic_s0_flag[i]);
+         }
+ 
+         for (i = 0; i < p_st_rps->num_positive_pics; i++) {
+             ni_set_ue_golomb(pb, p_st_rps->delta_poc_s1_minus1[i]);
+             ni_put_bits(pb, 1, p_st_rps->used_by_curr_pic_s1_flag[i]);
+         }
+     }
+ }
+ 
+ static void write_raw_SPS_extension(ni_bitstream_t *pb, const H265RawSPS *sps)
+ {
+     if (sps->sps_extension_present_flag) {
+         ni_put_bits(pb, 1, sps->sps_extension_present_flag);
+ 
+         ni_put_bits(pb, 1, sps->sps_range_extension_flag);
+         ni_put_bits(pb, 1, sps->sps_multilayer_extension_flag);
+         ni_put_bits(pb, 1, sps->sps_3d_extension_flag);
+         ni_put_bits(pb, 1, sps->sps_scc_extension_flag);
+         ni_put_bits(pb, 4, sps->sps_extension_4bits);
+ 
+         ni_put_bits(pb, 1, sps->transform_skip_rotation_enabled_flag);
+         ni_put_bits(pb, 1, sps->transform_skip_context_enabled_flag);
+         ni_put_bits(pb, 1, sps->implicit_rdpcm_enabled_flag);
+         ni_put_bits(pb, 1, sps->explicit_rdpcm_enabled_flag);
+         ni_put_bits(pb, 1, sps->extended_precision_processing_flag);
+         ni_put_bits(pb, 1, sps->intra_smoothing_disabled_flag);
+         ni_put_bits(pb, 1, sps->high_precision_offsets_enabled_flag);
+         ni_put_bits(pb, 1, sps->persistent_rice_adaptation_enabled_flag);
+         ni_put_bits(pb, 1, sps->cabac_bypass_alignment_enabled_flag);
+     } else {
+         ni_put_bits(pb, 1, sps->sps_extension_present_flag);
+     }
+ }
+ 
+ int ff_ni_hevc_encode_nal_sps(ni_bitstream_t *pb, void *ctx,
+                               const H265RawSPS *sps, int width, int height)
+ {
+     int i, start;
+ 
+     if (!sps) {
+         return AVERROR(EINVAL);
+     }
+ 
+     // TODO: profile IDC and level IDC should be defined later on
+     ni_put_bits(pb, 4, sps->sps_video_parameter_set_id);
+     ni_put_bits(pb, 3, sps->sps_max_sub_layers_minus1);
+     ni_put_bits(pb, 1, sps->sps_temporal_id_nesting_flag);
+ 
+     write_raw_ptl(pb, &sps->profile_tier_level, sps->sps_max_sub_layers_minus1);
+ 
+     ni_set_ue_golomb(pb, sps->sps_seq_parameter_set_id);
+     ni_set_ue_golomb(pb, sps->chroma_format_idc);
+ 
+     if (sps->chroma_format_idc == 3) {
+         ni_put_bits(pb, 1, sps->separate_colour_plane_flag);
+     }
+ 
+     ni_set_ue_golomb(pb, width);
+     ni_set_ue_golomb(pb, height);
+ 
+     ni_put_bits(pb, 1, sps->conformance_window_flag);
+     if (sps->conformance_window_flag) {
+         ni_set_ue_golomb(pb, sps->conf_win_left_offset);
+         ni_set_ue_golomb(pb, sps->conf_win_right_offset);
+         ni_set_ue_golomb(pb, sps->conf_win_top_offset);
+         ni_set_ue_golomb(pb, sps->conf_win_bottom_offset);
+     }
+ 
+     ni_set_ue_golomb(pb, sps->bit_depth_luma_minus8);
+     ni_set_ue_golomb(pb, sps->bit_depth_chroma_minus8);
+     ni_set_ue_golomb(pb, sps->log2_max_pic_order_cnt_lsb_minus4);
+ 
+     ni_put_bits(pb, 1, sps->sps_sub_layer_ordering_info_present_flag);
+ 
+     //for each layer
+     start = sps->sps_sub_layer_ordering_info_present_flag ? 0 : sps->sps_max_sub_layers_minus1;
+     for (i = start; i < sps->sps_max_sub_layers_minus1 + 1; i++) {
+         ni_set_ue_golomb(pb, sps->sps_max_dec_pic_buffering_minus1[i]);
+         ni_set_ue_golomb(pb, sps->sps_max_num_reorder_pics[i]);
+         ni_set_ue_golomb(pb, sps->sps_max_latency_increase_plus1[i]);
+     }
+     //end for
+ 
+     ni_set_ue_golomb(pb, sps->log2_min_luma_coding_block_size_minus3);
+     ni_set_ue_golomb(pb, sps->log2_diff_max_min_luma_coding_block_size);
+     ni_set_ue_golomb(pb, sps->log2_min_luma_transform_block_size_minus2);
+     ni_set_ue_golomb(pb, sps->log2_diff_max_min_luma_transform_block_size);
+     ni_set_ue_golomb(pb, sps->max_transform_hierarchy_depth_inter);
+     ni_set_ue_golomb(pb, sps->max_transform_hierarchy_depth_intra);
+ 
+     // scaling list
+     ni_put_bits(pb, 1, sps->scaling_list_enabled_flag);
+     if (sps->scaling_list_enabled_flag) {
+         // Signal scaling list data for custom lists
+         ni_put_bits(pb, 1, sps->sps_scaling_list_data_present_flag);
+         if (sps->sps_scaling_list_data_present_flag) {
+             write_raw_scaling_list(pb, &sps->scaling_list);
+         }
+     }
+ 
+     ni_put_bits(pb, 1, sps->amp_enabled_flag);
+     ni_put_bits(pb, 1, sps->sample_adaptive_offset_enabled_flag);
+     ni_put_bits(pb, 1, sps->pcm_enabled_flag);
+     if (sps->pcm_enabled_flag) {
+         ni_put_bits(pb, 4, sps->pcm_sample_bit_depth_luma_minus1);
+         ni_put_bits(pb, 4, sps->pcm_sample_bit_depth_chroma_minus1);
+         ni_set_ue_golomb(pb, sps->log2_min_pcm_luma_coding_block_size_minus3);
+         ni_set_ue_golomb(pb, sps->log2_diff_max_min_pcm_luma_coding_block_size);
+         ni_put_bits(pb, 1, sps->pcm_loop_filter_disabled_flag);
+     }
+ 
+     ni_set_ue_golomb(pb, sps->num_short_term_ref_pic_sets);
+     for (i = 0; i < sps->num_short_term_ref_pic_sets; i++) {
+         short_term_ref_pic_set(pb, &sps->st_ref_pic_set[i], i, sps);
+     }
+ 
+     //IF num short term ref pic sets
+     //ENDIF
+ 
+     av_assert0(!sps->long_term_ref_pics_present_flag);
+     ni_put_bits(pb, 1, sps->long_term_ref_pics_present_flag); //long_term_ref_pics_present_flag TODO(tyroun): netint not encode long term ref yet
+ 
+     //IF long_term_ref_pics_present
+     //ENDIF
+ 
+     ni_put_bits(pb, 1, sps->sps_temporal_mvp_enabled_flag);
+     ni_put_bits(pb, 1, sps->strong_intra_smoothing_enabled_flag);
+     ni_put_bits(pb, 1, sps->vui_parameters_present_flag);
+ 
+     if (sps->vui_parameters_present_flag) {
+         write_raw_VUI(pb, sps);
+     }
+ 
+     write_raw_SPS_extension(pb, sps);
+ 
+     ni_rbsp_trailing_bits(pb);
+ 
+     return 0;
+ }
+ 
+ /*
+  * force_tile: 0 for ignoring this flag. 1 for disabling tile. 2 for enabling tile.
+  * */
+ int ff_ni_hevc_encode_nal_pps(ni_bitstream_t *pb, void *ctx, const H265RawPPS *pps,
+                               uint8_t force_tile, int columns, int rows)
+ {
+     int i;
+ 
+     if (!pps || force_tile > 2) {
+         return AVERROR(EINVAL);
+     }
+ 
+     ni_set_ue_golomb(pb, pps->pps_pic_parameter_set_id);
+     ni_set_ue_golomb(pb, pps->pps_seq_parameter_set_id);
+     ni_put_bits(pb, 1, 0); /* dependent_slice_segments_enabled_flag */
+     ni_put_bits(pb, 1, pps->output_flag_present_flag);
+     ni_put_bits(pb, 3, pps->num_extra_slice_header_bits);
+     ni_put_bits(pb, 1, pps->sign_data_hiding_enabled_flag);
+     if (pps->cabac_init_present_flag) {
+         av_log(ctx, AV_LOG_ERROR, "not support cabac init in stream\n");
+         return AVERROR(EINVAL);
+     }
+     ni_put_bits(pb, 1, pps->cabac_init_present_flag);
+ 
+     ni_set_ue_golomb(pb, pps->num_ref_idx_l0_default_active_minus1);
+     ni_set_ue_golomb(pb, pps->num_ref_idx_l1_default_active_minus1);
+ 
+     // If tiles and slices = tiles is enabled, signal QP in the slice header. Keeping the PPS constant for OMAF etc
+     // Keep QP constant here also if it will be only set at CU level.
+     ni_set_se_golomb(pb, pps->init_qp_minus26);
+ 
+     ni_put_bits(pb, 1, pps->constrained_intra_pred_flag);
+     ni_put_bits(pb, 1, pps->transform_skip_enabled_flag);
+     ni_put_bits(pb, 1, pps->cu_qp_delta_enabled_flag);
+ 
+     if (pps->cu_qp_delta_enabled_flag) {
+         // Use separate QP for each LCU when rate control is enabled.
+         ni_set_ue_golomb(pb, pps->diff_cu_qp_delta_depth);
+     }
+ 
+     ni_set_se_golomb(pb, pps->pps_cb_qp_offset);
+     ni_set_se_golomb(pb, pps->pps_cr_qp_offset);
+     ni_put_bits(pb, 1, pps->pps_slice_chroma_qp_offsets_present_flag);
+     ni_put_bits(pb, 1, pps->weighted_pred_flag);
+     ni_put_bits(pb, 1, pps->weighted_bipred_flag);
+     ni_put_bits(pb, 1, pps->transquant_bypass_enabled_flag);
+     ni_put_bits(pb, 1, !!((force_tile == 2) || (!force_tile && pps->tiles_enabled_flag)));
+     //wavefronts
+     ni_put_bits(pb, 1, pps->entropy_coding_sync_enabled_flag);
+ 
+     if (force_tile) {
+         if (force_tile == 2) {
+             ni_set_ue_golomb(pb, columns - 1);
+             ni_set_ue_golomb(pb, rows - 1);
+ 
+             ni_put_bits(pb, 1, 1); // uniform_spacing_flag must be 1
+             ni_put_bits(pb, 1, pps->loop_filter_across_tiles_enabled_flag);//loop_filter_across_tiles_enabled_flag must be 0
+         }
+     } else if (pps->tiles_enabled_flag) {
+         ni_set_ue_golomb(pb, columns - 1);
+         ni_set_ue_golomb(pb, rows - 1);
+ 
+         ni_put_bits(pb, 1, pps->uniform_spacing_flag);
+ 
+         if (!pps->uniform_spacing_flag) {
+             for (i = 0; i < pps->num_tile_columns_minus1; ++i) {
+                 ni_set_ue_golomb(pb, pps->column_width_minus1[i]);
+             }
+             for (i = 0; i < pps->num_tile_rows_minus1; ++i) {
+                 ni_set_ue_golomb(pb, pps->row_height_minus1[i]);
+             }
+         }
+         ni_put_bits(pb, 1, pps->loop_filter_across_tiles_enabled_flag);
+     }
+ 
+     ni_put_bits(pb, 1, pps->pps_loop_filter_across_slices_enabled_flag);
+     ni_put_bits(pb, 1, pps->deblocking_filter_control_present_flag);
+ 
+     if (pps->deblocking_filter_control_present_flag) {
+         ni_put_bits(pb, 1, pps->deblocking_filter_override_enabled_flag);
+         ni_put_bits(pb, 1, pps->pps_deblocking_filter_disabled_flag);
+         if (!pps->pps_deblocking_filter_disabled_flag) {
+             ni_set_se_golomb(pb, pps->pps_beta_offset_div2);
+             ni_set_se_golomb(pb, pps->pps_tc_offset_div2);
+         }
+     }
+ 
+     ni_put_bits(pb, 1, pps->pps_scaling_list_data_present_flag);
+     if (pps->pps_scaling_list_data_present_flag) {
+         av_log(ctx, AV_LOG_ERROR, "not support pps_scaling_list_data_present_flag =1 \n");
+         av_assert0(0);
+         return AVERROR(EINVAL);
+     }
+ 
+     ni_put_bits(pb, 1, pps->lists_modification_present_flag);
+     ni_set_ue_golomb(pb, pps->log2_parallel_merge_level_minus2);
+     ni_put_bits(pb, 1, pps->slice_segment_header_extension_present_flag);
+     ni_put_bits(pb, 1, pps->pps_extension_present_flag);
+ 
+     ni_rbsp_trailing_bits(pb);
+ 
+     return 0;
+ }
+ 
+ static void write_raw_slice_header_independent(ni_bitstream_t *pb, H265RawSliceHeader *slice,
+                                                const H265RawSPS *sps, const H265RawPPS *pps)
+ {
+     const H265RawSTRefPicSet *rps;
+     int i, idx_size, entry_size, num_pic_total_curr;
+ 
+     for (i = 0; i < pps->num_extra_slice_header_bits; i++) {
+         ni_put_bits(pb, 1, 0); //slice_reserved_undetermined_flag
+     }
+     ni_set_ue_golomb(pb, slice->slice_type);
+ 
+     av_assert0(!pps->output_flag_present_flag);
+     av_assert0(!sps->separate_colour_plane_flag);
+ 
+     if (slice->nal_unit_header.nal_unit_type != HEVC_NAL_IDR_W_RADL &&
+         slice->nal_unit_header.nal_unit_type != HEVC_NAL_IDR_N_LP) {
+         ni_put_bits(pb, sps->log2_max_pic_order_cnt_lsb_minus4 + 4, slice->slice_pic_order_cnt_lsb);
+ 
+         ni_put_bits(pb, 1, slice->short_term_ref_pic_set_sps_flag);
+         if (!slice->short_term_ref_pic_set_sps_flag) {
+             rps = &slice->short_term_ref_pic_set;
+             short_term_ref_pic_set(pb, rps, sps->num_short_term_ref_pic_sets, sps);
+         } else if (slice->short_term_ref_pic_set_sps_flag && sps->num_short_term_ref_pic_sets > 1) {
+             idx_size = av_log2(sps->num_short_term_ref_pic_sets - 1) + 1;
+             ni_put_bits(pb, idx_size, slice->short_term_ref_pic_set_idx);
+             rps =  &sps->st_ref_pic_set[slice->short_term_ref_pic_set_idx];
+         } else {
+             rps = &sps->st_ref_pic_set[0];
+         }
+ 
+         num_pic_total_curr = 0;
+         for (i = 0; i < rps->num_negative_pics; i++)
+             if (rps->used_by_curr_pic_s0_flag[i])
+                 ++num_pic_total_curr;
+ 
+         for (i = 0; i < rps->num_positive_pics; i++)
+             if (rps->used_by_curr_pic_s1_flag[i])
+                 ++num_pic_total_curr;
+ 
+         if (sps->sps_temporal_mvp_enabled_flag) {
+             ni_put_bits(pb, 1, slice->slice_temporal_mvp_enabled_flag);
+         }
+ 
+         if (pps->pps_curr_pic_ref_enabled_flag) {
+             ++num_pic_total_curr;
+         }
+     }
+ 
+     if (sps->sample_adaptive_offset_enabled_flag) {
+         ni_put_bits(pb, 1, slice->slice_sao_luma_flag);
+         if (!sps->separate_colour_plane_flag && sps->chroma_format_idc > 0) {
+             ni_put_bits(pb, 1, slice->slice_sao_chroma_flag);
+         }
+     }
+ 
+     if (slice->slice_type == HEVC_SLICE_P || slice->slice_type == HEVC_SLICE_B) {
+         ni_put_bits(pb, 1, slice->num_ref_idx_active_override_flag);
+         if (slice->num_ref_idx_active_override_flag) {
+             ni_set_ue_golomb(pb, slice->num_ref_idx_l0_active_minus1);
+             if (slice->slice_type == HEVC_SLICE_B) {
+                 ni_set_ue_golomb(pb, slice->num_ref_idx_l1_active_minus1);
+             }
+         }
+ 
+         if (pps->lists_modification_present_flag && num_pic_total_curr > 1) {
+             entry_size = av_log2(num_pic_total_curr - 1) + 1;
+ 
+             // For h265_ni_enc the ref_pic_list_modification_flag_l0 is always 0
+             // that does not match the standard. So we have to use
+             // slice->slice_type == HEVC_SLICE_P expression as that flag.
+             ni_put_bits(pb, 1, slice->slice_type == HEVC_SLICE_P);//slice->ref_pic_list_modification_flag_l0);
+ #if 0
+             // This dead code due to ref_pic_list_modification_flag_l0 is
+             // always 0 and for decoder we must not run the following code.
+             if (slice->ref_pic_list_modification_flag_l0) {
+                 for (i = 0; i <= slice->num_ref_idx_l0_active_minus1; i++) {
+                     ni_put_bits(pb, entry_size, slice->list_entry_l0[i]);
+                 }
+             }
+ #endif
+ 
+             if (slice->slice_type == HEVC_SLICE_B) {
+                 ni_put_bits(pb, 1, slice->ref_pic_list_modification_flag_l1);
+                 if (slice->ref_pic_list_modification_flag_l1) {
+                     for (i = 0; i <= slice->num_ref_idx_l1_active_minus1; i++) {
+                         ni_put_bits(pb, entry_size, slice->list_entry_l1[i]);
+                     }
+                 }
+             }
+         }
+ 
+         if (slice->slice_type == HEVC_SLICE_B) {
+             av_assert0(!slice->mvd_l1_zero_flag);
+             ni_put_bits(pb, 1, slice->mvd_l1_zero_flag);
+         }
+ 
+         av_assert0(!pps->cabac_init_present_flag);
+ 
+         // Temporal Motion Vector Prediction flags
+         if (slice->slice_temporal_mvp_enabled_flag) {
+             int nb_refs;
+             if (slice->slice_type == HEVC_SLICE_B) {
+                 // Always use L0 for prediction
+                 ni_put_bits(pb, 1, slice->collocated_from_l0_flag);
+             }
+ 
+             nb_refs = slice->collocated_from_l0_flag ?
+                     (slice->num_ref_idx_l0_active_minus1 + 1) :
+                     (slice->num_ref_idx_l1_active_minus1 + 1);
+             if (nb_refs > 1) {
+                 // Use first reference from L0
+                 // ToDo: use better reference
+                 av_assert0(slice->collocated_ref_idx == 0);
+                 ni_set_ue_golomb(pb, nb_refs);
+             }
+         }
+ 
+         av_assert0(!pps->weighted_pred_flag);
+         av_assert0(!pps->weighted_bipred_flag);
+ 
+         ni_set_ue_golomb(pb, slice->five_minus_max_num_merge_cand);
+ 
+         if (sps->motion_vector_resolution_control_idc == 2) {
+             ni_put_bits(pb, 1, slice->use_integer_mv_flag);
+         }
+     }
+ 
+     ni_set_se_golomb(pb, slice->slice_qp_delta);
+ 
+     av_assert0(!pps->pps_slice_chroma_qp_offsets_present_flag);
+     av_assert0(!pps->pps_slice_act_qp_offsets_present_flag);
+     av_assert0(!pps->chroma_qp_offset_list_enabled_flag);
+     av_assert0(!pps->deblocking_filter_override_enabled_flag);
+     av_assert0(!slice->deblocking_filter_override_flag);
+ 
+     if (pps->pps_loop_filter_across_slices_enabled_flag &&
+             (slice->slice_sao_chroma_flag || slice->slice_sao_luma_flag ||
+             !slice->slice_deblocking_filter_disabled_flag)) {
+         av_assert0(slice->slice_loop_filter_across_slices_enabled_flag);
+         ni_put_bits(pb, 1, slice->slice_loop_filter_across_slices_enabled_flag);
+     }
+ }
+ 
+ /*
+  * force_tile: 0 for ignoring this flag. 1 for disabling tile. 2 for enabling tile.
+  * */
+ int ff_ni_hevc_encode_nal_slice_header(ni_bitstream_t *pb, void *ctx, H265RawSliceHeader *slice,
+                                        const H265RawSPS *sps, const H265RawPPS *pps,
+                                        int width, int height, uint8_t force_tile,
+                                        int x, int y, int independent)
+ {
+     int i;
+     int first_slice_segment_in_pic;
+     int slice_segment_addr, len;
+     int MinCbLog2SizeY;
+     int CtbLog2SizeY;
+     int CtbSizeY;
+     int PicWidthInCtbsY;
+     int PicHeightInCtbsY;
+     int PicSizeInCtbsY;
+ 
+     if (!pps || !slice || force_tile > 2) {
+         return AVERROR(EINVAL);
+     }
+ 
+     first_slice_segment_in_pic = (x == 0 && y == 0) ? 1 : 0;
+     ni_put_bits(pb, 1, first_slice_segment_in_pic);
+ 
+     if (slice->nal_unit_header.nal_unit_type >= 16 &&
+         slice->nal_unit_header.nal_unit_type <= 23) {
+         av_assert0(!slice->no_output_of_prior_pics_flag);
+         ni_put_bits(pb, 1, slice->no_output_of_prior_pics_flag);
+     }
+ 
+     ni_set_ue_golomb(pb, slice->slice_pic_parameter_set_id);
+ 
+     if (!first_slice_segment_in_pic) {
+         MinCbLog2SizeY = sps->log2_min_luma_coding_block_size_minus3 + 3;
+         CtbLog2SizeY = MinCbLog2SizeY + sps->log2_diff_max_min_luma_coding_block_size;
+     //    int MinCbSizeY = 1 << MinCbLog2SizeY;
+         CtbSizeY = 1 << CtbLog2SizeY;
+     //    int PicWidthInMinCbsY = width / MinCbSizeY;
+         PicWidthInCtbsY = (width + CtbSizeY - 1) / CtbSizeY;
+     //    int PicHeightInMinCbsY = height / MinCbSizeY;
+         PicHeightInCtbsY = (height + CtbSizeY - 1) / CtbSizeY;
+     //    int PicSizeInMinCbsY = PicWidthInMinCbsY * PicHeightInMinCbsY;
+         PicSizeInCtbsY = PicWidthInCtbsY * PicHeightInCtbsY;
+         len = av_ceil_log2_c(PicSizeInCtbsY);
+ 
+         slice_segment_addr = y / CtbSizeY * PicWidthInCtbsY + x / CtbSizeY;
+ 
+         ni_put_bits(pb, len, slice_segment_addr);
+     }
+ 
+     if (independent) {
+         write_raw_slice_header_independent(pb, slice, sps, pps);
+     }
+ 
+ //    if (pps->tiles_enabled_flag || pps->entropy_coding_sync_enabled_flag) {
+     if (((force_tile == 2) || (!force_tile && pps->tiles_enabled_flag)) ||
+             pps->entropy_coding_sync_enabled_flag) {
+         ni_set_ue_golomb(pb, slice->num_entry_point_offsets);
+         if (slice->num_entry_point_offsets > 0) {
+             ni_set_ue_golomb(pb, slice->offset_len_minus1);
+             for (i = 0; i < slice->num_entry_point_offsets; i++) {
+                 ni_put_bits(pb, slice->offset_len_minus1 + 1, slice->entry_point_offset_minus1[i]);
+             }
+         }
+     }
+ 
+     av_assert0(!pps->slice_segment_header_extension_present_flag);
+ 
+     ni_rbsp_trailing_bits(pb);
+ 
+     return 0;
+ }
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/ni_hevc_rbsp.h FFmpeg-n4.3.1/libavcodec/ni_hevc_rbsp.h
*** base_ffmpeg_n4.3.1/libavcodec/ni_hevc_rbsp.h	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/ni_hevc_rbsp.h	2021-09-13 14:19:52.148858760 -0700
***************
*** 0 ****
--- 1,55 ----
+ /*
+  * NetInt HEVC RBSP parser common code header
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ #ifndef ENCODER_STATE_BITSTREAM_H_
+ #define ENCODER_STATE_BITSTREAM_H_
+ 
+ #include "put_bits.h"
+ 
+ #define  MAX_PUT_BUF_SIZE (2*1024*1024)
+ 
+ typedef struct ni_bitstream_t {
+     PutBitContext pbc;
+     uint8_t *pb_buf;
+     uint8_t cache;
+     uint8_t cur_bits;
+     uint8_t zero_cnt;
+ } ni_bitstream_t;
+ 
+ extern int ni_bitstream_init(ni_bitstream_t *stream);
+ extern void ni_bitstream_deinit(ni_bitstream_t *stream);
+ extern void ni_bitstream_reset(ni_bitstream_t *stream);
+ extern void ni_bitstream_fetch(const ni_bitstream_t *stream, uint8_t *buf, size_t size);
+ extern int ni_bitstream_count(ni_bitstream_t *stream);
+ extern void ni_put_bits(ni_bitstream_t *stream, uint8_t bits, const uint32_t data);
+ extern void ff_ni_write_nal_header(ni_bitstream_t *stream, const uint8_t nal_type,
+         const uint8_t temporal_id, const int long_start_code);
+ extern int ff_ni_hevc_encode_nal_slice_header(ni_bitstream_t *stream, void *ctx,
+         H265RawSliceHeader *slice, const H265RawSPS *sps, const H265RawPPS *pps,
+         int width, int height, uint8_t force_tile, int x, int y, int independent);
+ extern int ff_ni_hevc_encode_nal_vps(ni_bitstream_t *stream, void *ctx,
+         const H265RawVPS *vps);
+ extern int ff_ni_hevc_encode_nal_sps(ni_bitstream_t *stream, void *ctx,
+         const H265RawSPS *sps, int width, int height);
+ extern int ff_ni_hevc_encode_nal_pps(ni_bitstream_t *stream, void *ctx,
+         const H265RawPPS *pps, uint8_t force_tile,
+         int columns, int rows);
+ #endif // ENCODER_STATE_BITSTREAM_H_
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/ni_hevc_tile_repack_bsf.c FFmpeg-n4.3.1/libavcodec/ni_hevc_tile_repack_bsf.c
*** base_ffmpeg_n4.3.1/libavcodec/ni_hevc_tile_repack_bsf.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavcodec/ni_hevc_tile_repack_bsf.c	2021-09-13 14:19:52.152858778 -0700
***************
*** 0 ****
--- 1,318 ----
+ /*
+  * NetInt HEVC tile repack BSF common source code
+  * Copyright (c) 2018-2019 NetInt
+  *
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ /**
+  * @file
+  *
+  * This bitstream filter repacks HEVC tiles into one packet containing
+  * just one frame.
+  */
+ 
+ #include "libavutil/avassert.h"
+ #include "libavutil/opt.h"
+ 
+ #include "internal.h"
+ #include "avcodec.h"
+ #include "bsf.h"
+ #include "bsf_internal.h"
+ #include "hevc.h"
+ 
+ 
+ typedef struct HEVCRepackContext {
+     AVPacket *buffer_pkt;
+     AVPacket **tile_pkt;
+ 
+     int tile_pos;
+     int tile_num;
+ } HEVCRepackContext;
+ 
+ static int hevc_tile_repack_filter(AVBSFContext *ctx, AVPacket *out)
+ {
+     HEVCRepackContext *s = ctx->priv_data;
+     int ret;
+     int tile_idx;
+     int8_t *side_data;
+     int i;
+ 
+     av_log(ctx, AV_LOG_DEBUG, "tile_pos %d, tile_num %d\n", s->tile_pos, s->tile_num);
+ 
+     if (s->tile_pos < s->tile_num) {
+         if (!s->buffer_pkt->data) {
+             ret = ff_bsf_get_packet_ref(ctx, s->buffer_pkt);
+             if (ret < 0) {
+                 av_log(ctx, AV_LOG_INFO, "failed to get packet ref: 0x%x\n", ret);
+                 return ret;
+             }
+         }
+ 
+         side_data = (int8_t *)av_packet_get_side_data(s->buffer_pkt, AV_PKT_DATA_SLICE_ADDR, NULL);
+         if (!side_data) {
+             av_log(ctx, AV_LOG_DEBUG, "failed to get packet side data\n");
+             return AVERROR(EINVAL);
+         }
+ 
+         tile_idx = *side_data;
+         if (tile_idx >= s->tile_num) {
+             av_log(ctx, AV_LOG_ERROR, "tile index %d exceeds maximum tile number %d\n",
+                     tile_idx, s->tile_num);
+             return AVERROR(EINVAL);
+         }
+ 
+         if (s->tile_pkt[tile_idx]->buf) {
+             av_log(ctx, AV_LOG_ERROR, "duplicated tile index %d\n", tile_idx);
+             return AVERROR(EINVAL);
+         }
+ 
+         s->tile_pkt[tile_idx]->buf = av_buffer_ref(s->buffer_pkt->buf);
+         if (!s->tile_pkt[tile_idx]->buf) {
+             av_log(ctx, AV_LOG_ERROR, "failed to get buffer for tile index %d\n", tile_idx);
+             return AVERROR(ENOMEM);
+         }
+         s->tile_pkt[tile_idx]->data = s->buffer_pkt->data;
+         s->tile_pkt[tile_idx]->size = s->buffer_pkt->size;
+ 
+         av_log(ctx, AV_LOG_DEBUG, "tile %d, data actual size %d\n", tile_idx,
+                 s->buffer_pkt->size);
+ 
+         if (s->tile_pos == 0) {
+             s->tile_pkt[0]->pts = s->buffer_pkt->pts;
+             s->tile_pkt[0]->dts = s->buffer_pkt->dts;
+             s->tile_pkt[0]->pos = s->buffer_pkt->pos;
+             s->tile_pkt[0]->flags = s->buffer_pkt->flags;
+             s->tile_pkt[0]->stream_index = s->buffer_pkt->stream_index;
+ 
+             s->tile_pkt[0]->side_data = NULL;
+             s->tile_pkt[0]->side_data_elems = 0;
+ 
+             for (i = 0; i < s->tile_pkt[0]->side_data_elems; i++) {
+                 enum AVPacketSideDataType type = s->buffer_pkt->side_data[i].type;
+                 if (type != AV_PKT_DATA_SLICE_ADDR) {
+                     int size = s->buffer_pkt->side_data[i].size;
+                     uint8_t *src_data = s->buffer_pkt->side_data[i].data;
+                     uint8_t *dst_data = av_packet_new_side_data(s->tile_pkt[0], type, size);
+ 
+                     if (!dst_data) {
+                         av_packet_free_side_data(s->tile_pkt[0]);
+                         return AVERROR(ENOMEM);
+                     }
+ 
+                     memcpy(dst_data, src_data, size);
+                 }
+             }
+         } else {
+             if (s->buffer_pkt->pts != s->tile_pkt[0]->pts ||
+                     s->buffer_pkt->dts != s->tile_pkt[0]->dts ||
+                     s->buffer_pkt->flags != s->tile_pkt[0]->flags ||
+                     s->buffer_pkt->stream_index != s->tile_pkt[0]->stream_index) {
+                 av_log(ctx, AV_LOG_ERROR, "packet metadata does not match\n");
+                 return AVERROR(EINVAL);
+             }
+         }
+         s->tile_pos++;
+         av_packet_unref(s->buffer_pkt);
+     }
+ 
+     if (s->tile_pos == s->tile_num) {
+         int new_size = 0;
+         int found;
+         const uint8_t *ptr;
+         const uint8_t *end;
+         const uint8_t *p_offset;
+         int nalu_type;
+         uint32_t stc;
+         uint8_t *data;
+         AVBufferRef *buf;
+ 
+         /* max payload size */
+         for (i = 0; i < s->tile_num; i++) {
+             new_size += s->tile_pkt[i]->size;
+         }
+ 
+         buf = av_buffer_alloc(new_size);
+         if (!buf) {
+             av_log(ctx, AV_LOG_ERROR, "failed to allocate new packet data\n");
+             return AVERROR(ENOMEM);
+         }
+ 
+         data = buf->data;
+         memcpy(data, s->tile_pkt[0]->data, s->tile_pkt[0]->size);
+         new_size = s->tile_pkt[0]->size;
+         av_log(ctx, AV_LOG_DEBUG, "tile %d size %d\n", 0, new_size);
+         av_buffer_unref(&s->tile_pkt[0]->buf);
+         s->tile_pkt[0]->buf = NULL;
+ 
+         for (i = 1; i < s->tile_num; i++) {
+             ptr = s->tile_pkt[i]->data;
+             end = s->tile_pkt[i]->data + s->tile_pkt[i]->size;
+ 
+             stc = -1;
+             found = 0;
+             ptr = avpriv_find_start_code(ptr, end, &stc);
+             while (ptr < end) {
+                 av_log(ctx, AV_LOG_DEBUG, "tile %d, %02x %02x %02x %02x %02x\n", i,
+                         *(ptr-4), *(ptr-3), *(ptr-2), *(ptr-1), *ptr);
+ 
+                 if (found) {
+                     memcpy(data + new_size, p_offset, ptr - 4 - p_offset);
+                     new_size += ptr - 4 - p_offset;
+                     found = 0;
+                 }
+ 
+                 nalu_type = (stc >> 1) & 0x3F;
+                 if (nalu_type >= (int)HEVC_NAL_TRAIL_N &&
+                         nalu_type <= (int)HEVC_NAL_RSV_VCL31) {
+                     p_offset = ptr - 4;
+                     found = 1;
+                 }
+ 
+                 stc = -1;
+                 ptr = avpriv_find_start_code(ptr, end, &stc);
+             }
+ 
+             if (found) {
+                 memcpy(data + new_size, p_offset, end - p_offset);
+                 new_size += end - p_offset;
+                 av_log(ctx, AV_LOG_DEBUG, "tile %d size %d\n", i, (int)(end - p_offset));
+             }
+             av_buffer_unref(&s->tile_pkt[i]->buf);
+             s->tile_pkt[i]->buf = NULL;
+         }
+ 
+         out->buf = buf;
+         out->data = data;
+         out->size = new_size;
+ 
+         av_log(ctx, AV_LOG_DEBUG, "repacket new size %d\n", new_size);
+ 
+         s->tile_pos = 0;
+         return 0;
+     } else {
+         return AVERROR(EAGAIN);
+     }
+ }
+ 
+ //static const CodedBitstreamUnitType decompose_unit_types[] = {
+ //};
+ 
+ static int hevc_tile_repack_init(AVBSFContext *ctx)
+ {
+     HEVCRepackContext *s = ctx->priv_data;
+     int ret;
+     int i;
+ 
+     av_log(ctx, AV_LOG_INFO, "number of tiles %d\n", s->tile_num);
+     if (s->tile_num <= 0) {
+         return AVERROR(EINVAL);
+     }
+ 
+     s->buffer_pkt = av_packet_alloc();
+     if (!s->buffer_pkt) {
+         return AVERROR(ENOMEM);
+     }
+     av_init_packet(s->buffer_pkt);
+ 
+     s->tile_pkt = av_malloc(sizeof(AVPacket *) * s->tile_num);
+     if (!s->tile_pkt) {
+         ret = AVERROR(ENOMEM);
+         goto fail_alloc_tile_pkt;
+     }
+     memset(s->tile_pkt, 0, sizeof(AVPacket *) * s->tile_num);
+ 
+     for (i = 0; i < s->tile_num; i++) {
+         s->tile_pkt[i] = av_packet_alloc();
+         if (!s->tile_pkt[i]) {
+             ret = AVERROR(ENOMEM);
+             goto fail_alloc_pkts;
+         }
+         av_init_packet(s->tile_pkt[i]);
+     }
+ 
+     return 0;
+ 
+ fail_alloc_pkts:
+     for (i -= 1; i >=0; i--) {
+         av_packet_free(&s->tile_pkt[i]);
+     }
+     free(s->tile_pkt);
+     s->tile_pkt = NULL;
+ fail_alloc_tile_pkt:
+     av_packet_free(&s->buffer_pkt);
+     s->buffer_pkt = NULL;
+ 
+     return ret;
+ }
+ 
+ static void hevc_tile_repack_flush(AVBSFContext *ctx)
+ {
+     HEVCRepackContext *s = ctx->priv_data;
+     int i;
+ 
+     av_packet_unref(s->buffer_pkt);
+ 
+     for (i = 0; i < s->tile_num; i++) {
+         av_packet_unref(s->tile_pkt[i]);
+     }
+ }
+ 
+ static void hevc_tile_repack_close(AVBSFContext *ctx)
+ {
+     HEVCRepackContext *s = ctx->priv_data;
+     int i;
+ 
+     av_packet_free(&s->buffer_pkt);
+     s->buffer_pkt = NULL;
+ 
+     for (i = 0; i < s->tile_num; i++) {
+         av_packet_free(&s->tile_pkt[i]);
+     }
+     free(s->tile_pkt);
+     s->tile_pkt = NULL;
+ }
+ 
+ static const enum AVCodecID hevc_tile_repack_codec_ids[] = {
+     AV_CODEC_ID_HEVC, AV_CODEC_ID_NONE,
+ };
+ 
+ #define OFFSET(x) offsetof(HEVCRepackContext, x)
+ #define FLAGS (AV_OPT_FLAG_VIDEO_PARAM|AV_OPT_FLAG_BSF_PARAM)
+ static const AVOption options[] = {
+     { "tile_num", "specify number of tiles", OFFSET(tile_num), AV_OPT_TYPE_INT,
+         { .i64 = 0 }, 0, 255, FLAGS },
+     { NULL },
+ };
+ 
+ static const AVClass tile_repack_class = {
+     .class_name = "hevc_tile_repack_bsf",
+     .item_name  = av_default_item_name,
+     .option     = options,
+     .version    = LIBAVUTIL_VERSION_INT,
+ };
+ 
+ const AVBitStreamFilter ff_hevc_tile_repack_bsf = {
+     .name           = "hevc_tile_repack",
+     .priv_data_size = sizeof(HEVCRepackContext),
+     .priv_class     = &tile_repack_class,
+     .init           = hevc_tile_repack_init,
+     .flush          = hevc_tile_repack_flush,
+     .close          = hevc_tile_repack_close,
+     .filter         = hevc_tile_repack_filter,
+     .codec_ids      = hevc_tile_repack_codec_ids,
+ };
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavcodec/packet.h FFmpeg-n4.3.1/libavcodec/packet.h
*** base_ffmpeg_n4.3.1/libavcodec/packet.h	2022-01-30 21:54:34.276206101 -0800
--- FFmpeg-n4.3.1/libavcodec/packet.h	2021-09-13 14:19:52.152858778 -0700
***************
*** 283,288 ****
--- 283,293 ----
      AV_PKT_DATA_DOVI_CONF,
  
      /**
+      * NETINT: HEVC tile/slice index in one frame.
+      */
+     AV_PKT_DATA_SLICE_ADDR,
+ 
+     /**
       * The number of side data types.
       * This is not part of the public API/ABI in the sense that it may
       * change when new side data types are added.
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavfilter/allfilters.c FFmpeg-n4.3.1/libavfilter/allfilters.c
*** base_ffmpeg_n4.3.1/libavfilter/allfilters.c	2022-01-30 21:54:34.340207015 -0800
--- FFmpeg-n4.3.1/libavfilter/allfilters.c	2021-11-04 21:55:58.351592756 -0700
***************
*** 265,270 ****
--- 265,271 ----
  extern AVFilter ff_vf_hwmap;
  extern AVFilter ff_vf_hwupload;
  extern AVFilter ff_vf_hwupload_cuda;
+ extern AVFilter ff_vf_hwupload_ni;
  extern AVFilter ff_vf_hysteresis;
  extern AVFilter ff_vf_idet;
  extern AVFilter ff_vf_il;
***************
*** 361,366 ****
--- 362,368 ----
  extern AVFilter ff_vf_scale2ref;
  extern AVFilter ff_vf_scdet;
  extern AVFilter ff_vf_scroll;
+ extern AVFilter ff_vf_sdl;
  extern AVFilter ff_vf_select;
  extern AVFilter ff_vf_selectivecolor;
  extern AVFilter ff_vf_sendcmd;
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavfilter/Makefile FFmpeg-n4.3.1/libavfilter/Makefile
*** base_ffmpeg_n4.3.1/libavfilter/Makefile	2022-01-30 21:54:34.328206843 -0800
--- FFmpeg-n4.3.1/libavfilter/Makefile	2021-11-04 21:55:58.351592756 -0700
***************
*** 279,284 ****
--- 279,285 ----
  OBJS-$(CONFIG_HWDOWNLOAD_FILTER)             += vf_hwdownload.o
  OBJS-$(CONFIG_HWMAP_FILTER)                  += vf_hwmap.o
  OBJS-$(CONFIG_HWUPLOAD_CUDA_FILTER)          += vf_hwupload_cuda.o
+ OBJS-$(CONFIG_HWUPLOAD_NI_FILTER)            += vf_hwupload_ni.o
  OBJS-$(CONFIG_HWUPLOAD_FILTER)               += vf_hwupload.o
  OBJS-$(CONFIG_HYSTERESIS_FILTER)             += vf_hysteresis.o framesync.o
  OBJS-$(CONFIG_IDET_FILTER)                   += vf_idet.o
***************
*** 379,384 ****
--- 380,386 ----
  OBJS-$(CONFIG_SCALE2REF_FILTER)              += vf_scale.o scale_eval.o
  OBJS-$(CONFIG_SCDET_FILTER)                  += vf_scdet.o
  OBJS-$(CONFIG_SCROLL_FILTER)                 += vf_scroll.o
+ OBJS-$(CONFIG_SDL_FILTER)                    += vf_sdl.o
  OBJS-$(CONFIG_SELECT_FILTER)                 += f_select.o
  OBJS-$(CONFIG_SELECTIVECOLOR_FILTER)         += vf_selectivecolor.o
  OBJS-$(CONFIG_SENDCMD_FILTER)                += f_sendcmd.o
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavfilter/vf_hwupload_ni.c FFmpeg-n4.3.1/libavfilter/vf_hwupload_ni.c
*** base_ffmpeg_n4.3.1/libavfilter/vf_hwupload_ni.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavfilter/vf_hwupload_ni.c	2021-11-04 21:55:58.347593967 -0700
***************
*** 0 ****
--- 1,214 ----
+ /*
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ #include "libavutil/buffer.h"
+ #include "libavutil/hwcontext.h"
+ #include "libavutil/hwcontext_ni.h"
+ #include "libavutil/hwcontext_internal.h"
+ #include "libavutil/log.h"
+ #include "libavutil/opt.h"
+ 
+ #include "avfilter.h"
+ #include "formats.h"
+ #include "internal.h"
+ #include "video.h"
+ 
+ typedef struct NiUploadContext {
+     const AVClass *class;
+     int device_idx;
+ 
+     AVBufferRef *hwdevice;
+     AVBufferRef *hwframe;
+ } NiUploadContext;
+ 
+ static av_cold int niupload_init(AVFilterContext *ctx)
+ {
+     NiUploadContext *s = ctx->priv;
+     char buf[64] = { 0 };
+ 
+     snprintf(buf, sizeof(buf), "%d", s->device_idx);
+ 
+     return av_hwdevice_ctx_create(&s->hwdevice, AV_HWDEVICE_TYPE_NI, buf, NULL, 0);
+ }
+ 
+ static av_cold void niupload_uninit(AVFilterContext *ctx)
+ {
+     NiUploadContext *s = ctx->priv;
+ 
+     av_buffer_unref(&s->hwframe);
+     av_buffer_unref(&s->hwdevice);
+ }
+ 
+ static int niupload_query_formats(AVFilterContext *ctx)
+ {
+     NiUploadContext *nictx = ctx->priv;
+     AVHWFramesConstraints *constraints = NULL;
+     const enum AVPixelFormat *input_pix_fmts, *output_pix_fmts;
+     AVFilterFormats *input_formats = NULL;
+     int err, i;
+ 
+     if (!nictx->hwdevice)
+         return AVERROR(ENOMEM);
+ 
+     constraints = av_hwdevice_get_hwframe_constraints(nictx->hwdevice, NULL);
+     if (!constraints) {
+         err = AVERROR(EINVAL);
+         goto fail;
+     }
+ 
+     input_pix_fmts  = constraints->valid_sw_formats;
+     output_pix_fmts = constraints->valid_hw_formats;
+ 
+     input_formats = ff_make_format_list(output_pix_fmts);
+     if (!input_formats) {
+         err = AVERROR(ENOMEM);
+         goto fail;
+     }
+     if (input_pix_fmts) {
+         for (i = 0; input_pix_fmts[i] != AV_PIX_FMT_NONE; i++) {
+             err = ff_add_format(&input_formats, input_pix_fmts[i]);
+             if (err < 0)
+                 goto fail;
+         }
+     }
+ 
+     if ((err = ff_formats_ref(input_formats, &ctx->inputs[0]->out_formats)) < 0 ||
+         (err = ff_formats_ref(ff_make_format_list(output_pix_fmts),
+                               &ctx->outputs[0]->in_formats)) < 0)
+         goto fail;
+ 
+     av_hwframe_constraints_free(&constraints);
+     return 0;
+ 
+ fail:
+     av_buffer_unref(&nictx->hwdevice);
+     av_hwframe_constraints_free(&constraints);
+     return err;
+ }
+ 
+ static int niupload_config_output(AVFilterLink *outlink)
+ {
+     AVFilterContext *ctx = outlink->src;
+     AVFilterLink *inlink = ctx->inputs[0];
+     NiUploadContext *s = ctx->priv;
+ 
+     AVHWFramesContext *hwframe_ctx;
+     int ret;
+ 
+     av_buffer_unref(&s->hwframe);
+     s->hwframe = av_hwframe_ctx_alloc(s->hwdevice);
+     if (!s->hwframe)
+         return AVERROR(ENOMEM);
+ 
+     hwframe_ctx            = (AVHWFramesContext*)s->hwframe->data;
+     hwframe_ctx->format    = AV_PIX_FMT_NI;
+     hwframe_ctx->sw_format = inlink->format;
+     hwframe_ctx->width     = inlink->w;
+     hwframe_ctx->height    = inlink->h;
+ 
+     ret = av_hwframe_ctx_init(s->hwframe);
+     if (ret < 0)
+         return ret;
+ 
+     outlink->hw_frames_ctx = av_buffer_ref(s->hwframe);
+     if (!outlink->hw_frames_ctx)
+         return AVERROR(ENOMEM);
+ 
+     return 0;
+ }
+ 
+ static int niupload_filter_frame(AVFilterLink *link, AVFrame *in)
+ {
+     AVFilterContext   *ctx = link->dst;
+     AVFilterLink  *outlink = ctx->outputs[0];
+ 
+     AVFrame *out = NULL;
+     int ret;
+ 
+     out = ff_get_video_buffer(outlink, outlink->w, outlink->h);
+     if (!out) {
+         ret = AVERROR(ENOMEM);
+         goto fail;
+     }
+ 
+     out->width  = in->width;
+     out->height = in->height;
+ 
+     ret = av_hwframe_transfer_data(out, in, 0);
+     if (ret < 0) {
+         av_log(ctx, AV_LOG_ERROR, "niupload_filter_frame(): Error transferring data to the NI devices\n");
+         goto fail;
+     }
+ 
+     ret = av_frame_copy_props(out, in);
+     if (ret < 0)
+         goto fail;
+ 
+     av_frame_free(&in);
+ 
+     return ff_filter_frame(ctx->outputs[0], out);
+ fail:
+     av_frame_free(&in);
+     av_frame_free(&out);
+     return ret;
+ }
+ 
+ #define OFFSET(x) offsetof(NiUploadContext, x)
+ #define FLAGS (AV_OPT_FLAG_FILTERING_PARAM | AV_OPT_FLAG_VIDEO_PARAM)
+ static const AVOption niupload_options[] = {
+     { "device", "Number of the device to use", OFFSET(device_idx), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, INT_MAX, FLAGS },
+     { NULL },
+ };
+ 
+ AVFILTER_DEFINE_CLASS(niupload);
+ 
+ static const AVFilterPad niupload_inputs[] = {
+     {
+         .name         = "default",
+         .type         = AVMEDIA_TYPE_VIDEO,
+         .filter_frame = niupload_filter_frame,
+     },
+     { NULL }
+ };
+ 
+ static const AVFilterPad niupload_outputs[] = {
+     {
+         .name         = "default",
+         .type         = AVMEDIA_TYPE_VIDEO,
+         .config_props = niupload_config_output,
+     },
+     { NULL }
+ };
+ 
+ AVFilter ff_vf_hwupload_ni = {
+     .name        = "ni_hwupload",
+     .description = NULL_IF_CONFIG_SMALL("Upload a system memory frame to a Netint device."),
+ 
+     .init      = niupload_init,
+     .uninit    = niupload_uninit,
+ 
+     .query_formats = niupload_query_formats,
+ 
+     .priv_size  = sizeof(NiUploadContext),
+     .priv_class = &niupload_class,
+ 
+     .inputs    = niupload_inputs,
+     .outputs   = niupload_outputs,
+ 
+     .flags_internal = FF_FILTER_FLAG_HWFRAME_AWARE,
+ };
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavfilter/vf_sdl.c FFmpeg-n4.3.1/libavfilter/vf_sdl.c
*** base_ffmpeg_n4.3.1/libavfilter/vf_sdl.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavfilter/vf_sdl.c	2021-09-13 14:19:52.152858778 -0700
***************
*** 0 ****
--- 1,199 ----
+ /*
+  * This file is part of FFmpeg.
+  *
+  * FFmpeg is free software; you can redistribute it and/or
+  * modify it under the terms of the GNU Lesser General Public
+  * License as published by the Free Software Foundation; either
+  * version 2.1 of the License, or (at your option) any later version.
+  *
+  * FFmpeg is distributed in the hope that it will be useful,
+  * but WITHOUT ANY WARRANTY; without even the implied warranty of
+  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+  * Lesser General Public License for more details.
+  *
+  * You should have received a copy of the GNU Lesser General Public
+  * License along with FFmpeg; if not, write to the Free Software
+  * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+  */
+ 
+ #include "libavutil/avassert.h"
+ #include "libavutil/opt.h"
+ #include "libavutil/time.h"
+ #include "libswscale/swscale.h"
+ #include "avfilter.h"
+ #include "internal.h"
+ #include <SDL.h>
+ 
+ 
+ typedef struct SdlContext {
+     const AVClass *class;
+     int quit;
+     int width;
+     int height;
+     SDL_Renderer *renderer;
+     SDL_Texture *texture;
+     SDL_Window *window;
+ } SdlContext;
+ 
+ static int query_formats(AVFilterContext *avctx)
+ {
+     static const enum AVPixelFormat pix_fmts[] = {
+         AV_PIX_FMT_RGB24, AV_PIX_FMT_BGR24,
+         AV_PIX_FMT_GRAY8, AV_PIX_FMT_GRAYF32,
+         AV_PIX_FMT_YUV420P, AV_PIX_FMT_YUV422P,
+         AV_PIX_FMT_YUV444P, AV_PIX_FMT_YUV410P, AV_PIX_FMT_YUV411P,
+         AV_PIX_FMT_NONE
+     };
+ 
+     AVFilterFormats *fmts_list = ff_make_format_list(pix_fmts);
+     if (!fmts_list) {
+         av_log(avctx, AV_LOG_ERROR, "could not create formats list\n");
+         return AVERROR(ENOMEM);
+     }
+ 
+     return ff_set_common_formats(avctx, fmts_list);
+ }
+ 
+ static int sdl_config_input(AVFilterLink *inlink)
+ {
+     AVFilterContext *avctx = inlink->dst;
+     SdlContext     *ctx = avctx->priv;
+ 
+     ctx->window = SDL_CreateWindow("FFmpeg SDL Filter", SDL_WINDOWPOS_UNDEFINED, SDL_WINDOWPOS_UNDEFINED,
+                                    inlink->w, inlink->h, SDL_WINDOW_RESIZABLE);
+     if (!ctx->window) {
+         av_log(ctx, AV_LOG_ERROR, "Failed to create SDL window %s!", SDL_GetError());
+         return AVERROR(ENOMEM);
+     }
+ 
+     ctx->renderer = SDL_CreateRenderer(ctx->window, -1, SDL_RENDERER_ACCELERATED | SDL_RENDERER_PRESENTVSYNC);
+     if (!ctx->renderer) {
+         av_log(ctx, AV_LOG_ERROR, "Failed to create SDL renderer %s!", SDL_GetError());
+         return AVERROR(ENOMEM);
+     }
+ 
+     ctx->texture = SDL_CreateTexture(ctx->renderer, SDL_PIXELFORMAT_IYUV,
+                                      SDL_TEXTUREACCESS_STREAMING, inlink->w , inlink->h);
+     if (!ctx->renderer) {
+         av_log(ctx, AV_LOG_ERROR, "Failed to create SDL texture %s!", SDL_GetError());
+         return AVERROR(ENOMEM);
+     }
+ 
+     return 0;
+ }
+ 
+ static int sdl_filter_frame(AVFilterLink *inlink, AVFrame *frame)
+ {
+     AVFilterContext *avctx = inlink->dst;
+     AVFilterLink  *outlink = avctx->outputs[0];
+     SdlContext     *ctx = avctx->priv;
+     SDL_Event event;
+ 
+     if (SDL_PollEvent(&event)) {
+         switch (event.type) {
+             case SDL_KEYDOWN:
+                 switch (event.key.keysym.sym) {
+                 case SDLK_ESCAPE:
+                 case SDLK_q:
+                     ctx->quit = 1;
+                     break;
+                 default:
+                     break;
+                 }
+                 break;
+             case SDL_QUIT:
+                 ctx->quit = 1;
+                 break;
+             case SDL_WINDOWEVENT:
+                 switch (event.window.event) {
+                     case SDL_WINDOWEVENT_RESIZED:
+                     case SDL_WINDOWEVENT_SIZE_CHANGED:
+                         ctx->width = event.window.data1;
+                         ctx->height = event.window.data2;
+                     default:
+                         break;
+                 }
+                 break;
+             default:
+                 break;
+         }
+     }
+ 
+     if (ctx->quit) {
+         SDL_DestroyTexture(ctx->texture);
+         SDL_DestroyRenderer(ctx->renderer);
+         SDL_DestroyWindow(ctx->window);
+         SDL_Quit();
+     } else {
+         SDL_UpdateYUVTexture(ctx->texture, NULL,
+                              frame->data[0], frame->linesize[0],
+                              frame->data[1], frame->linesize[1],
+                              frame->data[2], frame->linesize[2]);
+         SDL_RenderClear(ctx->renderer);
+         SDL_RenderCopyEx(ctx->renderer, ctx->texture, NULL, NULL, 0, NULL, 0);
+         SDL_RenderPresent(ctx->renderer);
+     }
+ 
+     return ff_filter_frame(outlink, frame);
+ }
+ 
+ static av_cold int sdl_init(AVFilterContext *avctx)
+ {
+     if (SDL_Init(SDL_INIT_VIDEO) < 0) {
+         av_log(avctx, AV_LOG_ERROR, "Failed to init SDL %s!", SDL_GetError());
+         return AVERROR(ENOMEM);
+     }
+ 
+     return 0;
+ }
+ 
+ static av_cold void sdl_uninit(AVFilterContext *avctx)
+ {
+     SdlContext *ctx = avctx->priv;
+ 
+     if (!ctx->quit) {
+         SDL_DestroyTexture(ctx->texture);
+         SDL_DestroyRenderer(ctx->renderer);
+         SDL_DestroyWindow(ctx->window);
+         SDL_Quit();
+     }
+ }
+ 
+ #define OFFSET(x) offsetof(SdlContext, x)
+ #define FLAGS AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM
+ static const AVOption sdl_options[] = {
+     { NULL }
+ };
+ 
+ AVFILTER_DEFINE_CLASS(sdl);
+ 
+ static const AVFilterPad sdl_inputs[] = {
+     {
+         .name         = "default",
+         .type         = AVMEDIA_TYPE_VIDEO,
+         .config_props = sdl_config_input,
+         .filter_frame = sdl_filter_frame,
+     },
+     { NULL }
+ };
+ 
+ static const AVFilterPad sdl_outputs[] = {
+     {
+         .name = "default",
+         .type = AVMEDIA_TYPE_VIDEO,
+     },
+     { NULL }
+ };
+ 
+ AVFilter ff_vf_sdl = {
+     .name          = "sdl",
+     .description   = NULL_IF_CONFIG_SMALL("Use SDL2.0 to display AVFrame."),
+     .init          = sdl_init,
+     .uninit        = sdl_uninit,
+ 
+     .priv_size     = sizeof(SdlContext),
+     .priv_class    = &sdl_class,
+     .query_formats = query_formats,
+     .inputs        = sdl_inputs,
+     .outputs       = sdl_outputs,
+ };
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavformat/flvdec.c FFmpeg-n4.3.1/libavformat/flvdec.c
*** base_ffmpeg_n4.3.1/libavformat/flvdec.c	2022-01-30 21:54:34.388207699 -0800
--- FFmpeg-n4.3.1/libavformat/flvdec.c	2021-08-09 14:16:17.898194620 -0700
***************
*** 36,41 ****
--- 36,42 ----
  #include "internal.h"
  #include "avio_internal.h"
  #include "flv.h"
+ #include "hevc.h"
  
  #define VALIDATE_INDEX_TS_THRESH 2500
  
***************
*** 318,323 ****
--- 319,326 ----
          return vpar->codec_id == AV_CODEC_ID_VP6A;
      case FLV_CODECID_H264:
          return vpar->codec_id == AV_CODEC_ID_H264;
+     case FLV_CODECID_HEVC:
+         return vpar->codec_id == AV_CODEC_ID_HEVC;
      default:
          return vpar->codec_tag == flv_codecid;
      }
***************
*** 363,368 ****
--- 366,376 ----
          vstream->need_parsing = AVSTREAM_PARSE_HEADERS;
          ret = 3;     // not 4, reading packet type will consume one byte
          break;
+     case FLV_CODECID_HEVC:
+         par->codec_id = AV_CODEC_ID_HEVC;
+         vstream->need_parsing = AVSTREAM_PARSE_NONE;
+         ret = 3;     // not 4, reading packet type will consume one byte
+         break;
      case FLV_CODECID_MPEG4:
          par->codec_id = AV_CODEC_ID_MPEG4;
          ret = 3;
***************
*** 1222,1228 ****
  
      if (st->codecpar->codec_id == AV_CODEC_ID_AAC ||
          st->codecpar->codec_id == AV_CODEC_ID_H264 ||
!         st->codecpar->codec_id == AV_CODEC_ID_MPEG4) {
          int type = avio_r8(s->pb);
          size--;
  
--- 1230,1237 ----
  
      if (st->codecpar->codec_id == AV_CODEC_ID_AAC ||
          st->codecpar->codec_id == AV_CODEC_ID_H264 ||
!         st->codecpar->codec_id == AV_CODEC_ID_MPEG4 ||
!         st->codecpar->codec_id == AV_CODEC_ID_HEVC) {
          int type = avio_r8(s->pb);
          size--;
  
***************
*** 1231,1237 ****
              goto leave;
          }
  
!         if (st->codecpar->codec_id == AV_CODEC_ID_H264 || st->codecpar->codec_id == AV_CODEC_ID_MPEG4) {
              // sign extension
              int32_t cts = (avio_rb24(s->pb) + 0xff800000) ^ 0xff800000;
              pts = dts + cts;
--- 1240,1247 ----
              goto leave;
          }
  
!         if (st->codecpar->codec_id == AV_CODEC_ID_H264 || st->codecpar->codec_id == AV_CODEC_ID_MPEG4 ||
!             st->codecpar->codec_id == AV_CODEC_ID_HEVC) {
              // sign extension
              int32_t cts = (avio_rb24(s->pb) + 0xff800000) ^ 0xff800000;
              pts = dts + cts;
***************
*** 1247,1253 ****
              }
          }
          if (type == 0 && (!st->codecpar->extradata || st->codecpar->codec_id == AV_CODEC_ID_AAC ||
!             st->codecpar->codec_id == AV_CODEC_ID_H264)) {
              AVDictionaryEntry *t;
  
              if (st->codecpar->extradata) {
--- 1257,1263 ----
              }
          }
          if (type == 0 && (!st->codecpar->extradata || st->codecpar->codec_id == AV_CODEC_ID_AAC ||
!             st->codecpar->codec_id == AV_CODEC_ID_H264 || st->codecpar->codec_id == AV_CODEC_ID_HEVC)) {
              AVDictionaryEntry *t;
  
              if (st->codecpar->extradata) {
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavformat/flvenc.c FFmpeg-n4.3.1/libavformat/flvenc.c
*** base_ffmpeg_n4.3.1/libavformat/flvenc.c	2022-01-30 21:54:34.388207699 -0800
--- FFmpeg-n4.3.1/libavformat/flvenc.c	2021-09-13 14:19:52.152858778 -0700
***************
*** 34,39 ****
--- 34,40 ----
  #include "libavutil/opt.h"
  #include "libavcodec/put_bits.h"
  #include "libavcodec/aacenctab.h"
+ #include "hevc.h"
  
  
  static const AVCodecTag flv_video_codec_ids[] = {
***************
*** 46,51 ****
--- 47,53 ----
      { AV_CODEC_ID_VP6,      FLV_CODECID_VP6 },
      { AV_CODEC_ID_VP6A,     FLV_CODECID_VP6A },
      { AV_CODEC_ID_H264,     FLV_CODECID_H264 },
+     { AV_CODEC_ID_HEVC,     FLV_CODECID_HEVC },
      { AV_CODEC_ID_NONE,     0 }
  };
  
***************
*** 236,248 ****
      avio_w8(pb, (ts >> 24) & 0x7F);
  }
  
! static void put_avc_eos_tag(AVIOContext *pb, unsigned ts)
  {
      avio_w8(pb, FLV_TAG_TYPE_VIDEO);
      avio_wb24(pb, 5);               /* Tag Data Size */
      put_timestamp(pb, ts);
      avio_wb24(pb, 0);               /* StreamId = 0 */
!     avio_w8(pb, 23);                /* ub[4] FrameType = 1, ub[4] CodecId = 7 */
      avio_w8(pb, 2);                 /* AVC end of sequence */
      avio_wb24(pb, 0);               /* Always 0 for AVC EOS. */
      avio_wb32(pb, 16);              /* Size of FLV tag */
--- 238,252 ----
      avio_w8(pb, (ts >> 24) & 0x7F);
  }
  
! // NETINT: add 'id' param
! static void put_avc_eos_tag(AVIOContext *pb, unsigned ts, enum AVCodecID id)
  {
      avio_w8(pb, FLV_TAG_TYPE_VIDEO);
      avio_wb24(pb, 5);               /* Tag Data Size */
      put_timestamp(pb, ts);
      avio_wb24(pb, 0);               /* StreamId = 0 */
!     // NETINT: 44(0x2C) for HEVC
!     avio_w8(pb, (id==AV_CODEC_ID_H264)? 23:44);   /* ub[4] FrameType = 1, ub[4] CodecId = 7 */
      avio_w8(pb, 2);                 /* AVC end of sequence */
      avio_wb24(pb, 0);               /* Always 0 for AVC EOS. */
      avio_wb32(pb, 16);              /* Size of FLV tag */
***************
*** 490,497 ****
      AVIOContext *pb = s->pb;
      FLVContext *flv = s->priv_data;
  
      if (par->codec_id == AV_CODEC_ID_AAC || par->codec_id == AV_CODEC_ID_H264
!             || par->codec_id == AV_CODEC_ID_MPEG4) {
          int64_t pos;
          avio_w8(pb,
                  par->codec_type == AVMEDIA_TYPE_VIDEO ?
--- 494,506 ----
      AVIOContext *pb = s->pb;
      FLVContext *flv = s->priv_data;
  
+     // NETINT: do not attempt to write FLV headers if they are not available
+     if ((par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_HEVC) &&
+         ! (par->extradata && par->extradata_size > 0))
+         return;
+ 
      if (par->codec_id == AV_CODEC_ID_AAC || par->codec_id == AV_CODEC_ID_H264
!             || par->codec_id == AV_CODEC_ID_MPEG4 || par->codec_id == AV_CODEC_ID_HEVC) {
          int64_t pos;
          avio_w8(pb,
                  par->codec_type == AVMEDIA_TYPE_VIDEO ?
***************
*** 537,543 ****
              avio_w8(pb, par->codec_tag | FLV_FRAME_KEY); // flags
              avio_w8(pb, 0); // AVC sequence header
              avio_wb24(pb, 0); // composition time
!             ff_isom_write_avcc(pb, par->extradata, par->extradata_size);
          }
          data_size = avio_tell(pb) - pos;
          avio_seek(pb, -data_size - 10, SEEK_CUR);
--- 546,556 ----
              avio_w8(pb, par->codec_tag | FLV_FRAME_KEY); // flags
              avio_w8(pb, 0); // AVC sequence header
              avio_wb24(pb, 0); // composition time
!             if (par->codec_id == AV_CODEC_ID_HEVC) {
!                 ff_isom_write_hvcc(pb, par->extradata, par->extradata_size, 0);
!             } else {
!                 ff_isom_write_avcc(pb, par->extradata, par->extradata_size);
!             }
          }
          data_size = avio_tell(pb) - pos;
          avio_seek(pb, -data_size - 10, SEEK_CUR);
***************
*** 844,851 ****
              AVCodecParameters *par = s->streams[i]->codecpar;
              FLVStreamContext *sc = s->streams[i]->priv_data;
              if (par->codec_type == AVMEDIA_TYPE_VIDEO &&
!                     (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4))
!                 put_avc_eos_tag(pb, sc->last_ts);
          }
      }
  
--- 857,864 ----
              AVCodecParameters *par = s->streams[i]->codecpar;
              FLVStreamContext *sc = s->streams[i]->priv_data;
              if (par->codec_type == AVMEDIA_TYPE_VIDEO &&
!                     (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4 || par->codec_id == AV_CODEC_ID_HEVC))
!                 put_avc_eos_tag(pb, sc->last_ts, par->codec_id); // NETINT: add codec_id 
          }
      }
  
***************
*** 895,907 ****
      if (par->codec_id == AV_CODEC_ID_VP6F || par->codec_id == AV_CODEC_ID_VP6A ||
          par->codec_id == AV_CODEC_ID_VP6  || par->codec_id == AV_CODEC_ID_AAC)
          flags_size = 2;
!     else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4)
          flags_size = 5;
      else
          flags_size = 1;
  
      if (par->codec_id == AV_CODEC_ID_AAC || par->codec_id == AV_CODEC_ID_H264
!             || par->codec_id == AV_CODEC_ID_MPEG4) {
          int side_size = 0;
          uint8_t *side = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);
          if (side && side_size > 0 && (side_size != par->extradata_size || memcmp(side, par->extradata, side_size))) {
--- 908,920 ----
      if (par->codec_id == AV_CODEC_ID_VP6F || par->codec_id == AV_CODEC_ID_VP6A ||
          par->codec_id == AV_CODEC_ID_VP6  || par->codec_id == AV_CODEC_ID_AAC)
          flags_size = 2;
!     else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4 || par->codec_id == AV_CODEC_ID_HEVC)
          flags_size = 5;
      else
          flags_size = 1;
  
      if (par->codec_id == AV_CODEC_ID_AAC || par->codec_id == AV_CODEC_ID_H264
!             || par->codec_id == AV_CODEC_ID_MPEG4 || par->codec_id == AV_CODEC_ID_HEVC) {
          int side_size = 0;
          uint8_t *side = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);
          if (side && side_size > 0 && (side_size != par->extradata_size || memcmp(side, par->extradata, side_size))) {
***************
*** 966,971 ****
--- 979,988 ----
          if (par->extradata_size > 0 && *(uint8_t*)par->extradata != 1)
              if ((ret = ff_avc_parse_nal_units_buf(pkt->data, &data, &size)) < 0)
                  return ret;
+     } else if (par->codec_id == AV_CODEC_ID_HEVC) {
+         if (par->extradata_size > 0 && *(uint8_t*)par->extradata != 1)
+             if ((ret = ff_hevc_annexb2mp4_buf(pkt->data, &data, &size, 0, NULL)) < 0)
+                 return ret;
      } else if (par->codec_id == AV_CODEC_ID_AAC && pkt->size > 2 &&
                 (AV_RB16(pkt->data) & 0xfff0) == 0xfff0) {
          if (!s->streams[pkt->stream_index]->nb_frames) {
***************
*** 1038,1044 ****
                               (FFALIGN(par->height, 16) - par->height));
          } else if (par->codec_id == AV_CODEC_ID_AAC)
              avio_w8(pb, 1); // AAC raw
!         else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4) {
              avio_w8(pb, 1); // AVC NALU
              avio_wb24(pb, pkt->pts - pkt->dts);
          }
--- 1055,1061 ----
                               (FFALIGN(par->height, 16) - par->height));
          } else if (par->codec_id == AV_CODEC_ID_AAC)
              avio_w8(pb, 1); // AAC raw
!         else if (par->codec_id == AV_CODEC_ID_H264 || par->codec_id == AV_CODEC_ID_MPEG4 || par->codec_id == AV_CODEC_ID_HEVC) {
              avio_w8(pb, 1); // AVC NALU
              avio_wb24(pb, pkt->pts - pkt->dts);
          }
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavformat/flv.h FFmpeg-n4.3.1/libavformat/flv.h
*** base_ffmpeg_n4.3.1/libavformat/flv.h	2022-01-30 21:54:34.388207699 -0800
--- FFmpeg-n4.3.1/libavformat/flv.h	2021-08-09 14:16:17.898194620 -0700
***************
*** 110,115 ****
--- 110,116 ----
      FLV_CODECID_H264    = 7,
      FLV_CODECID_REALH263= 8,
      FLV_CODECID_MPEG4   = 9,
+     FLV_CODECID_HEVC    = 12,
  };
  
  enum {
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavformat/movenc.c FFmpeg-n4.3.1/libavformat/movenc.c
*** base_ffmpeg_n4.3.1/libavformat/movenc.c	2022-01-30 21:54:34.400207871 -0800
--- FFmpeg-n4.3.1/libavformat/movenc.c	2021-09-10 14:46:57.110959896 -0700
***************
*** 5767,5773 ****
      if (trk->par->codec_id == AV_CODEC_ID_MP4ALS ||
              trk->par->codec_id == AV_CODEC_ID_AAC ||
              trk->par->codec_id == AV_CODEC_ID_AV1 ||
!             trk->par->codec_id == AV_CODEC_ID_FLAC) {
          int side_size = 0;
          uint8_t *side = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);
          if (side && side_size > 0 && (side_size != par->extradata_size || memcmp(side, par->extradata, side_size))) {
--- 5767,5775 ----
      if (trk->par->codec_id == AV_CODEC_ID_MP4ALS ||
              trk->par->codec_id == AV_CODEC_ID_AAC ||
              trk->par->codec_id == AV_CODEC_ID_AV1 ||
!             trk->par->codec_id == AV_CODEC_ID_FLAC ||
!             trk->par->codec_id == AV_CODEC_ID_HEVC ||
!             trk->par->codec_id == AV_CODEC_ID_H264) {
          int side_size = 0;
          uint8_t *side = av_packet_get_side_data(pkt, AV_PKT_DATA_NEW_EXTRADATA, &side_size);
          if (side && side_size > 0 && (side_size != par->extradata_size || memcmp(side, par->extradata, side_size))) {
***************
*** 7004,7011 ****
      { AV_CODEC_ID_MPEG4,           MKTAG('m', 'p', '4', 'v') },
      { AV_CODEC_ID_H264,            MKTAG('a', 'v', 'c', '1') },
      { AV_CODEC_ID_H264,            MKTAG('a', 'v', 'c', '3') },
-     { AV_CODEC_ID_HEVC,            MKTAG('h', 'e', 'v', '1') },
      { AV_CODEC_ID_HEVC,            MKTAG('h', 'v', 'c', '1') },
      { AV_CODEC_ID_MPEG2VIDEO,      MKTAG('m', 'p', '4', 'v') },
      { AV_CODEC_ID_MPEG1VIDEO,      MKTAG('m', 'p', '4', 'v') },
      { AV_CODEC_ID_MJPEG,           MKTAG('m', 'p', '4', 'v') },
--- 7006,7013 ----
      { AV_CODEC_ID_MPEG4,           MKTAG('m', 'p', '4', 'v') },
      { AV_CODEC_ID_H264,            MKTAG('a', 'v', 'c', '1') },
      { AV_CODEC_ID_H264,            MKTAG('a', 'v', 'c', '3') },
      { AV_CODEC_ID_HEVC,            MKTAG('h', 'v', 'c', '1') },
+     { AV_CODEC_ID_HEVC,            MKTAG('h', 'e', 'v', '1') },
      { AV_CODEC_ID_MPEG2VIDEO,      MKTAG('m', 'p', '4', 'v') },
      { AV_CODEC_ID_MPEG1VIDEO,      MKTAG('m', 'p', '4', 'v') },
      { AV_CODEC_ID_MJPEG,           MKTAG('m', 'p', '4', 'v') },
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavformat/mpegenc.c FFmpeg-n4.3.1/libavformat/mpegenc.c
*** base_ffmpeg_n4.3.1/libavformat/mpegenc.c	2022-01-30 21:54:34.400207871 -0800
--- FFmpeg-n4.3.1/libavformat/mpegenc.c	2021-08-09 14:16:17.910194688 -0700
***************
*** 423,429 ****
  
              /* This value HAS to be used for VCD (see VCD standard, p. IV-7).
               * Right now it is also used for everything else. */
!             stream->max_buffer_size = 4 * 1024;
              s->audio_bound++;
              break;
          case AVMEDIA_TYPE_VIDEO:
--- 423,429 ----
  
              /* This value HAS to be used for VCD (see VCD standard, p. IV-7).
               * Right now it is also used for everything else. */
!             stream->max_buffer_size = 4 * 1024 * 2; // NETINT: Increase MPG buffers to avoid overflow at higher bitrates
              s->audio_bound++;
              break;
          case AVMEDIA_TYPE_VIDEO:
***************
*** 434,447 ****
  
              props = (AVCPBProperties*)av_stream_get_side_data(st, AV_PKT_DATA_CPB_PROPERTIES, NULL);
              if (props && props->buffer_size)
!                 stream->max_buffer_size = 6 * 1024 + props->buffer_size / 8;
              else {
                  av_log(ctx, AV_LOG_WARNING,
                         "VBV buffer size not set, using default size of 230KB\n"
                         "If you want the mpeg file to be compliant to some specification\n"
                         "Like DVD, VCD or others, make sure you set the correct buffer size\n");
                  // FIXME: this is probably too small as default
!                 stream->max_buffer_size = 230 * 1024;
              }
              if (stream->max_buffer_size > 1024 * 8191) {
                  av_log(ctx, AV_LOG_WARNING, "buffer size %d, too large\n", stream->max_buffer_size);
--- 434,447 ----
  
              props = (AVCPBProperties*)av_stream_get_side_data(st, AV_PKT_DATA_CPB_PROPERTIES, NULL);
              if (props && props->buffer_size)
!                 stream->max_buffer_size = (6 * 1024 + props->buffer_size / 8) * 2; // NETINT: Increase MPG buffers to avoid overflow at higher bitrates
              else {
                  av_log(ctx, AV_LOG_WARNING,
                         "VBV buffer size not set, using default size of 230KB\n"
                         "If you want the mpeg file to be compliant to some specification\n"
                         "Like DVD, VCD or others, make sure you set the correct buffer size\n");
                  // FIXME: this is probably too small as default
!                 stream->max_buffer_size = 230 * 1024 * 2; // NETINT: Increase MPG buffers to avoid overflow at higher bitrates
              }
              if (stream->max_buffer_size > 1024 * 8191) {
                  av_log(ctx, AV_LOG_WARNING, "buffer size %d, too large\n", stream->max_buffer_size);
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavformat/mpegtsenc.c FFmpeg-n4.3.1/libavformat/mpegtsenc.c
*** base_ffmpeg_n4.3.1/libavformat/mpegtsenc.c	2022-01-30 21:54:34.400207871 -0800
--- FFmpeg-n4.3.1/libavformat/mpegtsenc.c	2021-08-09 14:16:17.910194688 -0700
***************
*** 75,80 ****
--- 75,81 ----
      const AVClass *av_class;
      MpegTSSection pat; /* MPEG-2 PAT table */
      MpegTSSection sdt; /* MPEG-2 SDT table context */
+     MpegTSSection scte35; /* MPEG-2 scte35 signaling */ // NETINT: add scte35 type to mpegts muxer as PSI
      MpegTSService **services;
      int64_t sdt_period; /* SDT period in PCR time base */
      int64_t pat_period; /* PAT/PMT period in PCR time base */
***************
*** 111,116 ****
--- 112,123 ----
      int64_t last_pat_ts;
      int64_t last_sdt_ts;
  
+     // NETINT: add scte35 type to mpegts muxer as PSI
+     int64_t last_scte35_ts;
+     int64_t scte35_period_us;
+     int scte35_packet_count;
+     int64_t scte35_period;
+ 
      int omit_video_pes_length;
  } MpegTSWrite;
  
***************
*** 213,218 ****
--- 220,243 ----
      return 0;
  }
  
+ // NETINT: add scte35 type to mpegts muxer as PSI
+ static int mpegts_write_section_scte35(MpegTSSection *s, uint8_t *buf, int len)
+ {
+     uint8_t section[1024], *q;
+     unsigned int tot_len;
+ 
+     tot_len = len;
+     /* check if not too big */
+     if (tot_len > 1024)
+         return AVERROR_INVALIDDATA;
+ 
+     q    = section;
+     memcpy(q, buf, len);
+ 
+     mpegts_write_section(s, section, tot_len);
+     return 0;
+ }
+ 
  /*********************************************/
  /* mpegts writer */
  
***************
*** 349,354 ****
--- 374,383 ----
      case AV_CODEC_ID_TIMED_ID3:
          stream_type = STREAM_TYPE_METADATA;
          break;
+ 	// NETINT: add scte35 type to mpegts muxer as PSI
+     case AV_CODEC_ID_SCTE_35:
+         stream_type = STREAM_TYPE_SCTE_35;
+         break;
      case AV_CODEC_ID_DVB_SUBTITLE:
      case AV_CODEC_ID_DVB_TELETEXT:
          stream_type = STREAM_TYPE_PRIVATE_DATA;
***************
*** 436,441 ****
--- 465,484 ----
      q += 2; /* patched after */
  
      /* put program info here */
+ 	// NETINT: add scte35 type to mpegts muxer as PSI
+     for (i = 0; i < s->nb_streams; i++) {
+         if(s->streams[i]->codecpar->codec_id==AV_CODEC_ID_SCTE_35){
+             *q++ = 0x05; // ANSI SCTE35 descriptor tag
+             *q++ = 0x04; // ANSI SCTE35 descriptor length (4 for CUEI)
+ 
+             *q++ = 0x43; // 'C'
+             *q++ = 0x55; // 'U'
+             *q++ = 0x45; // 'E'
+             *q++ = 0x49; // 'I'
+             break;
+         }
+     }
+ 
      if (ts->m2ts_mode) {
          put_registration_descriptor(&q, MKTAG('H', 'D', 'M', 'V'));
          *q++ = 0x88;        // descriptor_tag - hdmv_copy_control_descriptor
***************
*** 766,771 ****
--- 809,846 ----
                            data, q - data);
  }
  
+ // NETINT: add scte35 type to mpegts muxer as PSI
+ static void mpegts_write_scte35(AVFormatContext *s, int64_t pts, const uint8_t *payload, int payload_size)
+ {
+     MpegTSWrite *ts = s->priv_data;
+     uint8_t payloadSynced[SECTION_LENGTH];
+     uint8_t data[SECTION_LENGTH], *q;
+     if(payload_size > SECTION_LENGTH){
+       av_log(s, AV_LOG_ERROR, "SCTE35 Payload exceeds max section length \n");
+       return;
+     }
+     q = data;
+     memcpy(payloadSynced, payload, payload_size);
+ 
+     // set ffmpeg pts
+     if (payloadSynced[13] == 6){ // scte 35 time signal type = 6
+         payloadSynced[15] = (pts & 0xFF000000) >> 24;
+         payloadSynced[16] = (pts & 0x00FF0000) >> 16;
+         payloadSynced[17] = (pts & 0x0000FF00) >> 8;
+         payloadSynced[18] = (pts & 0x000000FF);
+     }else if (payloadSynced[13] == 5){ // scte 35 splice insert type = 5
+         payloadSynced[21] = (pts & 0xFF000000) >> 24;
+         payloadSynced[22] = (pts & 0x00FF0000) >> 16;
+         payloadSynced[23] = (pts & 0x0000FF00) >> 8;
+         payloadSynced[24] = (pts & 0x000000FF);
+     }else{
+         av_log(s, AV_LOG_ERROR, "SCTE35 signal type not yet supported\n");
+     }
+     memcpy(q, payloadSynced, payload_size);
+     q+=payload_size;
+     mpegts_write_section_scte35(&ts->scte35, data, q - data);
+ }
+ 
  /* This stores a string in buf with the correct encoding and also sets the
   * first byte as the length. !str is accepted for an empty string.
   * If the string is already encoded, invalid UTF-8 or has no multibyte sequence
***************
*** 991,996 ****
--- 1066,1077 ----
      ts->sdt.write_packet = section_write_packet;
      ts->sdt.opaque       = s;
  
+     // NETINT: add scte35 type to mpegts muxer as PSI
+     ts->scte35.cc           = 15;
+     ts->scte35.discontinuity= ts->flags & MPEGTS_FLAG_DISCONT;
+     ts->scte35.write_packet = section_write_packet;
+     ts->scte35.opaque       = s;
+ 
      /* assign pids to each stream */
      for (i = 0; i < s->nb_streams; i++) {
          AVStream *st = s->streams[i];
***************
*** 1109,1114 ****
--- 1190,1196 ----
  
      ts->last_pat_ts = AV_NOPTS_VALUE;
      ts->last_sdt_ts = AV_NOPTS_VALUE;
+     ts->last_scte35_ts = AV_NOPTS_VALUE; // NETINT: add scte35 type to mpegts muxer as PSI
      ts->pat_period = av_rescale(ts->pat_period_us, PCR_TIME_BASE, AV_TIME_BASE);
      ts->sdt_period = av_rescale(ts->sdt_period_us, PCR_TIME_BASE, AV_TIME_BASE);
  
***************
*** 1292,1297 ****
--- 1374,1386 ----
              pcr = (dts - delay) * 300;
  
          retransmit_si_info(s, force_pat, force_sdt, pcr);
+         // NETINT: add scte35 type to mpegts muxer as PSI
+         if(st->codecpar->codec_id == AV_CODEC_ID_SCTE_35){
+           ts->scte35.pid = ts_st->pid;
+           mpegts_write_scte35 (s, pts, payload, payload_size);
+           payload_size = 0;
+           continue;
+         }
          force_pat = 0;
          force_sdt = 0;
  
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavformat/mpegts.h FFmpeg-n4.3.1/libavformat/mpegts.h
*** base_ffmpeg_n4.3.1/libavformat/mpegts.h	2022-01-30 21:54:34.400207871 -0800
--- FFmpeg-n4.3.1/libavformat/mpegts.h	2021-08-09 14:16:17.910194688 -0700
***************
*** 135,140 ****
--- 135,141 ----
  #define STREAM_TYPE_AUDIO_AC3       0x81
  #define STREAM_TYPE_AUDIO_DTS       0x82
  #define STREAM_TYPE_AUDIO_TRUEHD    0x83
+ #define STREAM_TYPE_SCTE_35         0x86 // NETINT: add scte35 type to mpegts muxer as PSI
  #define STREAM_TYPE_AUDIO_EAC3      0x87
  
  typedef struct MpegTSContext MpegTSContext;
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavformat/mux.c FFmpeg-n4.3.1/libavformat/mux.c
*** base_ffmpeg_n4.3.1/libavformat/mux.c	2022-01-30 21:54:34.404207927 -0800
--- FFmpeg-n4.3.1/libavformat/mux.c	2021-08-09 14:16:17.910194688 -0700
***************
*** 916,921 ****
--- 916,923 ----
  {
      AVPacketList *pktl;
      int stream_count = 0;
+     // NETINT: fix scte35 handling in muxing buffer
+     int scte35_count = 0; // scte35 stream count
      int noninterleaved_count = 0;
      int i, ret;
      int eof = flush;
***************
*** 926,933 ****
      }
  
      for (i = 0; i < s->nb_streams; i++) {
!         if (s->streams[i]->last_in_packet_buffer) {
              ++stream_count;
          } else if (s->streams[i]->codecpar->codec_type != AVMEDIA_TYPE_ATTACHMENT &&
                     s->streams[i]->codecpar->codec_id != AV_CODEC_ID_VP8 &&
                     s->streams[i]->codecpar->codec_id != AV_CODEC_ID_VP9) {
--- 928,942 ----
      }
  
      for (i = 0; i < s->nb_streams; i++) {
!         // NETINT: fix scte35 handling in muxing buffer
!         // flush scte35 in muxing buffer like regular AV streams to fix ffmpeg muxing output
!         // stall when scte35 packet DTS has large delta compared to regular AV packet DTS
!         if (s->streams[i]->last_in_packet_buffer || s->streams[i]->codecpar->codec_id == AV_CODEC_ID_SCTE_35) { // treat scte35 like regular AV stream for flush consideration
              ++stream_count;
+             // NETINT: fix scte35 handling in muxing buffer
+             if (s->streams[i]->codecpar->codec_id == AV_CODEC_ID_SCTE_35) { // keep count of scte35 stream to avoid flushing when regular AV streams end
+                 scte35_count++;
+             }
          } else if (s->streams[i]->codecpar->codec_type != AVMEDIA_TYPE_ATTACHMENT &&
                     s->streams[i]->codecpar->codec_id != AV_CODEC_ID_VP8 &&
                     s->streams[i]->codecpar->codec_id != AV_CODEC_ID_VP9) {
***************
*** 1009,1015 ****
          }
      }
  
!     if (stream_count && flush) {
          AVStream *st;
          pktl = s->internal->packet_buffer;
          *out = pktl->pkt;
--- 1018,1026 ----
          }
      }
  
!     // NETINT: fix scte35 handling in muxing buffer
!     // the muxing buffer requires at least one regular AV stream be present during flush, otherwise segfault
!     if (((stream_count - scte35_count) > 0) && flush) { // flush if there are non-scte35 streams present AND it is required
          AVStream *st;
          pktl = s->internal->packet_buffer;
          *out = pktl->pkt;
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavformat/utils.c FFmpeg-n4.3.1/libavformat/utils.c
*** base_ffmpeg_n4.3.1/libavformat/utils.c	2022-01-30 21:54:40.412290411 -0800
--- FFmpeg-n4.3.1/libavformat/utils.c	2021-08-09 14:16:17.918194734 -0700
***************
*** 4573,4579 ****
  #endif
  
          /* default pts setting is MPEG-like */
!         avpriv_set_pts_info(st, 33, 1, 90000);
          /* we set the current DTS to 0 so that formats without any timestamps
           * but durations get some timestamps, formats with some unknown
           * timestamps have their first few packets buffered and the
--- 4573,4579 ----
  #endif
  
          /* default pts setting is MPEG-like */
!         avpriv_set_pts_info(st, 62, 1, 90000);
          /* we set the current DTS to 0 so that formats without any timestamps
           * but durations get some timestamps, formats with some unknown
           * timestamps have their first few packets buffered and the
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavutil/frame.h FFmpeg-n4.3.1/libavutil/frame.h
*** base_ffmpeg_n4.3.1/libavutil/frame.h	2022-01-30 21:54:34.424208213 -0800
--- FFmpeg-n4.3.1/libavutil/frame.h	2021-08-09 14:16:17.934194826 -0700
***************
*** 184,189 ****
--- 184,219 ----
       * Encoding parameters for a video frame, as described by AVVideoEncParams.
       */
      AV_FRAME_DATA_VIDEO_ENC_PARAMS,
+ 
+     // NETINT: custom SEI data
+     /**
+      * This side data takes SEI payload type USER_DATA_UNREGISTERED.
+      * There will be no byte reordering.
+      * Usually this payload would be: 16B UUID + other payload Bytes.
+      */
+     AV_FRAME_DATA_NETINT_UDU_SEI,
+ 
+ 
+     // NETINT: custom SEI data
+     /**
+      * This side data takes SEI payload custom types.
+      * There will be no byte reordering.
+      * Usually this payload would be: 1B Custom SEI type + 16B UUID + other payload Bytes.
+      */
+     AV_FRAME_DATA_NETINT_CUSTOM_SEI,
+ 
+     // NETINT: custom bitrate adjustment
+     /**
+      * This side data takes int32_t type data as payload which indicates the new target bitrate value.
+      */
+     AV_FRAME_DATA_NETINT_BITRATE,
+ 
+     // NETINT: long term reference frame support
+     /**
+      * This side data is a struct of AVNetintLongTermRef that specifies a
+      * frame's support of long term reference frame.
+      */
+     AV_FRAME_DATA_NETINT_LONG_TERM_REF,
  };
  
  enum AVActiveFormatDescription {
***************
*** 268,273 ****
--- 298,317 ----
  } AVRegionOfInterest;
  
  /**
+  * NETINT: Structure describing long term reference frame support.
+  *
+  */
+ typedef struct AVNetintLongTermRef {
+   // A flag for the current picture to be used as a long term reference
+   // picture later at other pictures' encoding
+   uint8_t use_cur_src_as_long_term_pic;
+ 
+   // A flag to use a long term reference picture in DPB when encoding the
+   // current picture
+   uint8_t use_long_term_ref;
+ } AVNetintLongTermRef;
+ 
+ /**
   * This structure describes decoded (raw) audio or video data.
   *
   * AVFrame must be allocated using av_frame_alloc(). Note that this only
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavutil/hwcontext.c FFmpeg-n4.3.1/libavutil/hwcontext.c
*** base_ffmpeg_n4.3.1/libavutil/hwcontext.c	2022-01-30 21:54:34.424208213 -0800
--- FFmpeg-n4.3.1/libavutil/hwcontext.c	2021-11-04 21:55:58.351592756 -0700
***************
*** 50,55 ****
--- 50,58 ----
  #if CONFIG_VAAPI
      &ff_hwcontext_type_vaapi,
  #endif
+ #if CONFIG_NI
+     &ff_hwcontext_type_ni,
+ #endif
  #if CONFIG_VDPAU
      &ff_hwcontext_type_vdpau,
  #endif
***************
*** 72,77 ****
--- 75,81 ----
      [AV_HWDEVICE_TYPE_D3D11VA] = "d3d11va",
      [AV_HWDEVICE_TYPE_OPENCL] = "opencl",
      [AV_HWDEVICE_TYPE_QSV]    = "qsv",
+     [AV_HWDEVICE_TYPE_NI]     = "ni",
      [AV_HWDEVICE_TYPE_VAAPI]  = "vaapi",
      [AV_HWDEVICE_TYPE_VDPAU]  = "vdpau",
      [AV_HWDEVICE_TYPE_VIDEOTOOLBOX] = "videotoolbox",
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavutil/hwcontext.h FFmpeg-n4.3.1/libavutil/hwcontext.h
*** base_ffmpeg_n4.3.1/libavutil/hwcontext.h	2022-01-30 21:54:34.424208213 -0800
--- FFmpeg-n4.3.1/libavutil/hwcontext.h	2021-11-04 21:55:58.351592756 -0700
***************
*** 31,36 ****
--- 31,37 ----
      AV_HWDEVICE_TYPE_VAAPI,
      AV_HWDEVICE_TYPE_DXVA2,
      AV_HWDEVICE_TYPE_QSV,
+     AV_HWDEVICE_TYPE_NI,
      AV_HWDEVICE_TYPE_VIDEOTOOLBOX,
      AV_HWDEVICE_TYPE_D3D11VA,
      AV_HWDEVICE_TYPE_DRM,
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavutil/hwcontext_internal.h FFmpeg-n4.3.1/libavutil/hwcontext_internal.h
*** base_ffmpeg_n4.3.1/libavutil/hwcontext_internal.h	2022-01-30 21:54:34.428208269 -0800
--- FFmpeg-n4.3.1/libavutil/hwcontext_internal.h	2021-11-04 21:55:58.351592756 -0700
***************
*** 169,174 ****
--- 169,175 ----
  extern const HWContextType ff_hwcontext_type_dxva2;
  extern const HWContextType ff_hwcontext_type_opencl;
  extern const HWContextType ff_hwcontext_type_qsv;
+ extern const HWContextType ff_hwcontext_type_ni;
  extern const HWContextType ff_hwcontext_type_vaapi;
  extern const HWContextType ff_hwcontext_type_vdpau;
  extern const HWContextType ff_hwcontext_type_videotoolbox;
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavutil/hwcontext_ni.c FFmpeg-n4.3.1/libavutil/hwcontext_ni.c
*** base_ffmpeg_n4.3.1/libavutil/hwcontext_ni.c	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavutil/hwcontext_ni.c	2021-12-21 15:39:35.010154336 -0800
***************
*** 0 ****
--- 1,904 ----
+ /*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+ 
+ #include "config.h"
+ 
+ #include <fcntl.h>
+ #if HAVE_UNISTD_H
+ #   include <unistd.h>
+ #endif
+ 
+ 
+ #include "avassert.h"
+ #include "buffer.h"
+ #include "common.h"
+ #include "hwcontext.h"
+ #include "hwcontext_internal.h"
+ #include "hwcontext_ni.h"
+ #include "libavutil/imgutils.h"
+ #include "mem.h"
+ #include "pixdesc.h"
+ #include "pixfmt.h"
+ #include "ni_util.h"
+ 
+ static enum AVPixelFormat supported_pixel_formats[] = {
+   AV_PIX_FMT_YUV420P,
+   AV_PIX_FMT_YUV420P10BE,
+   AV_PIX_FMT_YUV420P10LE
+ };
+ 
+ typedef struct NIDeviceContext {
+   ni_device_handle_t  handle;
+ } NIDeviceContext;
+ 
+ static inline void ni_buffer_free(void *opaque, uint8_t *data)
+ {
+   ni_aligned_free(data);
+ }
+ 
+ static inline void ni_frame_free(void *opaque, uint8_t *data)
+ {
+   av_log(NULL, AV_LOG_VERBOSE, "ni_frame_free\n");
+   if (data)
+   {
+     ni_session_context_t *p_ctx = (ni_session_context_t *) opaque;
+     ni_hwframe_surface_t* p_data3 = (ni_hwframe_surface_t *) data; //assuming for hwframes there is no data0,1,2?
+     //TODO use int32t device_handle to kill the buffer!
+     av_log(NULL, AV_LOG_VERBOSE, "ni_frame_free:%d, %p\n", p_data3->i8FrameIdx, data);
+     if (p_data3->i8FrameIdx != NI_INVALID_HW_FRAME_IDX)
+     {
+ #ifdef _WIN32
+       int64_t handle = (((int64_t) p_data3->device_handle_ext) << 32) | p_data3->device_handle;
+       ni_decode_buffer_free(p_data3, (ni_device_handle_t) handle, p_ctx->event_handle);
+ #else
+       ni_decode_buffer_free(p_data3, (ni_device_handle_t) p_data3->device_handle, p_ctx->event_handle);
+ #endif
+     }
+     free(data);
+   }
+ }
+ 
+ static int ni_device_create(AVHWDeviceContext *ctx,
+                             const char *device,
+                             AVDictionary *opts,
+                             int flags)
+ {
+   AVNIDeviceContext *ni_ctx;
+   int ret = 0;
+ 
+   av_log(ctx, AV_LOG_VERBOSE, "ni_device_create %s\n", device);
+ 
+   ni_ctx = (AVNIDeviceContext *) ctx->hwctx;
+   ni_ctx->device_idx = (int) NI_INVALID_DEVICE_HANDLE;
+   if (device)
+   {
+     ni_ctx->device_idx = atoi(device);
+     if (ni_ctx->device_idx < 0)
+     {
+       av_log(ctx, AV_LOG_ERROR, "ni_device_create(): error device index = %d\n",
+              ni_ctx->device_idx);
+       return AVERROR(EINVAL);
+     }
+   }
+ 
+   return ret;
+ }
+ 
+ static int ni_frames_get_constraints(AVHWDeviceContext *ctx,
+                                      const void *hwconfig,
+                                      AVHWFramesConstraints *constraints)
+ {
+   int i;
+ 
+   int num_pix_fmts_supported;
+ 
+   num_pix_fmts_supported = FF_ARRAY_ELEMS(supported_pixel_formats);
+ 
+   constraints->valid_sw_formats = av_malloc_array(num_pix_fmts_supported + 1,
+                                   sizeof(*constraints->valid_sw_formats));
+ 
+   if (!constraints->valid_sw_formats)
+     return AVERROR(ENOMEM);
+ 
+   for (i = 0; i < num_pix_fmts_supported; i++)
+     constraints->valid_sw_formats[i] = supported_pixel_formats[i];
+ 
+   constraints->valid_sw_formats[num_pix_fmts_supported] = AV_PIX_FMT_NONE;
+ 
+   constraints->valid_hw_formats = av_malloc_array(2, sizeof(*constraints->valid_hw_formats));
+ 
+   if (!constraints->valid_hw_formats)
+     return AVERROR(ENOMEM);
+ 
+   constraints->valid_hw_formats[0] = AV_PIX_FMT_NI;
+   constraints->valid_hw_formats[1] = AV_PIX_FMT_NONE;
+ 
+   return 0;
+ }
+ 
+ static int ni_get_buffer(AVHWFramesContext *ctx, AVFrame *frame)
+ {
+   int ret = 0, buf_size;
+   uint8_t *buf;
+   ni_frame_t *xfme;
+   NIFramesContext *ni_ctx = ctx->internal->priv;
+   ni_session_data_io_t dst_session_io_data = { 0 };
+   ni_session_data_io_t * p_dst_session_data = &dst_session_io_data;
+ 
+   av_log(ctx, AV_LOG_TRACE, "ni_get_buffer() enter\n");
+ 
+   //alloc dest avframe buff
+   ret = ni_frame_buffer_alloc(&(p_dst_session_data->data.frame),
+                               ctx->width,
+                               ctx->height,
+                               0,
+                               1, //codec type does not matter, metadata exists
+                               ni_ctx->api_ctx.bit_depth_factor,
+                               1);
+   if (ret != 0)
+     return AVERROR(ENOMEM);
+ 
+   xfme = &(p_dst_session_data->data.frame);
+   buf_size = xfme->data_len[0] + xfme->data_len[1] + xfme->data_len[2] + xfme->data_len[3];
+   buf = xfme->p_data[0];
+   memset(buf, 0, buf_size);
+   frame->buf[0] = av_buffer_create(buf, buf_size, ni_frame_free, &ni_ctx->api_ctx, 0);
+   buf = frame->buf[0]->data;
+   if (!frame->buf[0])
+     return AVERROR(ENOMEM);
+ 
+   // init AVFrame
+   frame->data[3] = (uint8_t*) xfme->p_buffer + xfme->data_len[0] + xfme->data_len[1] + xfme->data_len[2];
+   ((ni_hwframe_surface_t *)frame->data[3])->i8FrameIdx = NI_INVALID_HW_FRAME_IDX;
+   frame->format = AV_PIX_FMT_NI;
+   frame->width = ctx->width;
+   frame->height = ctx->height;
+   av_log(ctx, AV_LOG_TRACE, "ni_get_buffer() exit\n");
+ 
+   return 0;
+ }
+ 
+ static int ni_transfer_get_formats(AVHWFramesContext *ctx,
+                                    enum AVHWFrameTransferDirection dir,
+                                    enum AVPixelFormat **formats)
+ {
+   enum AVPixelFormat *fmts;
+ 
+   fmts = av_malloc_array(2, sizeof(*fmts));
+   if (!fmts)
+     return AVERROR(ENOMEM);
+ 
+   fmts[0] = ctx->sw_format;
+   fmts[1] = AV_PIX_FMT_NONE;
+ 
+   *formats = fmts;
+ 
+   return 0;
+ }
+ 
+ static void ni_frames_uninit(AVHWFramesContext *ctx)
+ {
+   NIFramesContext *s = ctx->internal->priv;
+   NIFramesContext *ni_ctx = ctx->internal->priv;
+   AVNIDeviceContext * ni_dev_ctx = ctx->device_ctx->hwctx;
+   int dev_idx = ni_dev_ctx->device_idx; //Supplied by init_hw_device ni=<name>:<id>
+ 
+   av_log(ctx, AV_LOG_TRACE, "ni_frames_uninit() :only close if upload instance, poolsize=%d devid=%d\n",
+          ctx->initial_pool_size, dev_idx);
+   if (dev_idx != -1)
+   {
+     av_log(ctx, AV_LOG_VERBOSE, "SessionID = %d!\n", ni_ctx->api_ctx.session_id);
+     if (ni_ctx->api_ctx.session_id != 0) //assume 0 in invalid ID
+     {
+       ni_device_session_close(&ni_ctx->api_ctx, 1, NI_DEVICE_TYPE_UPLOAD);
+     }
+     //only upload frames init allocates these ones
+     av_freep(&s->surface_ptrs);
+     av_freep(&s->surfaces_internal);
+     av_freep(&s->rsrc_ctx);
+   }
+ 
+   if (ni_ctx->src_session_io_data)
+   {
+     if (ni_ctx->src_session_io_data->data.frame.p_buffer)
+     {
+       av_log(ctx, AV_LOG_TRACE, "ni_frames_uninit free p_buffer\n");
+       ni_frame_buffer_free(&ni_ctx->src_session_io_data->data.frame);
+     }
+     av_freep(&ni_ctx->src_session_io_data);
+   }
+ 
+   if (ni_ctx->suspended_device_handle != NI_INVALID_DEVICE_HANDLE)
+   {
+     av_log(ctx, AV_LOG_TRACE, "ni_frames_uninit(): close suspended device "
+ 	   "handle, =%" SIZE_SPECIFIER "\n",
+ 	   (int64_t) ni_ctx->suspended_device_handle);
+     ni_device_close(ni_ctx->suspended_device_handle);
+   }
+ 
+   av_freep(&s->api_ctx); //usually cleaned out differently in decoder but let's see
+ }
+ 
+ static AVBufferRef *ni_pool_alloc(void *opaque, int size)
+ {
+   AVHWFramesContext    *ctx = (AVHWFramesContext*)opaque;
+   NIFramesContext       *s = ctx->internal->priv;
+   AVNIFramesContext *frames_hwctx = ctx->hwctx;
+ 
+   if (s->nb_surfaces_used < frames_hwctx->nb_surfaces) {
+     s->nb_surfaces_used++;
+     return av_buffer_create((uint8_t*)(s->surfaces_internal + s->nb_surfaces_used - 1),
+                             sizeof(*frames_hwctx->surfaces), NULL, NULL, 0);
+   }
+ 
+   return NULL;
+ }
+ 
+ static int ni_init_surface(AVHWFramesContext *ctx, ni_hwframe_surface_t *surf)
+ {
+   /* Fill with dummy values. This data is never used. */
+   surf->i8FrameIdx        = NI_INVALID_HW_FRAME_IDX;
+   surf->i8InstID          = 0;
+   surf->ui16SessionID     = NI_INVALID_SESSION_ID;
+   surf->device_handle     = NI_INVALID_DEVICE_HANDLE;
+   surf->device_handle_ext = NI_INVALID_DEVICE_HANDLE;
+   surf->bit_depth         = 0;
+   surf->encoding_type     = 0;
+   surf->seq_change        = 0;
+ 
+   return 0;
+ }
+ 
+ static int ni_init_pool(AVHWFramesContext *ctx)
+ {
+   NIFramesContext              *s = ctx->internal->priv; //NI
+   AVNIFramesContext *frames_hwctx = ctx->hwctx;          //NI
+ 
+   int i, ret = 0;
+ 
+   av_log(ctx, AV_LOG_VERBOSE, "ni_init_pool() enter, pool_size=%d\n", ctx->initial_pool_size);
+   if (ctx->initial_pool_size <= 0) {
+     av_log(ctx, AV_LOG_ERROR, "ni_init_pool(): NI requires a fixed frame pool size\n");
+     return AVERROR(EINVAL);
+   }
+ 
+   s->surfaces_internal = av_mallocz_array(ctx->initial_pool_size,
+                                           sizeof(*s->surfaces_internal));
+   if (!s->surfaces_internal)
+     return AVERROR(ENOMEM);
+ 
+   for (i = 0; i < ctx->initial_pool_size; i++) {
+     ret = ni_init_surface(ctx, &s->surfaces_internal[i]);
+     if (ret < 0)
+       return ret;
+   }
+ 
+   ctx->internal->pool_internal = av_buffer_pool_init2(sizeof(ni_hwframe_surface_t),
+                                                       ctx, ni_pool_alloc, NULL);
+   if (!ctx->internal->pool_internal)
+     return AVERROR(ENOMEM);
+ 
+   frames_hwctx->surfaces = s->surfaces_internal;
+   frames_hwctx->nb_surfaces = ctx->initial_pool_size;
+ 
+   return 0;
+ }
+ 
+ static int ni_init_internal_session(AVHWFramesContext *ctx)
+ {
+   NIFramesContext *s = ctx->internal->priv;
+   ni_session_context_t *p_ctx = &s->api_ctx;
+ 
+   ni_device_session_context_init(p_ctx);
+ 
+ #ifdef _WIN32
+   p_ctx->event_handle = ni_create_event();
+   if (p_ctx->event_handle == NI_INVALID_EVENT_HANDLE)
+   {
+     return AVERROR(EINVAL);
+   }
+ 
+   p_ctx->thread_event_handle = ni_create_event();
+   if (p_ctx->thread_event_handle == NI_INVALID_EVENT_HANDLE)
+   {
+     return AVERROR(EINVAL);
+   }
+ #endif
+ 
+   return 0;
+ }
+ 
+ // hwupload runs this on hwupload_config_output
+ static int ni_frames_init(AVHWFramesContext *ctx)
+ {
+   NIFramesContext *ni_ctx = ctx->internal->priv;
+   AVNIDeviceContext *device_hwctx = (AVNIDeviceContext *) ctx->device_ctx->hwctx;
+   int dev_idx = device_hwctx->device_idx;
+   int linesize_aligned,height_aligned;
+   int pool_size,ret;
+   ni_log_set_level(ff_to_ni_log_level(av_log_get_level()));
+ 
+   av_log(ctx, AV_LOG_VERBOSE, "ni_frames_init() enter, supplied poolsize = %d, dev_idx=%d\n",
+          ctx->initial_pool_size, dev_idx);
+   
+   ni_ctx->suspended_device_handle = NI_INVALID_DEVICE_HANDLE;
+   pool_size = ctx->initial_pool_size;
+   if (dev_idx == -1)
+   {
+     if (pool_size != -1) // ffmpeg does not sepcify init_hw_device for decoder - so decoder dev_dec_idx is always -1
+     {
+       av_log(ctx, AV_LOG_ERROR, "ni_frames_init(): No device selected!\n");
+       return AVERROR(EINVAL);
+     }
+   }
+ 
+   ret = ni_init_internal_session(ctx);
+   if (ret < 0)
+   {
+     return ret;
+   }
+   
+   if (pool_size == -1) // decoder returns here
+   {
+     // Init event handler for decoder since it does not invoke
+     // ni_device_session_open here but the event handler is necessary for
+     // Windows event handle.
+     av_log(ctx, AV_LOG_VERBOSE, "ni_frames_init(): Invalid poolsize, assumed decoder mode\n");
+     return ret;
+   }
+   else if (pool_size == 0)
+   {
+     uint32_t pixel_area = ctx->width * ctx->height * (1 + (AV_PIX_FMT_YUV420P10BE == ctx->sw_format)
+                          + (AV_PIX_FMT_YUV420P10LE == ctx->sw_format));
+     if (pixel_area < NI_NUM_OF_PIXELS_720P)
+     {
+       pool_size = ctx->initial_pool_size = 22;
+     }
+     else
+     {
+       pool_size = ctx->initial_pool_size = 20;
+     }
+ 
+     av_log(ctx, AV_LOG_VERBOSE, "ni_frames_init(): Pool_size autoset to %d\n", pool_size);
+   }
+ 
+   linesize_aligned = ((ctx->width + 31) / 32) * 32;
+   if (linesize_aligned < NI_MIN_WIDTH)
+   {
+     linesize_aligned = NI_MIN_WIDTH;
+   }
+ 
+   ctx->width = linesize_aligned;
+ 
+   height_aligned = ((ctx->height + 15) / 16) * 16;
+   if (height_aligned < NI_MIN_HEIGHT)
+   {
+     ctx->height = NI_MIN_HEIGHT;
+     height_aligned = NI_MIN_HEIGHT;
+   }
+   else if (height_aligned > ctx->height)
+   {
+     ctx->height = height_aligned;
+   }
+ 
+   ni_ctx->api_ctx.active_video_width = ctx->width;
+   ni_ctx->api_ctx.active_video_height = ctx->height;
+ 
+   switch (ctx->sw_format)
+   {
+     case AV_PIX_FMT_YUV420P:
+       ni_ctx->api_ctx.bit_depth_factor = 1;
+       ni_ctx->api_ctx.src_bit_depth = 8;
+       ni_ctx->api_ctx.pixel_format = NI_PIX_FMT_YUV420P;
+       break;
+     case AV_PIX_FMT_YUV420P10LE:
+       ni_ctx->api_ctx.bit_depth_factor = 2;
+       ni_ctx->api_ctx.src_bit_depth = 10;
+       ni_ctx->api_ctx.src_endian = NI_FRAME_LITTLE_ENDIAN;
+       ni_ctx->api_ctx.pixel_format = NI_PIX_FMT_YUV420P10LE;
+       break;
+     default:
+       return AVERROR(EINVAL);
+   }
+ 
+   if (ctx->width > NI_MAX_RESOLUTION_WIDTH ||
+       ctx->height > NI_MAX_RESOLUTION_HEIGHT ||
+       ctx->width * ctx->height > NI_MAX_RESOLUTION_AREA)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_frames_init(): Error XCoder resolution %dx%d not supported\n",
+            ctx->width, ctx->height);
+     av_log(ctx, AV_LOG_ERROR, "Max Supported Width: %d Height %d Area %d\n",
+            NI_MAX_RESOLUTION_WIDTH, NI_MAX_RESOLUTION_HEIGHT, NI_MAX_RESOLUTION_AREA);
+     return AVERROR_EXTERNAL;
+   }
+   else if (dev_idx >= 0)
+   {
+     /* allocate based on what user specifies */
+     if ((ni_ctx->rsrc_ctx = ni_rsrc_allocate_simple_direct(NI_DEVICE_TYPE_DECODER, dev_idx)) == NULL)
+     {
+       av_log(ctx, AV_LOG_ERROR, "ni_frames_init(): Error XCoder resource allocation: inst %d not available!\n",
+              dev_idx);
+       return AVERROR_EXTERNAL;
+     }
+   }
+   else
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_frames_init(): Error XCoder command line options");
+     return AVERROR(EINVAL);
+   }
+ 
+   av_log(ctx, AV_LOG_VERBOSE, "ni_frames_init(): pixel sw_format=%d width = %d height = %d outformat=%d\n",
+          ctx->sw_format, ctx->width, ctx->height, ctx->format);
+ 
+   ni_ctx->api_ctx.hw_id = dev_idx;
+   ret = ni_device_session_open(&ni_ctx->api_ctx, NI_DEVICE_TYPE_UPLOAD);
+   if (ret < 0)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_frames_init(): Error Something wrong in xcoder open\n");
+     ni_frames_uninit(ctx);
+     return AVERROR_EXTERNAL;
+   }
+   else
+   {
+     av_log(ctx, AV_LOG_VERBOSE, "ni_frames_init(): XCoder %s.%d (inst: %d) opened successfully\n",
+            ni_ctx->rsrc_ctx->p_device_info->dev_name, dev_idx, ni_ctx->api_ctx.session_id);
+   }
+ 
+   ret = ni_device_session_init_framepool(&ni_ctx->api_ctx, pool_size);
+   if (ret < 0)
+   {
+     return ret;
+   }
+ 
+   // init src_session_io_data
+   ni_ctx->src_session_io_data =  malloc(sizeof(ni_session_data_io_t));
+   if(!ni_ctx->src_session_io_data)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_frames_init(): Error alloc src_session_io_data memory\n");
+     return AVERROR(ENOMEM);
+   }
+   memset(ni_ctx->src_session_io_data, 0, sizeof(ni_session_data_io_t));
+   ni_ctx->src_session_io_data->data.frame.extra_data_len = NI_APP_ENC_FRAME_META_DATA_SIZE;
+ 
+   if (!ctx->pool) {
+     ret = ni_init_pool(ctx);
+     if (ret < 0) {
+       av_log(ctx, AV_LOG_ERROR, "ni_frames_init(): Error creating an internal frame pool\n");
+       return ret;
+     }
+   }
+   return 0;
+ }
+ 
+ /*!******************************************************************************
+ *  \brief  Download frame from the NI devices
+ *
+ *  \param[in]   ctx    FFmpeg hardware frames context
+ *  \param[in]   dst    input hardware frames, fmt AV_PIX_FMT_NI.
+ *  \param[out]  src    output frames, fmt YUV420P, etc.
+ *
+ *  \return On success    0
+ *          On failure    <0
+ *******************************************************************************/
+ static int ni_hwdl_frame(AVHWFramesContext *ctx, AVFrame *dst, const AVFrame *src)
+ {
+   int ret = 0, buf_size;
+   uint8_t *buf;
+   ni_frame_t *xfme;
+   NIFramesContext *ni_ctx = ctx->internal->priv;
+   ni_session_data_io_t session_io_data = { 0 };
+   ni_session_data_io_t * p_session_data = &session_io_data;
+ 
+   ni_hwframe_surface_t* src_surf = (ni_hwframe_surface_t*) src->data[3];
+   av_log(ctx, AV_LOG_VERBOSE, "ni_hwdl_frame(): dev_handle=%" SIZE_SPECIFIER ""
+ 	 ", FrameIdx=%d, SessionID=%d\n",
+          src_surf->device_handle,
+          src_surf->i8FrameIdx,
+          src_surf->ui16SessionID);
+ 
+   av_log(ctx, AV_LOG_DEBUG, "ni_hwdl_frame(): processed width=%d, height=%d\n",
+          src->width, src->height);
+ 
+   ret = ni_frame_buffer_alloc(&(p_session_data->data.frame),
+                               ni_ctx->pc_width, ni_ctx->pc_height,
+                               src_surf->encoding_type == NI_CODEC_FORMAT_H264,
+                               1,
+                               src_surf->bit_depth,
+                               0);
+   
+   if (NI_RETCODE_SUCCESS != ret)
+   {
+     return AVERROR_EXTERNAL;
+   }
+ 
+   ret = ni_device_session_hwdl(&ni_ctx->api_ctx, p_session_data, src_surf);
+   if (ret <= 0)
+   {
+     av_log(ctx, AV_LOG_DEBUG, "ni_hwdl_frame(): failed to retrieve frame\n");
+     return AVERROR_EXTERNAL;
+   }
+ 
+   xfme = &(p_session_data->data.frame);
+   buf_size = xfme->data_len[0] + xfme->data_len[1] + xfme->data_len[2];
+   buf = xfme->p_data[0];
+     
+   dst->buf[0] = av_buffer_create(buf, buf_size, ni_buffer_free, NULL, 0);
+   buf = dst->buf[0]->data;
+   if (!dst->buf[0])
+     return AVERROR(ENOMEM);
+ 
+   av_log(ctx, AV_LOG_DEBUG, "ni_hwdl_frame(): fill array, linesize[0]=%d, fmt=%d, width=%d, height=%d\n",
+          dst->linesize[0], ctx->sw_format, ni_ctx->pc_width, ni_ctx->pc_height);
+   if ((ret = av_image_fill_arrays(dst->data, dst->linesize,
+        buf, ctx->sw_format,
+        ni_ctx->pc_width,
+        ni_ctx->pc_height, 1)) < 0)
+   {
+     av_buffer_unref(&dst->buf[0]);
+     return ret;
+   }
+ 
+   dst->format = ctx->sw_format;
+   dst->width = ni_ctx->pc_width;
+   dst->height = ni_ctx->pc_height;
+   dst->crop_bottom = ni_ctx->pc_crop_bottom;
+   dst->crop_right = ni_ctx->pc_crop_right;
+ 
+   av_log(ctx, AV_LOG_DEBUG, "dst crop right %" SIZE_SPECIFIER " bot "
+ 	 "%" SIZE_SPECIFIER " width %d height %d\n",
+          dst->crop_right,
+          dst->crop_bottom,
+          dst->width,
+          dst->height);
+   av_frame_apply_cropping(dst, 0); //0 for simplicity
+   av_log(ctx, AV_LOG_DEBUG, "POST dst crop right %" SIZE_SPECIFIER " bot"
+ 	 "%" SIZE_SPECIFIER " width %d height %d\n",
+          dst->crop_right,
+          dst->crop_bottom,
+          dst->width,
+          dst->height);
+   av_frame_copy_props(dst, src);//should about get the metadata right
+   dst->format = ctx->sw_format;
+ 
+   av_log(ctx, AV_LOG_VERBOSE, "ni_hwdl_frame: frame->width=%d, frame->height=%d, "
+          "crop top %" SIZE_SPECIFIER " bottom %" SIZE_SPECIFIER " "
+          "left %" SIZE_SPECIFIER " right %" SIZE_SPECIFIER ", "
+          "frame->format=%d, frame->linesize=%d/%d/%d\n",
+          dst->width, dst->height,
+          dst->crop_top, dst->crop_bottom,
+          dst->crop_left, dst->crop_right,
+          dst->format, dst->linesize[0], dst->linesize[1], dst->linesize[2]);
+ 
+   return ret;
+ }
+ 
+ /*!******************************************************************************
+ *  \brief  Upload frame to the NI devices
+ *
+ *  \param[in]   ctx    FFmpeg hardware frames context
+ *  \param[in]   dst    input frames, fmt YUV420P, etc.
+ *  \param[out]  src    output hardware frames, fmt AV_PIX_FMT_NI.
+ *
+ *  \return On success    0
+ *          On failure    <0
+ *******************************************************************************/
+ static int ni_hwup_frame(AVHWFramesContext *ctx, AVFrame *dst, const AVFrame *src)
+ {
+   NIFramesContext *ni_ctx = ctx->internal->priv;
+   int ret = 0;
+   int dst_stride[4],plane_height[4];
+   int height_aligned[4]; //HEIGHT padding for enc
+   int padding_height;
+   int pixel_format;
+   int i,nb_planes=0;
+   const AVPixFmtDescriptor *desc;
+   ni_session_data_io_t * p_src_session_data = ni_ctx->src_session_io_data;
+   ni_hwframe_surface_t* dst_surf = (ni_hwframe_surface_t*)dst->data[3];
+ 
+   av_log(ctx, AV_LOG_VERBOSE, "ni_hwup_frame() enter\n");
+   if (!src)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_hwup_frame(): Src frame is empty! eof?\n");
+   }
+ 
+   if (ret < 0)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_hwup_frame(): failed to allocate surf\n");
+     return AVERROR_EXTERNAL;
+   }
+ 
+ 
+   //alloc src avframe buff--------------
+   switch (src->format)
+   {
+     case AV_PIX_FMT_YUV420P:
+     case AV_PIX_FMT_YUV420P10LE:
+       if (src->width < NI_MIN_WIDTH)
+       {
+         dst_stride[0] = FFALIGN(NI_MIN_WIDTH, 32) * ni_ctx->api_ctx.bit_depth_factor;
+       }
+       else
+       {
+         dst_stride[0] = FFALIGN(src->width,32) * ni_ctx->api_ctx.bit_depth_factor;
+       }
+       dst_stride[1] = dst_stride[2] = dst_stride[0]/2;
+       height_aligned[0] = ((src->height + 7) / 8) * 8;
+       if (1){//avctx->codec_id == AV_CODEC_ID_H264) {
+           height_aligned[0] = ((src->height + 15) / 16) * 16; //force to this for max compat
+       }
+       if (height_aligned[0] < NI_MIN_HEIGHT)
+       {
+           height_aligned[0] = NI_MIN_HEIGHT;
+       }
+       height_aligned[1] = height_aligned[2] = height_aligned[0] / 2;
+       break;
+     default:
+       av_log(ctx, AV_LOG_ERROR, "ni_hwup_frame(): Error Pixel format %s not supported by device %s\n",
+              av_get_pix_fmt_name(src->format),ctx->internal->hw_type->name);
+       return AVERROR(EINVAL);
+   }
+ 
+   switch (ctx->sw_format)
+   {
+     case AV_PIX_FMT_YUV420P:
+       pixel_format = NI_PIX_FMT_YUV420P;
+       break;
+     case AV_PIX_FMT_YUV420P10LE:
+       pixel_format = NI_PIX_FMT_YUV420P10LE;
+       break;
+     default:
+       av_log(ctx, AV_LOG_ERROR, "ni_hwup_frame(): Error Pixel format %s not supported by devices %s\n",
+              av_get_pix_fmt_name(src->format),ctx->internal->hw_type->name);
+       return AVERROR(EINVAL);
+   }
+ 
+   ret = ni_frame_buffer_alloc_v4(&(p_src_session_data->data.frame),
+     pixel_format, src->width, src->height, dst_stride,
+     1,
+     p_src_session_data->data.frame.extra_data_len);
+ 
+   if (ret < 0)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_hwup_frame(): Error Cannot allocate ni_frame %d\n", ret);
+     return ret;
+   }
+ 
+   if (!p_src_session_data->data.frame.p_data[0])
+   {
+     return AVERROR(ENOMEM);
+   }
+ 
+   switch (src->format)
+   {
+     case AV_PIX_FMT_YUV420P:
+     case AV_PIX_FMT_YUV420P10LE:
+       plane_height[0] = src->height;
+       plane_height[1] = src->height / 2;
+       plane_height[2] = src->height / 2;
+       plane_height[3] = 0;
+       break;
+     default:
+       av_log(ctx, AV_LOG_ERROR, "ni_hwup_frame(): Error Pixel format %s not supported by device %s\n",
+              av_get_pix_fmt_name(src->format),ctx->internal->hw_type->name);
+       return AVERROR(EINVAL);
+   }
+ 
+   desc = av_pix_fmt_desc_get(src->format);
+   for (i = 0; i < desc->nb_components; i++)
+   {
+     nb_planes = FFMAX(desc->comp[i].plane, nb_planes);
+   }
+   nb_planes++;
+ 
+   av_log(ctx, AV_LOG_TRACE, "ni_hwup_frame: src linesize = %d/%d/%d "
+          "dst alloc linesize = %d/%d/%d  height = %d/%d/%d\n",
+          src->linesize[0], src->linesize[1], src->linesize[2],
+          dst_stride[0], dst_stride[1], dst_stride[2],
+          plane_height[0], plane_height[1], plane_height[2]);
+ 
+   for (i = 0; i < nb_planes; i++)
+   {
+     int height = plane_height[i];
+     uint8_t *dest = p_src_session_data->data.frame.p_data[i];
+     const uint8_t *srce = (const uint8_t *)src->data[i];
+     for (; height > 0; height--)
+     {
+       memcpy(dest, srce, FFMIN(src->linesize[i], dst_stride[i]));
+       dest += dst_stride[i];      
+       srce += src->linesize[i];
+     }
+ 
+     // height padding if needed
+     switch (src->format)
+     {
+       case AV_PIX_FMT_YUV420P:
+       case AV_PIX_FMT_YUV420P10LE:
+         /*
+          * TODO: This should probably be removed for Quadra. NI_MIN_HEIGHT == 128
+          *       is smaller than what Quadra can support. This looks like a T408
+          *       requirement.
+          */
+         padding_height = height_aligned[i] - plane_height[i];
+         break;
+       default:
+         av_log(ctx, AV_LOG_ERROR, "ni_hwup_frame(): Error Pixel format %s not supported by device %s\n",
+                av_get_pix_fmt_name(src->format),ctx->internal->hw_type->name);
+         return AVERROR(EINVAL);
+     }
+ 
+     if (padding_height > 0)
+     {
+       av_log(ctx, AV_LOG_TRACE, "ni_hwup_frame(): plane %d padding %d\n",
+              i, padding_height);
+ 
+       srce = dest - dst_stride[i];
+       for (; padding_height > 0; padding_height--) {
+         memcpy(dest, srce, dst_stride[i]);
+         dest += dst_stride[i];
+       }
+     }
+   }
+ 
+   ret = ni_device_session_hwup(&ni_ctx->api_ctx, p_src_session_data, dst_surf);
+   if (ret < 0)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_hwup_frame(): failed to upload frame\n");
+     return AVERROR_EXTERNAL;
+   }
+ 
+   if (!dst->hw_frames_ctx)
+   {
+     dst->hw_frames_ctx = av_hwframe_ctx_alloc(ctx->device_ref);
+     //((AVHWFramesContext*)dst->hw_frames_ctx->data)->format = AV_PIX_FMT_NI_QUAD;
+   }
+   av_log(ctx, AV_LOG_DEBUG, "ni_hwup_frame(): Assigning hw_frames_ctx\n");
+   ((AVHWFramesContext*)dst->hw_frames_ctx->data)->internal->priv = ni_ctx;
+ 
+   //set additional info to hwdesc
+   dst_surf->ui16width = src->width;
+   dst_surf->ui16height = src->height;
+   //dst_surf->ui32nodeAddress = 0; //always 0 offset for upload
+   //dst_surf->encoding_type = NI_PIXEL_PLANAR_FORMAT_PLANAR;
+   ////Update frames context
+   //ctx->f[0] = dst_surf->encoding_type;
+ 
+   av_log(ctx, AV_LOG_VERBOSE, "ni_hwup_frame(): dev_handle=%" SIZE_SPECIFIER ""
+ 	 ", FrameIdx=%d, SessionID=%d\n",
+          dst_surf->device_handle,
+          dst_surf->i8FrameIdx,
+          dst_surf->ui16SessionID);
+   //Update frames context
+   //ctx->split_ctx.f[0] = dst_surf->encoding_type;
+ 
+   //av_log(ctx, AV_LOG_INFO, "original height width %d/%d, processed h/w = %d/%d\n",
+   //    ctx->pc_height, ctx->pc_width, src->height, src->width);
+   //
+   //ret = ni_frame_buffer_alloc(&(p_session_data->data.frame), ctx->pc_width, ctx->pc_height,
+   //    src_surf->encoding_type, 1,
+   //    src_surf->bit_depth,
+   //    false);
+   if (NI_RETCODE_SUCCESS != ret)
+   {
+     return AVERROR_EXTERNAL;
+   }
+ 
+   av_frame_copy_props(dst, src);//should about get the metadata right
+ 
+   av_log(ctx, AV_LOG_DEBUG, "ni_hwup_frame(): Upload frame w/h "
+ 	 "%d/%d crop r/b %" SIZE_SPECIFIER "/%" SIZE_SPECIFIER "\n",
+ 	 dst->width, dst->height, dst->crop_right, dst->crop_bottom);
+ 
+   return ret;
+ 
+ }
+ 
+ static int ni_transfer_data_to(AVHWFramesContext *ctx, AVFrame *dst,
+                                const AVFrame *src)
+ {
+   int ret = 0;
+ 
+   av_log(ctx, AV_LOG_VERBOSE, "ni_transfer_data_to() enter\n");
+ 
+   if (src->width > ctx->width || src->height > ctx->height)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_transfer_data_to(): parameter error, dst=%dx%d, src=%dx%d\n",
+            dst->width, dst->height, src->width, src->height);
+     return AVERROR(EINVAL);
+   }
+ 
+   ret = ni_hwup_frame(ctx, dst, src);
+   if (ret < 0)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_transfer_data_to(): ni_hwup_frame failed, ret=%d\n", ret);
+     av_frame_free(&dst);
+   }
+   ret = 0;
+   return ret;
+ }
+ 
+ static int ni_transfer_data_from(AVHWFramesContext *ctx, AVFrame *dst,
+                                  const AVFrame *src)
+ {
+   AVFrame *map;
+   int ret = 0;
+ 
+   av_log(ctx, AV_LOG_VERBOSE, "ni_transfer_data_from() enter\n");
+   if (dst->width > ctx->width || dst->height > ctx->height)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_transfer_data_from(): parameter error, dst=%dx%d, src=%dx%d\n",
+            dst->width, dst->height, src->width, src->height);
+     return AVERROR(EINVAL);
+   }
+ 
+   map = av_frame_alloc();
+   if (!map)
+     return AVERROR(ENOMEM);
+   
+   ret = ni_hwdl_frame(ctx, map, src);
+   if (ret < 0)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_transfer_data_from(): ni_hwdl_frame failed, ret=%d\n", ret);
+     goto fail;
+   }
+ 
+   //Roy?
+   if (dst->format != map->format)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_transfer_data_from(): format error, %d, %d\n",
+            dst->format, map->format);
+   }
+   dst->format = map->format;
+   ret = av_frame_copy(dst, map);
+ 
+   if (ret < 0)
+   {
+     av_log(ctx, AV_LOG_ERROR, "ni_transfer_data_from(): av_frame_copy failed, ret=%d\n", ret);
+     goto fail;
+   }
+ fail:
+   av_frame_free(&map);
+   return ret;
+ }
+ 
+ const HWContextType ff_hwcontext_type_ni = {
+   .type = AV_HWDEVICE_TYPE_NI,
+   .name = "NI",
+ 
+   .device_hwctx_size = sizeof(AVNIDeviceContext),
+   .device_priv_size  = sizeof(NIDeviceContext),
+   .frames_hwctx_size = sizeof(AVNIFramesContext),
+   .frames_priv_size  = sizeof(NIFramesContext),
+ 
+   .device_create = ni_device_create,
+ 
+   .frames_get_constraints = ni_frames_get_constraints,
+ 
+   .frames_init   = ni_frames_init,
+   .frames_uninit = ni_frames_uninit,
+ 
+   .frames_get_buffer = ni_get_buffer,
+ 
+   .transfer_get_formats = ni_transfer_get_formats,
+   .transfer_data_to     = ni_transfer_data_to,
+   .transfer_data_from   = ni_transfer_data_from,
+ 
+   .pix_fmts = (const enum AVPixelFormat[]) {
+     AV_PIX_FMT_NI,
+     AV_PIX_FMT_NONE
+   },
+ };
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavutil/hwcontext_ni.h FFmpeg-n4.3.1/libavutil/hwcontext_ni.h
*** base_ffmpeg_n4.3.1/libavutil/hwcontext_ni.h	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/libavutil/hwcontext_ni.h	2021-11-04 21:55:58.347593967 -0700
***************
*** 0 ****
--- 1,61 ----
+ /*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+ 
+ #ifndef AVUTIL_HWCONTEXT_NI_H
+ #define AVUTIL_HWCONTEXT_NI_H
+ 
+ #include <ni_device_api.h>
+ #include <ni_rsrc_api.h>
+ #include "hwcontext.h"
+ 
+ enum
+ {
+   NI_MEMTYPE_VIDEO_MEMORY_NONE,
+   NI_MEMTYPE_VIDEO_MEMORY_DECODER_TARGET,
+   NI_MEMTYPE_VIDEO_MEMORY_HWUPLOAD_TARGET,
+ };
+ 
+ typedef struct NIFramesContext {
+   ni_hwframe_surface_t    *surfaces_internal;
+   int                     nb_surfaces_used;
+   ni_hwframe_surface_t    **surface_ptrs;
+   ni_device_context_t     *rsrc_ctx;  /* resource management context */
+   ni_session_data_io_t    *src_session_io_data;
+   ni_session_context_t    api_ctx;//for down/uploading frames
+   int                     pc_height, pc_width, pc_crop_bottom, pc_crop_right; //precropped values
+   ni_device_handle_t      suspended_device_handle;
+ } NIFramesContext;
+ 
+ /**
+ * This struct is allocated as AVHWDeviceContext.hwctx
+ */
+ typedef struct AVNIDeviceContext {
+   int device_idx;
+ } AVNIDeviceContext;
+ 
+ /**
+ * This struct is allocated as AVHWFramesContext.hwctx
+ */
+ typedef struct AVNIFramesContext {
+   ni_hwframe_surface_t  *surfaces;
+   int                   nb_surfaces;
+   int                   bit_depth;
+   int                   frame_type;
+ } AVNIFramesContext;
+ 
+ #endif /* AVUTIL_HWCONTEXT_NI_H */
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavutil/Makefile FFmpeg-n4.3.1/libavutil/Makefile
*** base_ffmpeg_n4.3.1/libavutil/Makefile	2022-01-30 21:54:34.424208213 -0800
--- FFmpeg-n4.3.1/libavutil/Makefile	2021-11-04 21:55:58.351592756 -0700
***************
*** 40,45 ****
--- 40,46 ----
            hwcontext_drm.h                                               \
            hwcontext_dxva2.h                                             \
            hwcontext_qsv.h                                               \
+           hwcontext_ni.h                                                \
            hwcontext_mediacodec.h                                        \
            hwcontext_opencl.h                                            \
            hwcontext_vaapi.h                                             \
***************
*** 180,185 ****
--- 181,187 ----
  OBJS-$(CONFIG_MEDIACODEC)               += hwcontext_mediacodec.o
  OBJS-$(CONFIG_OPENCL)                   += hwcontext_opencl.o
  OBJS-$(CONFIG_QSV)                      += hwcontext_qsv.o
+ OBJS-$(CONFIG_NI)                       += hwcontext_ni.o
  OBJS-$(CONFIG_VAAPI)                    += hwcontext_vaapi.o
  OBJS-$(CONFIG_VIDEOTOOLBOX)             += hwcontext_videotoolbox.o
  OBJS-$(CONFIG_VDPAU)                    += hwcontext_vdpau.o
***************
*** 196,201 ****
--- 198,204 ----
  SKIPHEADERS-$(CONFIG_D3D11VA)          += hwcontext_d3d11va.h
  SKIPHEADERS-$(CONFIG_DXVA2)            += hwcontext_dxva2.h
  SKIPHEADERS-$(CONFIG_QSV)              += hwcontext_qsv.h
+ SKIPHEADERS-$(CONFIG_NI)               += hwcontext_ni.h
  SKIPHEADERS-$(CONFIG_OPENCL)           += hwcontext_opencl.h
  SKIPHEADERS-$(CONFIG_VAAPI)            += hwcontext_vaapi.h
  SKIPHEADERS-$(CONFIG_VIDEOTOOLBOX)     += hwcontext_videotoolbox.h
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavutil/pixdesc.c FFmpeg-n4.3.1/libavutil/pixdesc.c
*** base_ffmpeg_n4.3.1/libavutil/pixdesc.c	2022-01-30 21:54:34.432208327 -0800
--- FFmpeg-n4.3.1/libavutil/pixdesc.c	2021-11-04 21:55:58.351592756 -0700
***************
*** 2061,2066 ****
--- 2061,2070 ----
          .name = "qsv",
          .flags = AV_PIX_FMT_FLAG_HWACCEL,
      },
+     [AV_PIX_FMT_NI] = {
+         .name = "ni",
+         .flags = AV_PIX_FMT_FLAG_HWACCEL,
+     },
      [AV_PIX_FMT_MEDIACODEC] = {
          .name = "mediacodec",
          .flags = AV_PIX_FMT_FLAG_HWACCEL,
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/libavutil/pixfmt.h FFmpeg-n4.3.1/libavutil/pixfmt.h
*** base_ffmpeg_n4.3.1/libavutil/pixfmt.h	2022-01-30 21:54:34.432208327 -0800
--- FFmpeg-n4.3.1/libavutil/pixfmt.h	2021-11-04 21:55:58.351592756 -0700
***************
*** 220,225 ****
--- 220,229 ----
       *  mfxFrameSurface1 structure.
       */
      AV_PIX_FMT_QSV,
+     /*
+     * HW acceleration through NI, data[3] contains a pointer to HW buffer//to be elaborated
+     */
+     AV_PIX_FMT_NI,
      /**
       * HW acceleration though MMAL, data[3] contains a pointer to the
       * MMAL_BUFFER_HEADER_T structure.
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/mingw_package_ffmpeg.sh FFmpeg-n4.3.1/mingw_package_ffmpeg.sh
*** base_ffmpeg_n4.3.1/mingw_package_ffmpeg.sh	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/mingw_package_ffmpeg.sh	2021-09-13 14:19:52.152858778 -0700
***************
*** 0 ****
--- 1,101 ----
+ #!/bin/bash
+ 
+ # This is to package all the bin files.
+ # ffmpeg.exe, ffplay.exe, ffprobe.exe and their releated dll.
+ 
+ XCODER_WORKDIR="."
+ XCODER_BIN_DIR="bin"
+ XCODER_BIN="${XCODER_WORKDIR}/${XCODER_BIN_DIR}"
+ XCODER_LOCAL_PATH="/usr/local"
+ 
+ PLATFORM=$(uname -s)
+ echo ${PLATFORM}
+ 
+ if [[ $PLATFORM =~ "MINGW32" ]]; then
+     MIGNW_PATH="/mingw32/bin"
+ else
+     MIGNW_PATH="/mingw64/bin"
+ fi
+ 
+ # Create bin folder for compilation
+ if [ ! -d "${XCODER_WORKDIR}/${XCODER_BIN_DIR}" ]; then
+     mkdir ${XCODER_BIN}
+ fi
+ 
+ # Remove the old files
+ rm -rf  ${XCODER_BIN}/*
+ 
+ echo "Package the exe and libraries to folder ${XCODER_BIN}"
+ 
+ cp -v ${XCODER_WORKDIR}/ffmpeg.exe ${XCODER_BIN}
+ 
+ if $enable_ffplay; then
+     cp -v ${XCODER_WORKDIR}/ffplay.exe ${XCODER_BIN}
+ fi
+ 
+ if $enable_ffprobe; then
+     cp -v ${XCODER_WORKDIR}/ffprobe.exe ${XCODER_BIN}
+ fi
+ 
+ if $enable_x264; then
+     cp -v ${MIGNW_PATH}/libx264-161.dll ${XCODER_BIN}
+ fi
+ 
+ if $enable_x265; then
+     cp -v ${MIGNW_PATH}/libx265.dll ${XCODER_BIN}
+     cp -v ${MIGNW_PATH}/libstdc++-6.dll ${XCODER_BIN}
+     cp -v ${MIGNW_PATH}/libgcc_s_seh-1.dll ${XCODER_BIN}
+ fi
+ 
+ if $enable_ffnvcodec; then
+     echo "Warning: don't support to package nvcodec now!!"
+     exit 1
+ fi
+ 
+ if $enable_vmaf; then
+     echo "Warning: don't support to package vmaf now!!"
+     exit 1
+ fi
+ 
+ cp -v ${MIGNW_PATH}/libbz2-1.dll ${MIGNW_PATH}/libiconv-2.dll ${MIGNW_PATH}/liblzma-5.dll ${MIGNW_PATH}/libwinpthread-1.dll ${MIGNW_PATH}/zlib1.dll ${MIGNW_PATH}/SDL2.dll ${XCODER_BIN}
+ 
+ if [[ $PLATFORM =~ "MINGW32" ]]; then
+     cp -v ${MIGNW_PATH}/libgcc_s_dw2-1.dll ${XCODER_BIN}
+ fi
+ 
+ if $enable_shared; then
+     SUBFIX="dll"
+     cp -v ${XCODER_WORKDIR}/libavcodec/*avcodec-*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavdevice/*avdevice-*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavfilter/*avfilter-*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavformat/*avformat-*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavutil/*avutil-*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libpostproc/*postproc-*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libswresample/*swresample-*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libswscale/*swscale-*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_LOCAL_PATH}/bin/libxcoder.${SUBFIX} ${XCODER_BIN}
+ 
+     SUBFIX="lib"
+     cp -v ${XCODER_WORKDIR}/libavcodec/*avcodec*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavdevice/*avdevice*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavfilter/*avfilter*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavformat/*avformat*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavutil/*avutil*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libpostproc/*postproc*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libswresample/*swresample*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libswscale/*swscale*.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_LOCAL_PATH}/bin/libxcoder.${SUBFIX} ${XCODER_BIN}
+ else
+     SUBFIX="a"
+     cp -v ${XCODER_WORKDIR}/libavcodec/*avcodec.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavdevice/*avdevice.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavfilter/*avfilter.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavformat/*avformat.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libavutil/*avutil.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libpostproc/*postproc.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libswresample/*swresample.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_WORKDIR}/libswscale/*swscale.${SUBFIX} ${XCODER_BIN}
+     cp -v ${XCODER_LOCAL_PATH}/lib/libxcoder.${SUBFIX} ${XCODER_BIN}
+ fi
+ 
+ exit 0
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/run_ffmpeg.sh FFmpeg-n4.3.1/run_ffmpeg.sh
*** base_ffmpeg_n4.3.1/run_ffmpeg.sh	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/run_ffmpeg.sh	2022-01-30 21:44:04.793495205 -0800
***************
*** 0 ****
--- 1,151 ----
+ #!/bin/bash
+ # Check Ni xcoder basic functions
+ 
+ # generate a YUV file of 1280x720p_Basketball.264 if needed
+ function gen_yuv_file_if_needed() {
+     if [ ! -f "../libxcoder/test/1280x720p_Basketball.yuv" ]; then
+         ./ffmpeg -nostdin -vsync 0 -y -i ../libxcoder/test/1280x720p_Basketball.264 -c:v rawvideo ../libxcoder/test/1280x720p_Basketball.yuv &> /dev/null
+         if [[ $? != 0 ]]; then
+             echo -e "\e[31mFAIL\e[0m: cannot generate ../libxcoder/test/1280x720p_Basketball.yuv from ../libxcoder/test/1280x720p_Basketball.264"
+         fi
+     fi
+ }
+ 
+ #for some clis output is linked to the root directory
+ declare -a Outputs=("output_5.yuv" "output_6.yuv" "output_7.h264" "output_8.h265" "output_9.h265")
+ for i in "${Outputs[@]}"
+ do
+     rm -f $i
+ done
+ 
+ while true;do
+ options=("check pci device" "check nvme list" "rsrc_init" "ni_rsrc_mon" "test 264 decoder" "test 265 decoder" "test 264 encoder" "test 265 encoder" "test 264->265 transcoder" "Quit")
+ echo -e "\e[31mChoose an option:\e[0m"
+ select opt in "${options[@]}"
+ do
+     case $opt in
+         "check pci device")
+             echo -e "\e[31mYou chose $REPLY which is $opt\e[0m"
+             lspci -d 1d82:
+             echo
+             break
+         ;;
+         "check nvme list")
+             echo -e "\e[31mYou chose $REPLY which is $opt\e[0m"
+             sudo nvme list
+             echo
+             break
+         ;;
+         "rsrc_init")
+             echo -e "\e[31mYou chose $REPLY which is $opt\e[0m"
+             ../libxcoder/bin/init_rsrc
+             echo
+             break
+         ;;
+         "ni_rsrc_mon")
+             echo -e "\e[31mYou chose $REPLY which is $opt\e[0m"
+             ../libxcoder/bin/ni_rsrc_mon
+             echo
+             break
+         ;;
+         "test 264 decoder")
+             echo -e "\e[31mYou chose $REPLY which is $opt\e[0m"
+             ##### Decoding H.264 to YUV with NI XCoder (full log) #####
+             cmd="./ffmpeg -y -hide_banner -nostdin -vsync 0 -c:v h264_ni_dec -i ../libxcoder/test/1280x720p_Basketball.264 -c:v rawvideo output_5.yuv"
+             echo $cmd
+             $cmd 2>&1 | tee ffmpeg_5.log
+             echo -e "\e[31mComplete! output_5.yuv has been generated.\e[0m"
+             CHECKSUM="be2e62fc528c61a01ac44eae5518e13a"
+             HASH=`md5sum output_5.yuv`
+             if [[ ${HASH%% *} == $CHECKSUM ]]; then
+                 echo -e "\e[31mPASS: output_5.yuv matches checksum.\e[0m"
+             else
+                 echo -e "\e[31mFAIL: output_5.yuv does not match checksum.\e[0m"
+             fi
+             echo
+             break
+         ;;
+         "test 265 decoder")
+             echo -e "\e[31mYou chose $REPLY which is $opt\e[0m"
+             ##### Decoding H.265 to YUV with NI XCoder (full log) #####
+             cmd="./ffmpeg -y -hide_banner -nostdin -vsync 0 -c:v h265_ni_dec -i ../libxcoder/test/akiyo_352x288p25.265 -c:v rawvideo output_6.yuv"
+             echo $cmd
+             $cmd 2>&1 | tee ffmpeg_6.log
+             echo -e "\e[31mComplete! output_6.yuv has been generated.\e[0m"
+             CHECKSUM="f5a29fd3fd2581844848519bafd7370d"
+             HASH=`md5sum output_6.yuv`
+             if [[ ${HASH%% *} == $CHECKSUM ]]; then
+                 echo -e "\e[31mPASS: output_6.yuv matches checksum.\e[0m"
+             else
+                 echo -e "\e[31mFAIL: output_6.yuv does not match checksum.\e[0m"
+             fi
+             echo
+             break
+         ;;
+         "test 264 encoder")
+             echo -e "\e[31mYou chose $REPLY which is $opt\e[0m"
+             gen_yuv_file_if_needed
+             ##### Encoding YUV to H.264 with NI XCoder (full log) #####
+             cmd="./ffmpeg -y -hide_banner -nostdin -f rawvideo -pix_fmt yuv420p -s:v 1280x720 -r 25 -i ../libxcoder/test/1280x720p_Basketball.yuv -c:v h264_ni_enc output_7.h264"
+             echo $cmd
+             $cmd 2>&1 | tee ffmpeg_7.log
+             echo -e "\e[31mComplete! output_7.h264 has been generated.\e[0m"
+             CHECKSUM="6713d8cc54cc4d0ab0b912a54338e4ee"
+             HASH=`md5sum output_7.h264`
+             if [[ ${HASH%% *} == $CHECKSUM ]]; then
+                 echo -e "\e[31mPASS: output_7.h264 matches checksum.\e[0m"
+             else
+                 echo -e "\e[31mFAIL: output_7.h264 does not match checksum.\e[0m"
+             fi
+             echo
+             break
+         ;;
+         "test 265 encoder")
+             echo -e "\e[31mYou chose $REPLY which is $opt\e[0m"
+             gen_yuv_file_if_needed
+             ##### Encoding YUV to H.265 with NI XCoder (full log) #####
+             cmd="./ffmpeg -y -hide_banner -nostdin -f rawvideo -pix_fmt yuv420p -s:v 1280x720 -r 25 -i ../libxcoder/test/1280x720p_Basketball.yuv -c:v h265_ni_enc output_8.h265"
+             echo $cmd
+             $cmd 2>&1 | tee ffmpeg_8.log
+             echo -e "\e[31mComplete! output_8.h265 has been generated.\e[0m"
+             CHECKSUM="f13466948494cbc1217892f55f60f5ff"
+             HASH=`md5sum output_8.h265`
+             if [[ ${HASH%% *} == $CHECKSUM ]]; then
+                 echo -e "\e[31mPASS: output_8.h265 matches checksum.\e[0m"
+             else
+                 echo -e "\e[31mFAIL: output_8.h265 does not match checksum.\e[0m"
+             fi
+             echo
+             break
+         ;;
+         "test 264->265 transcoder")
+             echo -e "\e[31mYou chose $REPLY which is $opt\e[0m"
+             ##### Transcoding H.264 to H.265 with NI XCoder (full log) #####
+             cmd="./ffmpeg -y -hide_banner -nostdin -vsync 0 -c:v h264_ni_dec -i ../libxcoder/test/1280x720p_Basketball.264 -c:v h265_ni_enc output_9.h265"
+             echo $cmd
+             $cmd 2>&1 | tee ffmpeg_9.log
+             echo -e "\e[31mComplete! output_9.h265 has been generated.\e[0m"
+             CHECKSUM="171a75a81ae8a152fa9fb182099629bf"
+             HASH=`md5sum output_9.h265`
+             echo ${HASH%% *}
+             if [[ ${HASH%% *} == $CHECKSUM ]]; then
+                 echo -e "\e[31mPASS: output_9.h265 matches checksum.\e[0m"
+             else
+                 echo -e "\e[31mFAIL: output_9.h265 does not match checksum.\e[0m"
+             fi
+             echo
+             break
+         ;;
+         "Quit")
+             break 2
+         ;;
+         *)
+             echo -e "\e[31mInvalid choice!\e[0m"
+             echo
+             break
+         ;;
+     esac
+ done
+ done
+ echo -e "\e[31mBye!\e[0m"
+ echo
diff -crBN -x .git -x .gitattributes -x .gitignore base_ffmpeg_n4.3.1/VERSION FFmpeg-n4.3.1/VERSION
*** base_ffmpeg_n4.3.1/VERSION	1969-12-31 16:00:00.000000000 -0800
--- FFmpeg-n4.3.1/VERSION	2021-08-09 14:16:17.702193501 -0700
***************
*** 0 ****
--- 1 ----
+ 4.3.1
